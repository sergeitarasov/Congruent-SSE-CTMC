---

author: "Sergei Tarasov"
date: "`r Sys.Date()`"
output:
  html_document: 
    toc: yes
params:
  output_dir: "/output"
---


# Empirical study


```{r,  include=FALSE}
library(DT)
library(ggplot2)
library(dplyr)
library(knitr)
library(kableExtra)
library(here)
knitr::opts_knit$set(root.dir = here::here(), cache = TRUE)
```

```{r message=FALSE}

##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
##  ~ installations and dependencies  ----
##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
source('R/utils/dependencies.R')
source('R/hiclasse/HiClaSSE-R.R') # pure R implementation of HiCLaSSE
source('R/hiclasse/HiClaSSE_cpp.R') # fast implementation


```

## Read in data

```{r}
phy <- read.tree('R/data/Emberts_Wiens-2021/EW_2021-ready.tre')
phy<-force.ultrametric(phy)
dat <- readRDS('R/data/Emberts_Wiens-2021/EW_2021-traits-ready.rds')
# plot(tree)

tree <- phy
is.ultrametric(tree)
states <- as.numeric(dat$SSW)
names(states) <- dat$Tip
#which(states==1) %>% length
```

## Setting-up Q matrices for inference

### CID4

```{r}
# trait
Q_t <- initQ(c(0,1), c(.1, .1))

# diversification regime
Q_r2 <- initQ(c('A','B'), c(.1,.1))


# speciation rates for tracking the order
La4 <- diag(c(-0.1,-0.05),2)
La4 = La4 %x% diag(1,2)
# order according to regimes
Q_cid4.r <- amaSMM(Q_r2, Q_t)

# order according to trait
v=c(1,3, 2,4)
Q_cid4.t <- Q_cid4.r[v,v]

print(Q_cid4.r)
print(La4)
print(Q_cid4.t)
print(La4[v,v])

# Plot the graph
g <- create_graph_from_matrix(Q_cid4.t)
unidirectional_edges <- is_unidirectional(g)
plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))

```


### CID8 (congruent to CID4)

```{r}
# diversification regime
#Q_r4 <- initQ(c('a','b', 'c', 'd'), c(.01,.01))

Q_r4 <-amaSMM(Q_t, Q_t) 
colnames(Q_r4) <- rownames(Q_r4) <- c('a','b', 'c', 'd')

# speciation rates for tracking the order
La8 <- diag(c(-0.1,-0.05),2)
La8 = La8 %x% diag(1,4)

# order according to regimes
Q_cid8.r <- amaSMM(Q_r4, Q_t) 

# order according to trait
v=c(1,3,5,7, 2,4,6,8)
Q_cid8.t <- Q_cid8.r[v,v]

print(Q_cid8.r)
print(La8)
print(Q_cid8.t)
print(La8[v,v])

# Plot the graph
g <- create_graph_from_matrix(Q_cid8.t)
unidirectional_edges <- is_unidirectional(g)
plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))
```

### COR8-C (correlated evolution, congruent to CID4)

```{r}
# like CID8 but with correlation
Q_cor8_C.t <- Q_cid8.t


# Q_cor8_C.t['b0', 'd0'] <- 0
# Q_cor8_C.t['b0', 'c0'] <- 0.1

Q_cor8_C.t['b1', 'd1'] <- 0
Q_cor8_C.t['b1', 'c1'] <- 0.1

v=c(1,5, 2,6, 3,7, 4,8)
Q_cor8_C.r <- Q_cor8_C.t[v,v]

print(Q_cor8_C.r*10)
#print(La8)
print(Q_cor8_C.t*10)
#print(La8[v,v])

# Plot the graph
g <- create_graph_from_matrix(Q_cor8_C.t)
unidirectional_edges <- is_unidirectional(g)
plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))

```

### COR8-NC (correlated evolution, Non-congruent to CID4)

```{r}
# not congruent
Q_cor8_NC.t <- Q_cid8.t

# Q_cor8_NC.t['b0', 'd0'] <- 0
# Q_cor8_NC.t['b0', 'c0'] <- 0

Q_cor8_NC.t['b1', 'd1'] <- 0
Q_cor8_NC.t['b1', 'c1'] <- 0

v=c(1,5, 2,6, 3,7, 4,8)
Q_cor8_NC.r <- Q_cor8_NC.t[v,v]

print(Q_cor8_NC.r*10)
#print(La8)
print(Q_cor8_NC.t*10)
#print(La8[v,v])

# Plot the graph
g <- create_graph_from_matrix(Q_cor8_NC.t)
unidirectional_edges <- is_unidirectional(g)
plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))

```


## HiSSE: reproducing results from Emberts & Wiens (2020) 

All the data and code used in Emberts & Wiens (2020) are available on Dryad (https://doi.org/10.5061/dryad.fqz612js3).

The original study reports AIC = 1987.2 that is close to current estimate (AIC = 1986.766) using the same HiSSE setup.

```{r}

mytree.p <- tree
mydata.p.sse <- dat

#CID-2 Model
turnover.anc = c(1,1,2,2)
eps.anc = c(1,1,2,2)
#full 8 transition model
trans.rates = TransMatMaker.old(hidden.states=TRUE)
trans.rates.nodual = ParDrop(trans.rates, c(3,5,8,10))
#setting all transition rates equal
trans.rates.nodual.allequal = ParEqual(trans.rates.nodual, c(1,2,1,3,1,4,1,5,1,6,1,7,1,8))
trans.rates.nodual.allequal
CID2.p <-  hisse.old(mytree.p, mydata.p.sse, f=c(0.075,0.075), hidden.states=TRUE, turnover.anc=turnover.anc, eps.anc=eps.anc, trans.rate=trans.rates.nodual.allequal,output.type="raw")

print(CID2.p$loglik)
#-988.3828

#2*5-2*CID2.p$loglik
print(CID2.p$AIC)
# 1986.766

# div at A (lam-mu)
0.1291833-0.01168628

# div at B (lam-mu)
0.2884714-0.263662
```

### BiSSE

```{r}
#BiSSE Null Model (implemented in HiSSE)
turnover.anc = c(1,1,0,0)
eps.anc = c(1,1,0,0)
trans.rates.bisse = TransMatMaker.old(hidden.states=FALSE)
BiSSE.null.p <-  hisse.old(mytree.p, mydata.p.sse, f=c(0.075,0.075), hidden.states=FALSE,
                           turnover.anc=turnover.anc, eps.anc=eps.anc, trans.rate=trans.rates.bisse, output.type = "raw")
BiSSE.null.p
# -991.0471
```


## HiClaSSE: data from Emberts & Wiens (2020) 

### CID4: Reproducing results from Emberts & Wiens (2020)

```{r message=FALSE}

s1 <- 0.075
s2 <- 0.075

sam.fr4 = list(
  c(1-s1, 1-s2, 1-s1, 1-s2,   s1, 0, s1, 0),
  c(1-s1, 1-s2, 1-s1, 1-s2,   0, s2, 0, s2)
)

Args <- list(
  Nstates = 4L,
  y = sam.fr4)

newArgs <- makeArgs(Args)
#printArgsGlobal()
args <- argnames_HiClaSSE(4)
args$arrays
#args$pars
#length(args$pars)
#reoder_lambdas(args$arrays, c(1,3, 2,4))

pars.hc <- rep(0, length(args$pars))
names(pars.hc) <- args$pars
pars.hc['lam000'] <- 0.1
pars.hc['lam111'] <- 0.1
pars.hc['lam222'] <- 0.05
pars.hc['lam333'] <- 0.05
pars.hc['mu0'] <-pars.hc['mu1'] <- pars.hc['mu2'] <- pars.hc['mu3'] <-0.1
qs <- extract_off_diagonal(Q_cid4.r)
qsl=length(qs)
pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] <- qs

#pars.hc
#pars_to_arrays(pars.hc,4)
#args

zero.constr <- formulas_zero_pars(pars.hc)
f.qs <- assign_classes_pairwise(Q_cid4.r, args$arrays$Q)
f.mu <- c(mu1 ~ mu0, mu3 ~ mu2)
#f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0)
f.lams <- c(lam111 ~ lam000, lam333 ~ lam222)
f.list<- c(zero.constr,  f.qs, f.mu, f.lams)

```

```{r}

ar=names2array(args$arrays, c('A0',   'A1',   'B0',   'B1'))
ar.re=reoder_lambdas(ar, c(1,3,  2,4))
#ar.re$lam.tensor

element <- c(
'lam000',
'lam111',
'lam222',
'lam333'
)
find_elements(ar.re$lam.tensor, element)
```



Run inference. The result is the same with HiSSE

```{r message=FALSE}

lik.c <- make.HiClasse_cpp(tree, states,  sampling.f=NULL,  strict=TRUE, control=list(backend = "gslode"), newArgs)
lik.const <- constrain(lik.c, formulae = f.list)
arg.const <- argnames(lik.const)
starting.point <- pars.hc[arg.const]

starting.point[['lam000']] <-0.288701
starting.point[['lam222']] <-0.1292103
starting.point[['mu0']] <-0.2639205
starting.point[['mu2']] <-0.01172136
starting.point[['q01']] <- 0.001190693

CID4 <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.OBS, condition.surv=TRUE)
CID4$lnLik

#CID4$par
# -988.3828
# same Ln as HiSSE

```

Since we are going to create perfectly congruent models, we need to obtain the probability vector at the root because, for congruent models, it should be expanded as well. The original study uses a root prior inferred from data following FitzJohn et al. 2009. We take this vector and treat it as known to maintain exact congruence. This change affects the inference somewhat (as we will use the 'root=ROOT.OBS' option) and naturally, slightly changes the likelihood estimate.

```{r}
# getting root values using the original model
intermediates=lik.c(CID4$par.full, intermediates=T, root=ROOT.OBS, condition.surv=TRUE)
CID4.root <- attr(intermediates, "intermediates")$root.p
# Ln
#print(intermediates[1])
# probabilities at the root
print(CID4.root)

# now plugin the inferred root as observed and recalculating Ln
# Ln is slightly better
CID4.given <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.GIVEN,
                 root.p=CID4.root,
                 condition.surv=TRUE)
CID4.given$lnLik
#  -988.22
get_aic(CID4.given$lnLik, 5)
# 1986.44

# parametres
CID4.given$par


# root vector for congruent models
root8.cong <- c(
  CID4.root[1]/2,
  CID4.root[2]/2,
  CID4.root[1]/2,
  CID4.root[2]/2,
  CID4.root[3]/2,
  CID4.root[4]/2,
  CID4.root[3]/2,
  CID4.root[4]/2)


```

#### Different starting point.

Another staritng point to check for local optima. The results is the same as before.

```{r}
starting.point[['lam000']] <-0.3231599281*3
starting.point[['lam222']] <-0.3231599281
starting.point[['mu0']] <-1.4947999228
starting.point[['mu2']] <-0.0287763212
starting.point[['q01']] <- 0.0003463041

CID4.given2 <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.GIVEN,
                 root.p=CID4.root,
                 condition.surv=TRUE)
CID4.given2$lnLik

```

```{r}
# 
# ar=names2array(args$arrays, c('A0',   'A1',   'B0',   'B1'))
# ar.re=reoder_lambdas(ar, c(1,3,  2,4))
# 
# pars_to_arrays(CID4.given$par.full, 4)
# v=c(1,3,5,7, 2,4,6,8)
# pars_to_arrays(pars.hc, 8)$Q[v,v]

```

### CID2 (BiSSE)

```{r}

s1 <- 0.075
s2 <- 0.075

sam.fr2 = list(
  c(1-s1, 1-s2,   s1, 0),
  c(1-s1, 1-s2,   0, s2)
)

Args <- list(
  Nstates = 2L,
  y = sam.fr2)

newArgs <- makeArgs(Args)
args <- argnames_HiClaSSE(2)


f.list<- c(lam001 ~ 0, lam011 ~ 0, lam100 ~ 0, lam101 ~ 0, lam111 ~ lam000, mu0 ~ mu1)

lik.c <- make.HiClasse_cpp(tree, states,  sampling.f=NULL,  strict=TRUE, control=list(backend = "gslode"), newArgs)
lik.const <- constrain(lik.c, formulae = f.list)
starting.point <- c()
starting.point['lam000'] <-0.1487245
starting.point['mu1'] <-0.04179899
starting.point['q01'] <- 0.001084268
starting.point['q10'] <- 2.061154e-09


CID2 <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.OBS,condition.surv=TRUE)
CID2$lnLik
#  -991.0454
get_aic(CID2$lnLik, 4)
# 1990.091

```



### CID8

```{r}
s1 <- 0.075
s2 <- 0.075

sam.fr8 = list(
  c(1-s1, 1-s2, 1-s1, 1-s2,  1-s1, 1-s2, 1-s1, 1-s2,   s1, 0, s1, 0,  s1, 0, s1, 0),
  c(1-s1, 1-s2, 1-s1, 1-s2,  1-s1, 1-s2, 1-s1, 1-s2,   0, s2, 0, s2,  0, s2, 0, s2)
)

Args <- list(
  Nstates = 8L,
  y = sam.fr8
    )

newArgs <- makeArgs(Args)
#printArgsGlobal()
args <- argnames_HiClaSSE(8)
#args$arrays
#args$pars
#length(args$pars)

pars.hc <- rep(0, length(args$pars))
names(pars.hc) <- args$pars
pars.hc['lam000'] <- 0.1
pars.hc['lam111'] <- 0.1
pars.hc['lam222'] <- 0.1
pars.hc['lam333'] <- 0.1
pars.hc['lam444'] <- 0.05
pars.hc['lam555'] <- 0.05
pars.hc['lam666'] <- 0.05
pars.hc['lam777'] <- 0.05
pars.hc['mu0'] <-pars.hc['mu1'] <- pars.hc['mu2'] <- pars.hc['mu3'] <- pars.hc['mu4']<- pars.hc['mu5']<- pars.hc['mu6']<- pars.hc['mu7'] <-0.1
qs <- extract_off_diagonal(Q_cid8.r)
qsl=length(qs)
#unique(qs)
pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] <- qs

#pars.hc
#pars_to_arrays(pars.hc,8)
#args

zero.constr <- formulas_zero_pars(pars.hc)
f.qs <- assign_classes_pairwise(Q_cid8.r, args$arrays$Q)
#f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0)
f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0,  mu5 ~ mu4, mu6 ~ mu4, mu7 ~ mu4)
f.lams <- c(lam111 ~ lam000, lam222 ~ lam000, lam333 ~ lam000,   
            lam555 ~ lam444, lam666 ~ lam444, lam777 ~ lam444)
f.list<- c(zero.constr,  f.qs, f.mu, f.lams)

```

```{r}
# a0 a1 b0 b1 c0 c1 d0 d1
ar=names2array(args$arrays, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))
ar.re=reoder_lambdas(ar, c(1,3,5,7, 2,4,6,8))
#ar.re$lam.tensor

element <- c(
'lam000',
'lam111',
'lam222',
'lam333',

'lam444',
'lam555',
'lam666',
'lam777'
)
find_elements(ar.re$lam.tensor, element)
```



Run inference

```{r}

lik.c <- make.HiClasse_cpp(tree, states,  sampling.f=NULL,  strict=TRUE, control=list(backend = "gslode"), newArgs)
lik.const <- constrain(lik.c, formulae = f.list)
arg.const <- argnames(lik.const)
starting.point <- pars.hc[arg.const]

starting.point[['lam000']] <-0.288701
starting.point[['lam444']] <-0.1292103
starting.point[['mu0']] <-0.2639205
starting.point[['mu4']] <-0.01172136
starting.point[['q01']] <- 0.001190693

# CID8 <- find.mle(lik.const, starting.point, method="subplex", keep.func=F, root=ROOT.OBS, condition.surv=TRUE)
# CID8$lnLik
# #-988.3828
CID8 <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.GIVEN,
                 root.p=root8.cong,
                 condition.surv=TRUE)
CID8$lnLik
#  -988.22
get_aic(CID8$lnLik, 5)
# 1986.44
```

```{r}
# Plot the graph
# ar <- pars_to_arrays(CID8$par.full, 8)
# Qpl <- names2array(ar, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))$Q
# g <- create_graph_from_matrix(Qpl)
# unidirectional_edges <- is_unidirectional(g)
# plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))
```


### COR8-C

```{r}


pars.hc <- rep(0, length(args$pars))
names(pars.hc) <- args$pars
pars.hc['lam000'] <- 0.1
pars.hc['lam111'] <- 0.1
pars.hc['lam222'] <- 0.1
pars.hc['lam333'] <- 0.1
pars.hc['lam444'] <- 0.05
pars.hc['lam555'] <- 0.05
pars.hc['lam666'] <- 0.05
pars.hc['lam777'] <- 0.05
pars.hc['mu0'] <-pars.hc['mu1'] <- pars.hc['mu2'] <- pars.hc['mu3'] <- pars.hc['mu4']<- pars.hc['mu5']<- pars.hc['mu6']<- pars.hc['mu7'] <-0.1
qs <- extract_off_diagonal(Q_cor8_C.r)
qsl=length(qs)
pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] <- qs


zero.constr <- formulas_zero_pars(pars.hc)
f.qs <- assign_classes_pairwise(Q_cor8_C.r, args$arrays$Q)
#f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0)
f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0,  mu5 ~ mu4, mu6 ~ mu4, mu7 ~ mu4)
f.lams <- c(lam111 ~ lam000, lam222 ~ lam000, lam333 ~ lam000,   
            lam555 ~ lam444, lam666 ~ lam444, lam777 ~ lam444)
f.list<- c(zero.constr,  f.qs, f.mu, f.lams)

```

```{r}
# # a0 a1 b0 b1 c0 c1 d0 d1
# ar=names2array(args$arrays, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))
# ar.re=reoder_lambdas(ar, c(1,3,5,7, 2,4,6,8))
# #ar.re$lam.tensor
# 
# element <- c(
# 'lam000',
# 'lam111',
# 'lam222',
# 'lam333',
# 
# 'lam444',
# 'lam555',
# 'lam666',
# 'lam777'
# )
# find_elements(ar.re$lam.tensor, element)
```



Run inference

```{r}


lik.c <- make.HiClasse_cpp(tree, states,  sampling.f=NULL,  strict=TRUE, control=list(backend = "gslode"), newArgs)
lik.const <- constrain(lik.c, formulae = f.list)
arg.const <- argnames(lik.const)

starting.point <- pars.hc[arg.const]
starting.point[['lam000']] <-0.288701
starting.point[['lam444']] <-0.1292103
starting.point[['mu0']] <-0.2639205
starting.point[['mu4']] <-0.01172136
starting.point[['q01']] <- 0.001190693


#pars_to_arrays(COR8_C$par.full, 8) %>% reoder_lambdas(., c(1,3,5,7, 2,4,6,8))
# COR8_C <- find.mle(lik.const, starting.point, method="subplex", keep.func=F, root=ROOT.OBS, condition.surv=TRUE)
# COR8_C$lnLik

COR8_C  <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.GIVEN,
                 root.p=root8.cong,
                 condition.surv=TRUE)
COR8_C $lnLik
#  -988.22
get_aic(COR8_C $lnLik, 5)
# 1986.44
#COR8_C $par
```

```{r}
# Plot the graph
ar <- pars_to_arrays(COR8_C$par.full, 8)
Qpl <- names2array(ar, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))$Q
g <- create_graph_from_matrix(Qpl)
unidirectional_edges <- is_unidirectional(g)
plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))
```


### COR8-NC

```{r}

pars.hc <- rep(0, length(args$pars))
names(pars.hc) <- args$pars
pars.hc['lam000'] <- 0.1
pars.hc['lam111'] <- 0.1
pars.hc['lam222'] <- 0.1
pars.hc['lam333'] <- 0.1
pars.hc['lam444'] <- 0.05
pars.hc['lam555'] <- 0.05
pars.hc['lam666'] <- 0.05
pars.hc['lam777'] <- 0.05
pars.hc['mu0'] <-pars.hc['mu1'] <- pars.hc['mu2'] <- pars.hc['mu3'] <- pars.hc['mu4']<- pars.hc['mu5']<- pars.hc['mu6']<- pars.hc['mu7'] <-0.1
qs <- extract_off_diagonal(Q_cor8_NC.r)
qsl=length(qs)
pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] <- qs

#pars.hc
#pars_to_arrays(pars.hc,8)
#args

zero.constr <- formulas_zero_pars(pars.hc)
f.qs <- assign_classes_pairwise(Q_cor8_NC.r, args$arrays$Q)
#f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0)
f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0,  mu5 ~ mu4, mu6 ~ mu4, mu7 ~ mu4)
f.lams <- c(lam111 ~ lam000, lam222 ~ lam000, lam333 ~ lam000,   
            lam555 ~ lam444, lam666 ~ lam444, lam777 ~ lam444)
f.list<- c(zero.constr,  f.qs, f.mu, f.lams)

```

Run inference

```{r}


lik.c <- make.HiClasse_cpp(tree, states,  sampling.f=NULL,  strict=TRUE, control=list(backend = "gslode"), newArgs)
lik.const <- constrain(lik.c, formulae = f.list)
arg.const <- argnames(lik.const)

starting.point <- pars.hc[arg.const]
starting.point[['lam000']] <-0.288701
starting.point[['lam444']] <-0.1292103
starting.point[['mu0']] <-0.2639205
starting.point[['mu4']] <-0.01172136
starting.point[['q01']] <- 0.001190693


#COR8_NC <- find.mle(lik.const, starting.point, method="subplex", keep.func=F, root=ROOT.OBS, condition.surv=TRUE)
#COR8_NC$lnLik

COR8_NC  <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.GIVEN,
                 root.p=root8.cong,
                 condition.surv=TRUE)
COR8_NC$lnLik
# -988.2076
#COR8_NC$par
get_aic(COR8_NC$lnLik, 5)
# 1986.415
```


```{r}
# Plot the graph
ar <- pars_to_arrays(COR8_NC$par.full, 8)
Qpl <- names2array(ar, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))$Q
g <- create_graph_from_matrix(Qpl)
unidirectional_edges <- is_unidirectional(g)
plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))
```


### CLA8-C

```{r}

pars.hc <- rep(0, length(args$pars))
names(pars.hc) <- args$pars

pars.hc['lam022'] <- 0.1
pars.hc['lam133'] <- 0.1
pars.hc['lam202'] <- 0.1
pars.hc['lam311'] <- 0.1
pars.hc['lam466'] <- 0.05
pars.hc['lam577'] <- 0.05
pars.hc['lam646'] <- 0.05
pars.hc['lam757'] <- 0.05
pars.hc['mu0'] <-pars.hc['mu1'] <- pars.hc['mu2'] <- pars.hc['mu3'] <- pars.hc['mu4']<- pars.hc['mu5']<- pars.hc['mu6']<- pars.hc['mu7'] <-0.1
qs <- extract_off_diagonal(Q_cor8_C.r)
qsl=length(qs)
pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] <- qs

#pars.hc
#pars_to_arrays(pars.hc,8)
#args

zero.constr <- formulas_zero_pars(pars.hc)
f.qs <- assign_classes_pairwise(Q_cor8_C.r, args$arrays$Q)
#f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0)
f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0,  mu5 ~ mu4, mu6 ~ mu4, mu7 ~ mu4)
f.lams <- c(lam133 ~ lam022, lam202 ~ lam022, lam311 ~ lam022,   
            lam577 ~ lam466, lam646 ~ lam466, lam757 ~ lam466)
f.list<- c(zero.constr,  f.qs, f.mu, f.lams)

```


Checking the model setup
```{r}
# a0 a1 b0 b1 c0 c1 d0 d1
ar=names2array(args$arrays, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))
ar.re=reoder_lambdas(ar, c(1,3,5,7, 2,4,6,8))
#ar.re$lam.tensor

element <- c(
'lam022',
'lam133',
'lam202',
'lam311',
'lam466',
'lam577',
'lam646',
'lam757'
)
find_elements(ar.re$lam.tensor, element)

```

Run inference

```{r}


lik.c <- make.HiClasse_cpp(tree, states,  sampling.f=NULL,  strict=TRUE, control=list(backend = "gslode"), newArgs)
lik.const <- constrain(lik.c, formulae = f.list)
arg.const <- argnames(lik.const)

starting.point <- pars.hc[arg.const]
starting.point[['lam022']] <-0.288701
starting.point[['lam466']] <-0.1292103
starting.point[['mu0']] <-0.2639205
starting.point[['mu4']] <-0.01172136
starting.point[['q01']] <- 0.001190693


# CLA8_C <- find.mle(lik.const, starting.point, method="subplex", keep.func=F, root=ROOT.OBS, condition.surv=TRUE)
# CLA8_C$lnLik

CLA8_C  <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.GIVEN,
                 root.p=root8.cong,
                 condition.surv=TRUE)
CLA8_C$lnLik
# -988.22
get_aic(CLA8_C$lnLik, 5)
# 1986.44
#CLA8_C$par
```

```{r}
# Plot the graph
ar <- pars_to_arrays(CLA8_C$par.full, 8)
Qpl <- names2array(ar, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))$Q
g <- create_graph_from_matrix(Qpl)
unidirectional_edges <- is_unidirectional(g)
plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))

#names2array(ar, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1')) %>% reoder_lambdas(., c(1,3,5,7, 2,4,6,8))

```


### CLA8-NC

```{r}

pars.hc <- rep(0, length(args$pars))
names(pars.hc) <- args$pars
# lam004, lam116, lam422 violate lumpability
pars.hc['lam004'] <- 0.1
pars.hc['lam116'] <- 0.1
pars.hc['lam202'] <- 0.1
pars.hc['lam311'] <- 0.1
pars.hc['lam422'] <- 0.05
pars.hc['lam577'] <- 0.05
pars.hc['lam646'] <- 0.05
pars.hc['lam757'] <- 0.05
pars.hc['mu0'] <-pars.hc['mu1'] <- pars.hc['mu2'] <- pars.hc['mu3'] <- pars.hc['mu4']<- pars.hc['mu5']<- pars.hc['mu6']<- pars.hc['mu7'] <-0.1
qs <- extract_off_diagonal(Q_cor8_C.r)
qsl=length(qs)
pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] <- qs

#pars.hc
#pars_to_arrays(pars.hc,8)
#args

zero.constr <- formulas_zero_pars(pars.hc)
f.qs <- assign_classes_pairwise(Q_cor8_C.r, args$arrays$Q)
f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0,  mu5 ~ mu4, mu6 ~ mu4, mu7 ~ mu4)
f.lams <- c(lam116 ~ lam004, lam202 ~ lam004, lam311 ~ lam004,   
            lam577 ~ lam422, lam646 ~ lam422, lam757 ~ lam422)
f.list<- c(zero.constr,  f.qs, f.mu, f.lams)

```

```{r}
# a0 a1 b0 b1 c0 c1 d0 d1
ar=names2array(args$arrays, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))
ar.re=reoder_lambdas(ar, c(1,3,5,7, 2,4,6,8))
#ar.re$lam.tensor

element <- c(
'lam004',
'lam116',
'lam202',
'lam311',

'lam422',
'lam577',
'lam646',
'lam757'
)
find_elements(ar.re$lam.tensor, element)


```

Run inference

```{r}

lik.c <- make.HiClasse_cpp(tree, states,  sampling.f=NULL,  strict=TRUE, control=list(backend = "gslode"), newArgs)
lik.const <- constrain(lik.c, formulae = f.list)
arg.const <- argnames(lik.const)

starting.point <- pars.hc[arg.const]
starting.point[['lam004']] <-0.288701
starting.point[['lam422']] <-0.1292103
starting.point[['mu0']] <-0.2639205
starting.point[['mu4']] <-0.01172136
starting.point[['q01']] <- 0.001190693

# CLA8_NC <- find.mle(lik.const, starting.point, method="subplex", keep.func=F, root=ROOT.OBS, condition.surv=TRUE)
CLA8_NC <- find.mle(lik.const, starting.point, method="subplex", keep.func=F, root=ROOT.GIVEN, root.p=root8.cong, condition.surv=TRUE)

CLA8_NC$lnLik
# -992.1789
get_aic(CLA8_NC$lnLik, 5)
# 1994.358
#CLA8_NC$par
```


```{r}
# Plot the graph
ar <- pars_to_arrays(CLA8_NC$par.full, 8)
Qpl <- names2array(ar, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))$Q
g <- create_graph_from_matrix(Qpl)
unidirectional_edges <- is_unidirectional(g)
plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))

#names2array(ar, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1')) %>% reoder_lambdas(., c(1,3,5,7, 2,4,6,8))
```


### EHE25-C

EHE models can have thousands of states, depending on the rounding of the original rates. In this example, we round the original rates to rounding to three decimal places, which results in EHE with 25 hidden states. This EHE is a close approximation to the original model as we will see given its similar likelihood value.

HiClaSSE may not handle so many states at the moment. Additionally, setting up such models is tedious due to excessively many transitions. Thus, we use a trick: we derive an EHE model but instead substitute it with CID4 with rate multipliers for the base rate. Such an approach is equivalent due to the true EHE model and yields identical likelihood.

In deriving EHE, we follow the EHE algorithm from the SI. As the code below shows, such an EHE model should have 25 hidden states but just 3 parameters (q, mu0, mu1), instead of 5 in CID4.

```{r}
# original model
# CID4.given$par
#      lam000      lam222         mu0         mu2         q01 
# 0.309573792 0.138211489 0.288302422 0.025494279 0.001151849 

# let's round the rates and pool them
pool=c(0.310, 0.140, 0.001)
frac=MASS::fractions(pool, cycles = 10, max.denominator = 2000)
fracs <- attr(frac[frac != 0], "fracs")
fracs[fracs == "1"] <- "1/1"
fracs <- strsplit(fracs, "/")
vec.denom <- lapply(fracs, function(x) x[2]) %>% unlist() %>%  as.numeric()
lcm <- numbers::mLCM(vec.denom)

# base rate
r <- 1/lcm
lam.max=0.31
q.max=0.001
Nq=q.max/r

u=(-1+sqrt(1+8*(lam.max/r)))/2
Nlam=ceiling(u)

# number of hidden states in EHE
Nh=max(Nq, Nlam)
print(Nh)
# [1] 25

# rate multipliers for the base rates
print(pool/r)
# [1] 310 140   1
```


```{r}

s1 <- 0.075
s2 <- 0.075

sam.fr4 = list(
  c(1-s1, 1-s2, 1-s1, 1-s2,   s1, 0, s1, 0),
  c(1-s1, 1-s2, 1-s1, 1-s2,   0, s2, 0, s2)
)

Args <- list(
  Nstates = 4L,
  y = sam.fr4)

newArgs <- makeArgs(Args)
#printArgsGlobal()
args <- argnames_HiClaSSE(4)
#args$arrays
#args$pars
#length(args$pars)
#reoder_lambdas(args$arrays, c(1,3, 2,4))

pars.hc <- rep(0, length(args$pars))
names(pars.hc) <- args$pars
pars.hc['lam000'] <- 0.1
pars.hc['lam111'] <- 0.1
pars.hc['lam222'] <- 0.05
pars.hc['lam333'] <- 0.05
pars.hc['mu0'] <-pars.hc['mu1'] <- pars.hc['mu2'] <- pars.hc['mu3'] <-0.1
qs <- extract_off_diagonal(Q_cid4.r)
qsl=length(qs)
pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] <- qs

#pars.hc
#pars_to_arrays(pars.hc,4)
#args

zero.constr <- formulas_zero_pars(pars.hc)
f.qs <- assign_classes_pairwise(Q_cid4.r, args$arrays$Q)
#f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0)
f.mu <- c(mu1 ~ mu0, mu3 ~ mu2)
# here we plug in EHE rate multipliers
f.lams <- c(lam000 ~ 310 * q01, lam111 ~ 310 * q01, lam222 ~ 140 * q01, lam333 ~ 140 * q01)

f.list<- c(zero.constr,  f.qs, f.mu, f.lams)

```


Run inference

```{r message=FALSE}

lik.c <- make.HiClasse_cpp(tree, states,  sampling.f=NULL, strict=TRUE, control=list(backend = "gslode", intermediates=T), newArgs)
lik.const <- constrain(lik.c, formulae = f.list)
arg.const <- argnames(lik.const)
starting.point <- pars.hc[arg.const]

starting.point[['q01']] <- 0.001190693
starting.point[['mu0']] <-0.2639205
starting.point[['mu2']] <-0.01172136

#EHE <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.OBS, condition.surv=TRUE)
EHE <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.GIVEN, root.p=CID4.root, condition.surv=TRUE)

EHE$lnLik
# -988.285
#get_aic(EHE$lnLik, 3)
```








### SEM: semi-congreunt model

By expanding CID4 to create a semi-congruent model (SEM8) with 8 hidden states, we manually found a parameterization scheme for SEM8 that outperforms the initial CID4 model and demonstrates trait-dependent evolution.


```{r}

s1 <- 0.075
s2 <- 0.075

sam.fr8 = list(
  c(1-s1, 1-s2, 1-s1, 1-s2,  1-s1, 1-s2, 1-s1, 1-s2,   s1, 0, s1, 0,  s1, 0, s1, 0),
  c(1-s1, 1-s2, 1-s1, 1-s2,  1-s1, 1-s2, 1-s1, 1-s2,   0, s2, 0, s2,  0, s2, 0, s2)
)

Args <- list(
  Nstates = 8L,
  y = sam.fr8
)


newArgs <- makeArgs(Args)
#printArgsGlobal()
args <- argnames_HiClaSSE(8)
#args$arrays
#args$pars
#length(args$pars)

pars.hc <- rep(0, length(args$pars))
names(pars.hc) <- args$pars

pars.hc['lam000'] <- pars.hc['lam002'] <- pars.hc['lam022'] <- 0.1/2
pars.hc['lam200'] <- pars.hc['lam202'] <- pars.hc['lam222'] <- 0.1/2
pars.hc['lam111'] <- pars.hc['lam113'] <- pars.hc['lam133'] <- 0.1/2
pars.hc['lam311'] <- pars.hc['lam313'] <- pars.hc['lam333'] <- 0.1/2
pars.hc['lam466'] <- 0.05
pars.hc['lam555'] <- 0.05
pars.hc['lam604'] <- 0.05
pars.hc['lam777'] <- 0.05

pars.hc['mu0'] <-pars.hc['mu1'] <- pars.hc['mu2'] <- pars.hc['mu3'] <- pars.hc['mu4']<- pars.hc['mu5']<- pars.hc['mu6']<- pars.hc['mu7'] <-0.1

# Best
Q_sem_best.t <- matrix(c(
  -4,  0,  1,  1,  1,  1,  0,  0,
   0, -4,  1,  0,  1,  1,  0,  0,
   1,  1, -4,  0,  0,  0,  1,  0,
   1,  1,  0, -4,  0,  0,  0,  0,
   1,  1,  1,  1, -4,  0,  1,  1,
   1,  1,  1,  0,  0, -4,  1,  1,
   1,  1,  1,  1,  1,  1, -4,  0,
   1,  0,  1,  1,  1,  1,  0, -4),
  nrow = 8, byrow = TRUE,
  dimnames = list(c("a0", "b0", "c0", "d0", "a1", "b1", "c1", "d1"), c("a0", "b0", "c0", "d0", "a1", "b1", "c1", "d1"))
)




v=c(1,5,2,6, 3,7,4,8)
Q_sem_best.r <-  Q_sem_best.t[v,v]

qs <- extract_off_diagonal(Q_sem_best.r)
qsl=length(qs)
#unique(qs)
pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] <- qs

#pars.hc
#pars_to_arrays(pars.hc,8)
#args

zero.constr <- formulas_zero_pars(pars.hc)
f.qs <- assign_classes_pairwise(Q_sem_best.r, args$arrays$Q)

f.mu <- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0,  mu5 ~ mu4, mu6 ~ mu4, mu7 ~ mu4)

f.lams <- c(  lam002 ~ lam000, lam022 ~ lam000,
              lam200 ~ lam000, lam202 ~ lam000, lam222 ~ lam000,
              lam111 ~ lam000, lam113 ~ lam000, lam133 ~ lam000,
              lam311 ~ lam000, lam313 ~ lam000, lam333 ~ lam000,
              lam604 ~ lam000,
              lam777 ~ lam000,
              lam466 ~ lam000,
              lam555 ~ lam000
)

f.list<- c(zero.constr,  f.qs, f.mu, f.lams)


```



Run inference

```{r}

lik.c <- make.HiClasse_cpp(tree, states,  sampling.f=NULL,  strict=TRUE, control=list(backend = "gslode"), newArgs)
lik.const <- constrain(lik.c, formulae = f.list)
arg.const <- argnames(lik.const)
starting.point <- pars.hc[arg.const]

starting.point[['lam000']] <-0.3231599281
starting.point[['mu0']] <- 1.4947999228
starting.point[['mu4']] <-0.0287763212
starting.point[4] <- 0.0003463041 

SEM8 <- find.mle(lik.const, starting.point, intermediates=F,  method="subplex", keep.func=F, root=ROOT.GIVEN,
                 root.p=root8.cong,
                 condition.surv=TRUE)
SEM8$lnLik
#  -984.2077

get_aic(SEM8$lnLik, 4)
```


```{r}

# SEM8$par

# a0 a1 b0 b1 c0 c1 d0 d1
ar=names2array(args$arrays, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))
ar.re=reoder_lambdas(ar, c(1,3,5,7, 2,4,6,8))
#ar.re$lam.tensor

element <- c(
'lam000',
'lam002', 
'lam022', 
'lam200', 
'lam202',  
'lam222',
'lam111', 
'lam113',  
'lam133',
'lam311', 
'lam313',  
'lam333',
'lam604',
'lam777',
'lam466',
'lam555'
)
find_elements(ar.re$lam.tensor, element)


```

Print nice to show matrix structure only

```{r}

pp <- SEM8$par.full*100
X <- pars_to_arrays(pp, 8) %>% reoder_lambdas(., c(1,3,5,7, 2,4,6,8))
X <- names2array(X, c('a0', 'b0', 'c0',  'd0',  'a1',  'b1',  'c1',  'd1'))

```




```{r}
# Plot the graph
ar <- pars_to_arrays(SEM8$par.full, 8)
Qpl <- names2array(ar, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1'))$Q
g <- create_graph_from_matrix(Qpl)
unidirectional_edges <- is_unidirectional(g)
plot(g, vertex.label = V(g)$name, vertex.size = 30, edge.color = ifelse(unidirectional_edges, "red", "black"))

#round(Qpl, 4)
# v=c(1,3,5,7, 2,4,6,8)
# round(Qpl, 4)[v,v]
# 
# names2array(ar, c('a0', 'a1', 'b0', 'b1', 'c0', 'c1', 'd0', 'd1')) %>% reoder_lambdas(., c(1,3,5,7, 2,4,6,8))
```





## Results 

### Estimates

```{r}
# Function to calculate delta AIC
get_delta_aic <- function(aic_values) {
  min_aic <- min(aic_values)
  return(aic_values - min_aic)
}

# Create data frame with model names as rows and AIC values, Ln values, number of parameters, and delta AIC values as columns
estimates <- data.frame(
  Model = c("CID4", "CID2", "CID8", "COR8-C", "CLA8-C", "COR8-NC", "CLA8-NC", "EHE", "SEM8"),
  npars = c(5, 4, 5, 5, 5, 5, 5, 3, 4),
  Ln = c(CID4.given$lnLik, CID2$lnLik, CID8$lnLik, COR8_C$lnLik, CLA8_C$lnLik, COR8_NC$lnLik, CLA8_NC$lnLik, EHE$lnLik, SEM8$lnLik),
  AIC = c(get_aic(CID4.given$lnLik, 5), 
          get_aic(CID2$lnLik, 4),
          get_aic(CID8$lnLik, 5), 
          get_aic(COR8_C$lnLik, 5), 
          get_aic(CLA8_C$lnLik, 5), 
          get_aic(COR8_NC$lnLik, 5), 
          get_aic(CLA8_NC$lnLik, 5),
          get_aic(EHE$lnLik, 3),
          get_aic(SEM8$lnLik, 4)
          )
)

# Calculate delta AIC
estimates$Delta_AIC <- get_delta_aic(estimates$AIC)

# Convert to tibble
estimates_tibble <- as_tibble(estimates)

# # Round all columns of the tibble to two digits after the decimal point
# estimates_tibble <- estimates_tibble %>%
#   mutate(across(where(is.numeric), ~ round(., digits = 1)))
# 
# # Print the tibble
# print(estimates_tibble)

kable(estimates_tibble, "html", digits = 2) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))  
```

### Plot tree

```{r}

simmap <- make.simmap(tree, states, model="SYM", nsim=1)
cols<-setNames(c("#000000","#E65100"), c("0","1"))

# png("Figs/Phasmatodea.png")
# plot(simmap, cols, type='fan', pts=F, ftype="off",lwd=5, outline=F)
# dev.off()

pdf("Figs/Phasmatodea.pdf")  # open a PDF device
plot(simmap, cols, type = 'fan', pts = FALSE, ftype = "off", lwd = 5, outline = FALSE)
dev.off()  # close the device
```





