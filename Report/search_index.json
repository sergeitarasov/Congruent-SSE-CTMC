[["index.html", "Report for Simulations using HiClaSSE model 1 Setting-up HiClaSSE", " Report for Simulations using HiClaSSE model Sergei Tarasov 2024-02-29 1 Setting-up HiClaSSE The HiClaSSE model is implemented using the diversitree package framework. To reproduce the examples, you will most likely need to compile the C code for HiClaSSE on your computer yourself. The instruction below works on Mac. Compile the hiclasse_c.c file located in the R/hiclasse/src directory by running this command in your terminal: R CMD SHLIB hiclasse_c.c Next, copy the two files hiclasse_c.o and hiclasse_c.so to the R/hiclasse/ folder. Replace the existing files if necessary. Now you can execute the provided R examples, and they should work. "],["validation-of-hiclasse.html", "2 Validation of HiClaSSE 2.1 BiSSE-ness and HiClaSSE 2.2 BiSSE and HiClaSSE 2.3 HiSSE4 and HiClaSSE4 2.4 Sampling fraction: BiSSE-ness and HiClaSSE", " 2 Validation of HiClaSSE Here, we validate HiClaSSE against available models from diversitree package. ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~ installations and dependencies ---- ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ # source dependencies and install them if they are not source(&#39;R/utils/dependencies.R&#39;) #source(&#39;R-models/my-ClaSSE.R&#39;) # pure R implementation of HiCLaSSE source(&#39;R/hiclasse/HiClaSSE-R.R&#39;) # pure R implementation of HiCLaSSE ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 source(&#39;R/hiclasse/HiClaSSE_cpp.R&#39;) # fast implementation ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE 2.0.1 Make data set.seed(123) # BiSSE pars &lt;- c(1.5, 0.5, .1, .1, 1.2, 1) names(pars) &lt;- diversitree:::default.argnames.bisse() #pars phy &lt;- tree.bisse(pars, max.taxa=100, x0=0) tree &lt;- phy states &lt;- phy$tip.state #states plot(tree) 2.1 BiSSE-ness and HiClaSSE 2.1.1 BiSSE-ness Likelihood ## BiSSEness: lambda0 = 1.2 p0c = 0.7 p0a = 0.1 lambda1 = 2 p1c = 0.6 p1a = 0.4 # lambda0, lambda1, mu0, mu1, q01, q10, p0c, p0a, p1c, p1a pars.bi &lt;-c(lambda0, lambda1, 0.03, 0.04, .5, .6, p0c, p0a, p1c, p1a) #pars.bi lik.bisseness &lt;- make.bisseness(tree, states) bisseness &lt;- lik.bisseness(pars.bi, intermediates=F, root=ROOT.GIVEN, root.p=c(.5, .5)) #bisseness 2.1.2 HiClaSSE2 Likelihood Make model Args &lt;- list( Nstates = 2L, y = list( c(0,0, 1,0), c(0,0, 0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(2) #args$pars Parameter mapping lam000 = lambda0 * (1-p0c) lam001 = lambda0 * p0c*p0a lam011 = lambda0 * p0c*(1-p0a) lam100 = lambda1 * p1c*(1-p1a) lam101 = lambda1 * p1c*p1a lam111 = lambda1 * (1-p1c) pars.hi &lt;- c(lam000,lam001,lam011, lam100,lam101,lam111, 0.03, 0.04, .5, .6) names(pars.hi) &lt;- args$pars print(pars.hi) ## lam000 lam001 lam011 lam100 lam101 lam111 mu0 mu1 q01 q10 ## 0.360 0.084 0.756 0.720 0.480 0.800 0.030 0.040 0.500 0.600 Inference lik.hiclasse &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) ## [1] &quot;Recoding: 0010 -&gt; 0010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0001&quot; hiclasse &lt;- lik.hiclasse(pars.hi, intermediates=F, root=ROOT.GIVEN, root.p=c(.5, .5), condition.surv=T) 2.1.3 Compare models The likelihood of BiSSE-ness and HiClaSSE2 are the same print(bisseness) ## [1] -149.1999 print(hiclasse) ## [1] -149.1999 print(bisseness-hiclasse) ## [1] 0 2.2 BiSSE and HiClaSSE 2.2.1 BiSSE ## BiSSEness: lambda0 = 1.2 lambda1 = 2 # lambda0, lambda1, mu0, mu1, q01, q10 pars.bi &lt;-c(lambda0, lambda1, 0.03, 0.04, .5, .6) #pars.bi lik.bisse &lt;- make.bisse(tree, states) bisse &lt;- lik.bisse(pars.bi, intermediates=F, root=ROOT.GIVEN, root.p=c(.5, .5)) bisse ## [1] -150.388 2.2.2 HiClaSSE2 Make model Args &lt;- list( Nstates = 2L, y = list( c(0,0, 1,0), c(0,0, 0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(2) lam000 = lambda0 lam001 = 0 lam011 = 0 lam100 = 0 lam101 = 0 lam111 = lambda1 pars.hi &lt;- c(lam000,lam001,lam011, lam100,lam101,lam111, 0.03, 0.04, 0.5, 0.6) names(pars.hi) &lt;- args$pars print(pars.hi) ## lam000 lam001 lam011 lam100 lam101 lam111 mu0 mu1 q01 q10 ## 1.20 0.00 0.00 0.00 0.00 2.00 0.03 0.04 0.50 0.60 # Inference lik.hiclasse &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) ## [1] &quot;Recoding: 0010 -&gt; 0010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0001&quot; hiclasse &lt;- lik.hiclasse(pars.hi, intermediates=F, root=ROOT.GIVEN, root.p=c(.5, .5), condition.surv=T) 2.2.3 Compare models The likelihood is the same print(bisse) ## [1] -150.388 print(hiclasse) ## [1] -150.388 print(bisse-hiclasse) ## [1] -2.842171e-14 2.3 HiSSE4 and HiClaSSE4 2.3.1 HiClaSSE4 s1 &lt;- 0.6 s2 &lt;- 0.3 sam.fr4 = list( c(1-s1, 1-s1, 1-s2, 1-s2, s1, s1, 0, 0), c(1-s1, 1-s1, 1-s2, 1-s2, 0, 0, s2, s2) ) Args &lt;- list( Nstates = 4L, y = sam.fr4) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(4) #args #args$pars length(args$pars) ## [1] 56 pars.hc &lt;- c(1:56) pars.hc[41:56] &lt;- c(1:16) names(pars.hc) &lt;- args$pars pars.hc[0:40] &lt;- 0 pars.hc[&#39;lam000&#39;] &lt;- 1 pars.hc[&#39;lam111&#39;] &lt;- 2 pars.hc[&#39;lam222&#39;] &lt;- 3 pars.hc[&#39;lam333&#39;] &lt;- 4 pars.hc &lt;- pars.hc/1000 pars.hc ## lam000 lam001 lam002 lam003 lam011 lam012 lam013 lam022 lam023 lam033 lam100 lam101 lam102 lam103 lam111 lam112 lam113 lam122 lam123 ## 0.001 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.002 0.000 0.000 0.000 0.000 ## lam133 lam200 lam201 lam202 lam203 lam211 lam212 lam213 lam222 lam223 lam233 lam300 lam301 lam302 lam303 lam311 lam312 lam313 lam322 ## 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.003 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 ## lam323 lam333 mu0 mu1 mu2 mu3 q01 q02 q03 q10 q12 q13 q20 q21 q23 q30 q31 q32 ## 0.000 0.004 0.001 0.002 0.003 0.004 0.005 0.006 0.007 0.008 0.009 0.010 0.011 0.012 0.013 0.014 0.015 0.016 #pars_to_arrays(pars.hc, 4) #states&lt;- mapvalues(phy$tip.state, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 0, 1, 1) ) lik.hiclasse4 &lt;- make.HiClasse_cpp(phy, states, sampling.f=NULL, strict=F, control=list(backend = &quot;gslode&quot;), newArgs) ## [1] &quot;Recoding: 0010 -&gt; 0.40.40.70.70.60.600&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.40.70.7000.30.3&quot; hiclasse4 &lt;- lik.hiclasse4(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=rep(1/4, 4), condition.surv=T) #hiclasse4 2.3.2 HiSSE4 pars.reoder &lt;- pars_to_arrays(pars.hc, 4) v=c(1,3, 2,4) pars.reoder &lt;-reoder_pars(pars.reoder, v) #pars.reoder Q_hisse &lt;- TransMatMakerHiSSE(hidden.traits=1) qs &lt;- extract_off_diagonal(t(pars.reoder$Q)) mu &lt;- pars.reoder$mu lam &lt;- c(0.001, 0.003, 0.002, 0.004) div.pars &lt;- convert2ratesHisse(lam, mu) pars.hisse4 &lt;- c(div.pars$turnover, div.pars$eps, qs) #states&lt;- mapvalues(phy$tip.state, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 0, 1, 1) ) dat &lt;- data.frame(names(phy$tip.state), states) root &lt;- rep(1/4, 4) hisse.func &lt;- makeHiSSELikelihood(phy = phy, data = dat, hidden.states = 1, ode.eps=0, root.p=root, f=c(s1,s2)) hisse.func_lik &lt;- hisse.func$log.lik pars.hisse4 &lt;- setNames(pars.hisse4, names(hisse.func$pars)) lik.hisse &lt;- hisse.func_lik(pars.hisse4) #lik.hisse 2.3.3 Compare models The likelihood is the same print(lik.hisse) ## [1] -786.9318 print(hiclasse4) ## [1] -786.9318 print(lik.hisse-hiclasse4) ## [1] 2.128028e-05 2.4 Sampling fraction: BiSSE-ness and HiClaSSE 2.4.1 BiSSE-ness Likelihood ## BiSSEness: lambda0 = 1.2 p0c = 0.7 p0a = 0.1 lambda1 = 2 p1c = 0.6 p1a = 0.4 # lambda0, lambda1, mu0, mu1, q01, q10, p0c, p0a, p1c, p1a pars.bi &lt;-c(lambda0, lambda1, 0.03, 0.04, .5, .6, p0c, p0a, p1c, p1a) #pars.bi lik.bisseness &lt;- make.bisseness(tree, states, sampling.f=c(0.3, 0.6)) #lik.bisseness &lt;- make.bisseness(tree, states, sampling.f=NULL) bisseness &lt;- lik.bisseness(pars.bi, intermediates=F, root=ROOT.GIVEN, root.p=c(.5, .5)) #bisseness 2.4.2 HiClaSSE2 Likelihood Make model Args &lt;- list( Nstates = 2L, y = list( c(1-0.3,1-0.6, 0.3,0), c(1-0.3,1-0.6, 0,0.6) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(2) #args$pars Parameter mapping lam000 = lambda0 * (1-p0c) lam001 = lambda0 * p0c*p0a lam011 = lambda0 * p0c*(1-p0a) lam100 = lambda1 * p1c*(1-p1a) lam101 = lambda1 * p1c*p1a lam111 = lambda1 * (1-p1c) pars.hi &lt;- c(lam000,lam001,lam011, lam100,lam101,lam111, 0.03, 0.04, .5, .6) names(pars.hi) &lt;- args$pars #print(pars.hi) Inference lik.hiclasse &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) ## [1] &quot;Recoding: 0010 -&gt; 0.70.40.30&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.70.400.6&quot; hiclasse &lt;- lik.hiclasse(pars.hi, intermediates=F, root=ROOT.GIVEN, root.p=c(.5, .5), condition.surv=T) 2.4.3 Compare models The likelihood of BiSSE-ness and HiClaSSE2 are the same print(bisseness) ## [1] -157.0841 print(hiclasse) ## [1] -157.0841 print(bisseness-hiclasse) ## [1] 0 "],["misse-congruence.html", "3 MiSSE Congruence 3.1 SET-UP Q matrix for inference 3.2 MiSSE-2 3.3 MiSSE-3 Congruent 3.4 MiSSE-3 Congruent, Inferred Pars 3.5 MiSSE-3 Non-congruent 3.6 Another Non-congruent Models 3.7 Zero Extinction 3.8 Results", " 3 MiSSE Congruence This example, drawn from Eq. 2 in the main text, demonstrates that the MiSSE2 model with two states (M1) is congruent with MiSSE3 (M2), but is not congruent with MiSSE3 (M3) that violates lumpability. ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~ installations and dependencies ---- ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ # source dependencies and install them if they are not source(&#39;R/utils/dependencies.R&#39;) #source(&#39;R-models/my-ClaSSE.R&#39;) # pure R implementation of HiCLaSSE source(&#39;R/hiclasse/HiClaSSE-R.R&#39;) # pure R implementation of HiCLaSSE ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 source(&#39;R/hiclasse/HiClaSSE_cpp.R&#39;) # fast implementation ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE Read in data: NSIM = 10 phy &lt;- readRDS(file=&#39;R/data/phy_CID4.RDS&#39;) 3.1 SET-UP Q matrix for inference Q3 &lt;- make_Qcol(4, c(0.01, 0.01, 0.01, 0)) Q3[1,3] &lt;- Q3[2,1] &lt;- Q3[3,2] &lt;- 0 Q3[4,] &lt;- Q3[4,] &lt;- rep(0, 4) v=c(1,3,2) Q3[v,v] ## [,1] [,2] [,3] ## [1,] -0.02 0.00 0.01 ## [2,] 0.01 -0.02 0.00 ## [3,] 0.00 0.01 -0.02 diag(Q3) &lt;- NA Q3 ## [,1] [,2] [,3] [,4] ## [1,] NA 0.01 0.00 0 ## [2,] 0.00 NA 0.01 0 ## [3,] 0.01 0.00 NA 0 ## [4,] 0.00 0.00 0.00 NA 3.2 MiSSE-2 # this is character coding at tips. It sets MiSSE model Args &lt;- list( Nstates = 2L, y = list( c(0,0, 1,1), c(0,0, 1,1) )) newArgs &lt;- makeArgs(Args) printArgsGlobal() ## [1] &quot;MY_Nstates:&quot; ## [1] 2 ## [1] &quot;matrix_times_2:&quot; ## [,1] [,2] ## [1,] 2 1 ## [2,] 1 2 ## [1] &quot;matrix_times_half:&quot; ## [,1] [,2] ## [1,] 1.0 0.5 ## [2,] 0.5 1.0 ## [1] &quot;flat_vec:&quot; ## [1] 1 1 args &lt;- argnames_HiClaSSE(2) #args args$pars ## [1] &quot;lam000&quot; &quot;lam001&quot; &quot;lam011&quot; &quot;lam100&quot; &quot;lam101&quot; &quot;lam111&quot; &quot;mu0&quot; &quot;mu1&quot; &quot;q01&quot; &quot;q10&quot; #length(args$pars) #Q3 pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.05 pars.hc[&#39;lam111&#39;] &lt;- 0.02 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;-0.1 pars.hc[&#39;q01&#39;] &lt;- Q3[1,2] pars.hc[&#39;q10&#39;] &lt;- Q3[3,1] pars.hc ## lam000 lam001 lam011 lam100 lam101 lam111 mu0 mu1 q01 q10 ## 0.05 0.00 0.00 0.00 0.00 0.02 0.10 0.10 0.01 0.01 pars_to_arrays(pars.hc, 2) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] ## [1,] 0.05 0 ## [2,] 0.00 0 ## ## $lam.tensor$`2` ## [,1] [,2] ## [1,] 0 0.00 ## [2,] 0 0.02 ## ## ## $mu ## mu0 mu1 ## 0.1 0.1 ## ## $Q ## [,1] [,2] ## [1,] -0.01 0.01 ## [2,] 0.01 -0.01 args$arrays ## $lam.tensor ## $lam.tensor[[1]] ## [,1] [,2] ## [1,] &quot;lam000&quot; &quot;lam001&quot; ## [2,] &quot;0&quot; &quot;lam011&quot; ## ## $lam.tensor[[2]] ## [,1] [,2] ## [1,] &quot;lam100&quot; &quot;lam101&quot; ## [2,] &quot;0&quot; &quot;lam111&quot; ## ## ## $mu ## [1] &quot;mu0&quot; &quot;mu1&quot; ## ## $Q ## [,1] [,2] ## [1,] &quot;0&quot; &quot;q01&quot; ## [2,] &quot;q10&quot; &quot;0&quot; Run inference Misse2 &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/2, 2) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, lam001~0, lam011~0, lam100~0, lam101~0, mu0 ~ mu1, q01 ~ q10) arg.const &lt;- argnames(lik.const) starting.point &lt;- pars.hc[arg.const] Misse2[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0011&quot; ## [1] &quot;Recoding: 0001 -&gt; 0011&quot; Some helper function to assess the inference parameters get_item(Misse2, &#39;lnLik&#39;) ## [1] -388.2559 -369.0999 -359.5762 -364.5667 -381.8074 -353.8319 -374.0264 -374.2723 -365.3551 -353.5485 pars_to_arrays(Misse2[[1]]$par.full, 2) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] ## [1,] 4.851662e-08 0 ## [2,] 0.000000e+00 0 ## ## $lam.tensor$`2` ## [,1] [,2] ## [1,] 0 0.00000000 ## [2,] 0 0.05826839 ## ## ## $mu ## mu0 mu1 ## 2.413234e-07 2.413234e-07 ## ## $Q ## [,1] [,2] ## [1,] -0.008239823 0.008239823 ## [2,] 0.008239823 -0.008239823 3.3 MiSSE-3 Congruent Args &lt;- list( Nstates = 3L, y = list( c(0,0,0, 1,1,1), c(0,0,0, 1,1,1) )) newArgs &lt;- makeArgs(Args) printArgsGlobal() ## [1] &quot;MY_Nstates:&quot; ## [1] 3 ## [1] &quot;matrix_times_2:&quot; ## [,1] [,2] [,3] ## [1,] 2 1 1 ## [2,] 1 2 1 ## [3,] 1 1 2 ## [1] &quot;matrix_times_half:&quot; ## [,1] [,2] [,3] ## [1,] 1.0 0.5 0.5 ## [2,] 0.5 1.0 0.5 ## [3,] 0.5 0.5 1.0 ## [1] &quot;flat_vec:&quot; ## [1] 1 1 1 args &lt;- argnames_HiClaSSE(3) args ## $pars ## [1] &quot;lam000&quot; &quot;lam001&quot; &quot;lam002&quot; &quot;lam011&quot; &quot;lam012&quot; &quot;lam022&quot; &quot;lam100&quot; &quot;lam101&quot; &quot;lam102&quot; &quot;lam111&quot; &quot;lam112&quot; &quot;lam122&quot; &quot;lam200&quot; &quot;lam201&quot; &quot;lam202&quot; ## [16] &quot;lam211&quot; &quot;lam212&quot; &quot;lam222&quot; &quot;mu0&quot; &quot;mu1&quot; &quot;mu2&quot; &quot;q01&quot; &quot;q02&quot; &quot;q10&quot; &quot;q12&quot; &quot;q20&quot; &quot;q21&quot; ## ## $arrays ## $arrays$lam.tensor ## $arrays$lam.tensor[[1]] ## [,1] [,2] [,3] ## [1,] &quot;lam000&quot; &quot;lam001&quot; &quot;lam002&quot; ## [2,] &quot;0&quot; &quot;lam011&quot; &quot;lam012&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam022&quot; ## ## $arrays$lam.tensor[[2]] ## [,1] [,2] [,3] ## [1,] &quot;lam100&quot; &quot;lam101&quot; &quot;lam102&quot; ## [2,] &quot;0&quot; &quot;lam111&quot; &quot;lam112&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam122&quot; ## ## $arrays$lam.tensor[[3]] ## [,1] [,2] [,3] ## [1,] &quot;lam200&quot; &quot;lam201&quot; &quot;lam202&quot; ## [2,] &quot;0&quot; &quot;lam211&quot; &quot;lam212&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam222&quot; ## ## ## $arrays$mu ## [1] &quot;mu0&quot; &quot;mu1&quot; &quot;mu2&quot; ## ## $arrays$Q ## [,1] [,2] [,3] ## [1,] &quot;0&quot; &quot;q01&quot; &quot;q02&quot; ## [2,] &quot;q10&quot; &quot;0&quot; &quot;q12&quot; ## [3,] &quot;q20&quot; &quot;q21&quot; &quot;0&quot; args$pars ## [1] &quot;lam000&quot; &quot;lam001&quot; &quot;lam002&quot; &quot;lam011&quot; &quot;lam012&quot; &quot;lam022&quot; &quot;lam100&quot; &quot;lam101&quot; &quot;lam102&quot; &quot;lam111&quot; &quot;lam112&quot; &quot;lam122&quot; &quot;lam200&quot; &quot;lam201&quot; &quot;lam202&quot; ## [16] &quot;lam211&quot; &quot;lam212&quot; &quot;lam222&quot; &quot;mu0&quot; &quot;mu1&quot; &quot;mu2&quot; &quot;q01&quot; &quot;q02&quot; &quot;q10&quot; &quot;q12&quot; &quot;q20&quot; &quot;q21&quot; length(args$pars) ## [1] 27 Q30 &lt;- Q3 Q30 &lt;- Q30[-4,-4] Q30[2,3] &lt;- 0.01 Q30[2,1] &lt;- 0.01 diag(Q30) &lt;- 0 Q30 ## [,1] [,2] [,3] ## [1,] 0.00 0.01 0.00 ## [2,] 0.01 0.00 0.01 ## [3,] 0.01 0.00 0.00 pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.05 pars.hc[&#39;lam111&#39;] &lt;- 0.02 pars.hc[&#39;lam222&#39;] &lt;- 0.02 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;-pars.hc[&#39;mu2&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q30) pars.hc[22:27] &lt;- qs pars.hc ## lam000 lam001 lam002 lam011 lam012 lam022 lam100 lam101 lam102 lam111 lam112 lam122 lam200 lam201 lam202 lam211 lam212 lam222 mu0 ## 0.05 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.02 0.10 ## mu1 mu2 q01 q02 q10 q12 q20 q21 ## 0.10 0.10 0.01 0.00 0.01 0.01 0.01 0.00 pars_to_arrays(pars.hc, 3) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] ## [1,] 0.05 0 0 ## [2,] 0.00 0 0 ## [3,] 0.00 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] ## [1,] 0 0.00 0 ## [2,] 0 0.02 0 ## [3,] 0 0.00 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] ## [1,] 0 0 0.00 ## [2,] 0 0 0.00 ## [3,] 0 0 0.02 ## ## ## $mu ## mu0 mu1 mu2 ## 0.1 0.1 0.1 ## ## $Q ## [,1] [,2] [,3] ## [1,] -0.01 0.01 0.00 ## [2,] 0.01 -0.02 0.01 ## [3,] 0.01 0.00 -0.01 zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- c(q12 ~ q20, q10 ~ q20, q01 ~ q20) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0) f.lams &lt;- c(lam222 ~ lam111) f.list&lt;- c(zero.constr, f.lams, f.mu, f.qs) Run inference Misse3C &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/2, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) starting.point &lt;- pars.hc[arg.const] Misse3C[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; Some helper function to assess the inference parameters get_item(Misse3C, &#39;lnLik&#39;) ## [1] -388.2559 -369.0999 -359.5762 -364.5667 -381.8074 -353.8319 -374.0264 -374.2723 -365.3551 -353.5485 #get_item(Misse2, &#39;lnLik&#39;) pars_to_arrays(Misse3C[[1]]$par.full, 3) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] ## [1,] 4.851662e-08 0 0 ## [2,] 0.000000e+00 0 0 ## [3,] 0.000000e+00 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] ## [1,] 0 0.00000000 0 ## [2,] 0 0.05826839 0 ## [3,] 0 0.00000000 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] ## [1,] 0 0 0.00000000 ## [2,] 0 0 0.00000000 ## [3,] 0 0 0.05826839 ## ## ## $mu ## mu0 mu1 mu2 ## 2.413234e-07 2.413234e-07 2.413234e-07 ## ## $Q ## [,1] [,2] [,3] ## [1,] -0.008239823 0.008239823 0.000000000 ## [2,] 0.008239823 -0.016479646 0.008239823 ## [3,] 0.008239823 0.000000000 -0.008239823 3.4 MiSSE-3 Congruent, Inferred Pars Mapping of parameters between congruent models is deterministic. Here, we derive the parameters directly from MiSSE2 model. Misse3C_pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #--- mi2_est &lt;- get_item(Misse2[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- mi2_est[&#39;lam000&#39;] pars.hc[&#39;lam111&#39;] &lt;- mi2_est[&#39;lam111&#39;] pars.hc[&#39;lam222&#39;] &lt;- mi2_est[&#39;lam111&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;-pars.hc[&#39;mu2&#39;] &lt;- mi2_est[&#39;mu1&#39;] qs &lt;- extract_off_diagonal(Q30) pars.hc[22:27] &lt;- c(mi2_est[&#39;q10&#39;], 0, mi2_est[&#39;q10&#39;], mi2_est[&#39;q10&#39;], mi2_est[&#39;q10&#39;], 0) #pars.hc #pars_to_arrays(pars.hc, 3) #--- tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/2, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) Misse3C_pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; 3.5 MiSSE-3 Non-congruent Args &lt;- list( Nstates = 3L, y = list( c(0,0,0, 1,1,1), c(0,0,0, 1,1,1) )) newArgs &lt;- makeArgs(Args) printArgsGlobal() ## [1] &quot;MY_Nstates:&quot; ## [1] 3 ## [1] &quot;matrix_times_2:&quot; ## [,1] [,2] [,3] ## [1,] 2 1 1 ## [2,] 1 2 1 ## [3,] 1 1 2 ## [1] &quot;matrix_times_half:&quot; ## [,1] [,2] [,3] ## [1,] 1.0 0.5 0.5 ## [2,] 0.5 1.0 0.5 ## [3,] 0.5 0.5 1.0 ## [1] &quot;flat_vec:&quot; ## [1] 1 1 1 args &lt;- argnames_HiClaSSE(3) args ## $pars ## [1] &quot;lam000&quot; &quot;lam001&quot; &quot;lam002&quot; &quot;lam011&quot; &quot;lam012&quot; &quot;lam022&quot; &quot;lam100&quot; &quot;lam101&quot; &quot;lam102&quot; &quot;lam111&quot; &quot;lam112&quot; &quot;lam122&quot; &quot;lam200&quot; &quot;lam201&quot; &quot;lam202&quot; ## [16] &quot;lam211&quot; &quot;lam212&quot; &quot;lam222&quot; &quot;mu0&quot; &quot;mu1&quot; &quot;mu2&quot; &quot;q01&quot; &quot;q02&quot; &quot;q10&quot; &quot;q12&quot; &quot;q20&quot; &quot;q21&quot; ## ## $arrays ## $arrays$lam.tensor ## $arrays$lam.tensor[[1]] ## [,1] [,2] [,3] ## [1,] &quot;lam000&quot; &quot;lam001&quot; &quot;lam002&quot; ## [2,] &quot;0&quot; &quot;lam011&quot; &quot;lam012&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam022&quot; ## ## $arrays$lam.tensor[[2]] ## [,1] [,2] [,3] ## [1,] &quot;lam100&quot; &quot;lam101&quot; &quot;lam102&quot; ## [2,] &quot;0&quot; &quot;lam111&quot; &quot;lam112&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam122&quot; ## ## $arrays$lam.tensor[[3]] ## [,1] [,2] [,3] ## [1,] &quot;lam200&quot; &quot;lam201&quot; &quot;lam202&quot; ## [2,] &quot;0&quot; &quot;lam211&quot; &quot;lam212&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam222&quot; ## ## ## $arrays$mu ## [1] &quot;mu0&quot; &quot;mu1&quot; &quot;mu2&quot; ## ## $arrays$Q ## [,1] [,2] [,3] ## [1,] &quot;0&quot; &quot;q01&quot; &quot;q02&quot; ## [2,] &quot;q10&quot; &quot;0&quot; &quot;q12&quot; ## [3,] &quot;q20&quot; &quot;q21&quot; &quot;0&quot; args$pars ## [1] &quot;lam000&quot; &quot;lam001&quot; &quot;lam002&quot; &quot;lam011&quot; &quot;lam012&quot; &quot;lam022&quot; &quot;lam100&quot; &quot;lam101&quot; &quot;lam102&quot; &quot;lam111&quot; &quot;lam112&quot; &quot;lam122&quot; &quot;lam200&quot; &quot;lam201&quot; &quot;lam202&quot; ## [16] &quot;lam211&quot; &quot;lam212&quot; &quot;lam222&quot; &quot;mu0&quot; &quot;mu1&quot; &quot;mu2&quot; &quot;q01&quot; &quot;q02&quot; &quot;q10&quot; &quot;q12&quot; &quot;q20&quot; &quot;q21&quot; length(args$pars) ## [1] 27 Q30 &lt;- Q3 Q30 &lt;- Q30[-4,-4] Q30[2,3] &lt;- 0.01 diag(Q30) &lt;- 0 Q30 ## [,1] [,2] [,3] ## [1,] 0.00 0.01 0.00 ## [2,] 0.00 0.00 0.01 ## [3,] 0.01 0.00 0.00 pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.05 pars.hc[&#39;lam111&#39;] &lt;- 0.02 pars.hc[&#39;lam222&#39;] &lt;- 0.02 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;-pars.hc[&#39;mu2&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q30) pars.hc[22:27] &lt;- qs pars.hc ## lam000 lam001 lam002 lam011 lam012 lam022 lam100 lam101 lam102 lam111 lam112 lam122 lam200 lam201 lam202 lam211 lam212 lam222 mu0 ## 0.05 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.02 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.02 0.10 ## mu1 mu2 q01 q02 q10 q12 q20 q21 ## 0.10 0.10 0.01 0.00 0.00 0.01 0.01 0.00 pars_to_arrays(pars.hc, 3) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] ## [1,] 0.05 0 0 ## [2,] 0.00 0 0 ## [3,] 0.00 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] ## [1,] 0 0.00 0 ## [2,] 0 0.02 0 ## [3,] 0 0.00 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] ## [1,] 0 0 0.00 ## [2,] 0 0 0.00 ## [3,] 0 0 0.02 ## ## ## $mu ## mu0 mu1 mu2 ## 0.1 0.1 0.1 ## ## $Q ## [,1] [,2] [,3] ## [1,] -0.01 0.01 0.00 ## [2,] 0.00 -0.01 0.01 ## [3,] 0.01 0.00 -0.01 zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- c(q12 ~ q20, q01 ~ q20) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0) f.lams &lt;- c(lam222 ~ lam111) f.list&lt;- c(zero.constr, f.lams, f.mu, f.qs) Inference Misse3 &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/2, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) #res &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) starting.point &lt;- pars.hc[arg.const] Misse3[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; 3.6 Another Non-congruent Models If lumpability does not hold, then shuffling parameters within partition subsets results in different models. Below, M4 is identical to MiSSE4-NonCongruent, and M5 represents another distinct model where ‘lam112’ is set to 0.2. Qnc &lt;- c(0.05, 0, 0.05, 0.05, 0, 0) M4 &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #--- #mi2_est &lt;- get_item(Misse2[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam111&#39;] &lt;- 0.2 pars.hc[&#39;lam222&#39;] &lt;- 0.2 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;-pars.hc[&#39;mu2&#39;] &lt;- 0.001 #qs &lt;- extract_off_diagonal(Q30) pars.hc[22:27] &lt;- Qnc #pars.hc #pars_to_arrays(pars.hc, 3) #--- tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/2, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) M4[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; M5 &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #--- #mi2_est &lt;- get_item(Misse2[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam112&#39;] &lt;- 0.2 pars.hc[&#39;lam222&#39;] &lt;- 0.2 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;-pars.hc[&#39;mu2&#39;] &lt;- 0.001 #qs &lt;- extract_off_diagonal(Q30) pars.hc[22:27] &lt;- Qnc #pars.hc #pars_to_arrays(pars.hc, 3) #--- tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/2, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) M5[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 000111&quot; ## [1] &quot;Recoding: 0001 -&gt; 000111&quot; unlist(M4) ## [1] -461.4407 -413.0295 -392.7123 -403.3131 -448.2163 -381.9687 -427.5845 -435.4708 -405.2969 -381.6042 unlist(M5) ## [1] -463.3620 -414.8086 -394.3445 -404.8322 -450.3726 -383.5439 -429.5115 -437.1792 -407.2266 -383.0326 3.7 Zero Extinction Args &lt;- list( Nstates = 3L, y = list( c(0,0,0, 1,0,0), c(0,0,0, 0,1,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(3) #args #args$pars length(args$pars) ## [1] 27 Qnc &lt;- c(0.05, 0, 0.05, 0.05, 0.05, 0) M4 &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #--- #mi2_est &lt;- get_item(Misse2[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam111&#39;] &lt;- 0.2 pars.hc[&#39;lam222&#39;] &lt;- 0.2 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;-pars.hc[&#39;mu2&#39;] &lt;- 0 #qs &lt;- extract_off_diagonal(Q30) pars.hc[22:27] &lt;- Qnc #pars.hc #pars_to_arrays(pars.hc, 3) #--- tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/2, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) M4[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; M5 &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #--- #mi2_est &lt;- get_item(Misse2[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam100&#39;] &lt;- 0.2 pars.hc[&#39;lam222&#39;] &lt;- 0.2 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;-pars.hc[&#39;mu2&#39;] &lt;- 0 #qs &lt;- extract_off_diagonal(Q30) pars.hc[22:27] &lt;- Qnc #pars.hc #pars_to_arrays(pars.hc, 3) #--- tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/2, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) M5[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 000100&quot; ## [1] &quot;Recoding: 0001 -&gt; 000011&quot; unlist(M4) ## [1] -507.7641 -465.2830 -441.9091 -450.4049 -486.5549 -437.9186 -480.5218 -481.2484 -454.2903 -427.8796 unlist(M5) ## [1] -487.2446 -450.9794 -424.3511 -437.1302 -468.9831 -427.1957 -461.8652 -463.1470 -437.4129 -406.9824 3.8 Results 3.8.1 Likelihood table The likelihood scores of the used models. mi2 = get_item(Misse2, &#39;lnLik&#39;) mi3c = get_item(Misse3C, &#39;lnLik&#39;) mi3c_pars = unlist(Misse3C_pars) mi3 = get_item(Misse3, &#39;lnLik&#39;) misse &lt;- tibble( &quot;N&quot; = c(1:10), &quot;MiSSE2&quot; = mi2, &quot;congruent MiSSE3 (MiSSE2)&quot;=mi3c, &quot;congruent MiSSE3 (pars of MiSSE2)&quot;= mi3c_pars, &quot;Non-congruent MiSSE3&quot; = mi3) kable(misse, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;)) N MiSSE2 congruent MiSSE3 (MiSSE2) congruent MiSSE3 (pars of MiSSE2) Non-congruent MiSSE3 1 -388.2559 -388.2559 -388.2559 -388.1151 2 -369.0999 -369.0999 -369.0999 -368.9913 3 -359.5762 -359.5762 -359.5762 -359.4225 4 -364.5667 -364.5667 -364.5667 -364.4014 5 -381.8074 -381.8074 -381.8074 -381.6955 6 -353.8319 -353.8319 -353.8319 -353.7770 7 -374.0264 -374.0264 -374.0264 -373.8552 8 -374.2723 -374.2723 -374.2723 -373.2421 9 -365.3551 -365.3551 -365.3551 -365.3553 10 -353.5485 -353.5485 -353.5485 -353.1941 3.8.2 Mean absolute error The table and plot below demonstrate that the likelihoods of MiSSE2 and MiSSE3-Congruent are the same; the differences arise solely from numerical integration. In constrast, the differences between MiSSE2 and MiSSE3-NonCongruent are substantial, indicating they are distinct models. d1 =abs(mi2-mi3c) %&gt;% mean() d2 =abs(mi2-mi3c_pars) %&gt;% mean() d3 = abs(mi2-mi3) %&gt;% mean() # Data delta_values &lt;- tibble( Delta = c(&quot;mi2-mi3_Cong&quot;, &quot;mi2-mi3_Cong_pars&quot;, &quot;mi2-mi3_nonCongruent&quot;), Value = c(d1, d2, d3) ) kable(delta_values, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;)) Delta Value mi2-mi3_Cong 0.0000005 mi2-mi3_Cong_pars 0.0000005 mi2-mi3_nonCongruent 0.2291213 # Create the plot ggplot(delta_values, aes(x = Delta, y = Value, label = sprintf(&quot;%.2e&quot;, Value))) + geom_col(fill = c(&quot;blue&quot;, &quot;green&quot;, &quot;red&quot;)) + geom_text(vjust = -0.5, angle = 45) + labs(title = &quot;Comparison of Ln Differences&quot;, x = &quot;Deltas&quot;, y = &quot;Magnitude&quot;) + theme_minimal() 3.8.3 Parameter estimates get_item(Misse2[1], &#39;par&#39;) ## lam000 lam111 mu1 q10 ## 4.851662e-08 5.826839e-02 2.413234e-07 8.239823e-03 get_item(Misse3C[1], &#39;par&#39;) ## lam000 lam111 mu0 q20 ## 4.851662e-08 5.826839e-02 2.413234e-07 8.239823e-03 get_item(Misse3[1], &#39;par&#39;) ## lam000 lam111 mu0 q20 ## 5.836296e-02 7.822481e-07 2.067451e-06 7.587586e-03 pars_to_arrays(Misse2[[1]]$par.full, 2) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] ## [1,] 4.851662e-08 0 ## [2,] 0.000000e+00 0 ## ## $lam.tensor$`2` ## [,1] [,2] ## [1,] 0 0.00000000 ## [2,] 0 0.05826839 ## ## ## $mu ## mu0 mu1 ## 2.413234e-07 2.413234e-07 ## ## $Q ## [,1] [,2] ## [1,] -0.008239823 0.008239823 ## [2,] 0.008239823 -0.008239823 pars_to_arrays(Misse3C[[1]]$par.full, 3) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] ## [1,] 4.851662e-08 0 0 ## [2,] 0.000000e+00 0 0 ## [3,] 0.000000e+00 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] ## [1,] 0 0.00000000 0 ## [2,] 0 0.05826839 0 ## [3,] 0 0.00000000 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] ## [1,] 0 0 0.00000000 ## [2,] 0 0 0.00000000 ## [3,] 0 0 0.05826839 ## ## ## $mu ## mu0 mu1 mu2 ## 2.413234e-07 2.413234e-07 2.413234e-07 ## ## $Q ## [,1] [,2] [,3] ## [1,] -0.008239823 0.008239823 0.000000000 ## [2,] 0.008239823 -0.016479646 0.008239823 ## [3,] 0.008239823 0.000000000 -0.008239823 pars_to_arrays(Misse3[[1]]$par.full, 3) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] ## [1,] 0.05836296 0 0 ## [2,] 0.00000000 0 0 ## [3,] 0.00000000 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] ## [1,] 0 0.000000e+00 0 ## [2,] 0 7.822481e-07 0 ## [3,] 0 0.000000e+00 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] ## [1,] 0 0 0.000000e+00 ## [2,] 0 0 0.000000e+00 ## [3,] 0 0 7.822481e-07 ## ## ## $mu ## mu0 mu1 mu2 ## 2.067451e-06 2.067451e-06 2.067451e-06 ## ## $Q ## [,1] [,2] [,3] ## [1,] -0.007587586 0.007587586 0.000000000 ## [2,] 0.000000000 -0.007587586 0.007587586 ## [3,] 0.007587586 0.000000000 -0.007587586 "],["congruence-between-independent-and-dependent-sses.html", "4 Congruence between independent and dependent SSEs 4.1 Read in data 4.2 Setting-up Q matrices for inference 4.3 Irreducible model 4.4 Inferences using parameters from CID4 4.5 Maximum Likelihood. All models have 4 pars. 4.6 Results", " 4 Congruence between independent and dependent SSEs Model np pars Cong. with CID4 Trait &amp; Div. Speciation Rates CID4 4 2d 1q 1mu – independent decoupled (d) CID8 4 2d 1q 1mu yes independent decoupled (d) COR8-C 4 2d 1q 1mu yes correlated decoupled (d) CLA8-C 4 2c 1q 1mu yes correlated coupled (c) COR8-NC 4 2d 1q 1mu no correlated* decoupled (d) CLA8-NC 4 2c 1q 1mu no correlated coupled* (c) *indicates non-lumpable transition or speciation rates. See also, Fig. referenced and Table S1. ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~ installations and dependencies ---- ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ source(&#39;R/utils/dependencies.R&#39;) source(&#39;R/hiclasse/HiClaSSE-R.R&#39;) # pure R implementation of HiCLaSSE ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 source(&#39;R/hiclasse/HiClaSSE_cpp.R&#39;) # fast implementation ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE 4.1 Read in data NSIM = 10 phy &lt;- readRDS(file=&#39;R/data/phy_CID4.RDS&#39;) 4.2 Setting-up Q matrices for inference 4.2.1 CID4 # trait Q_t &lt;- initQ(c(0,1), c(.1, .1)) # diversification regime Q_r2 &lt;- initQ(c(&#39;A&#39;,&#39;B&#39;), c(.1,.1)) # speciation rates for tracking the order La4 &lt;- diag(c(-0.1,-0.05),2) La4 = La4 %x% diag(1,2) # order according to regimes Q_cid4.r &lt;- amaSMM(Q_r2, Q_t) # order according to trait v=c(1,3, 2,4) Q_cid4.t &lt;- Q_cid4.r[v,v] print(Q_cid4.r) ## A0 A1 B0 B1 ## A0 -0.2 0.1 0.1 0.0 ## A1 0.1 -0.2 0.0 0.1 ## B0 0.1 0.0 -0.2 0.1 ## B1 0.0 0.1 0.1 -0.2 print(La4) ## [,1] [,2] [,3] [,4] ## [1,] -0.1 0.0 0.00 0.00 ## [2,] 0.0 -0.1 0.00 0.00 ## [3,] 0.0 0.0 -0.05 0.00 ## [4,] 0.0 0.0 0.00 -0.05 print(Q_cid4.t) ## A0 B0 A1 B1 ## A0 -0.2 0.1 0.1 0.0 ## B0 0.1 -0.2 0.0 0.1 ## A1 0.1 0.0 -0.2 0.1 ## B1 0.0 0.1 0.1 -0.2 print(La4[v,v]) ## [,1] [,2] [,3] [,4] ## [1,] -0.1 0.00 0.0 0.00 ## [2,] 0.0 -0.05 0.0 0.00 ## [3,] 0.0 0.00 -0.1 0.00 ## [4,] 0.0 0.00 0.0 -0.05 4.2.2 CID8 (congruent to CID4) # diversification regime #Q_r4 &lt;- initQ(c(&#39;a&#39;,&#39;b&#39;, &#39;c&#39;, &#39;d&#39;), c(.01,.01)) Q_r4 &lt;-amaSMM(Q_t, Q_t) colnames(Q_r4) &lt;- rownames(Q_r4) &lt;- c(&#39;a&#39;,&#39;b&#39;, &#39;c&#39;, &#39;d&#39;) # speciation rates for tracking the order La8 &lt;- diag(c(-0.1,-0.05),2) La8 = La8 %x% diag(1,4) # order according to regimes Q_cid8.r &lt;- amaSMM(Q_r4, Q_t) # order according to trait v=c(1,3,5,7, 2,4,6,8) Q_cid8.t &lt;- Q_cid8.r[v,v] print(Q_cid8.r) ## a0 a1 b0 b1 c0 c1 d0 d1 ## a0 -0.3 0.1 0.1 0.0 0.1 0.0 0.0 0.0 ## a1 0.1 -0.3 0.0 0.1 0.0 0.1 0.0 0.0 ## b0 0.1 0.0 -0.3 0.1 0.0 0.0 0.1 0.0 ## b1 0.0 0.1 0.1 -0.3 0.0 0.0 0.0 0.1 ## c0 0.1 0.0 0.0 0.0 -0.3 0.1 0.1 0.0 ## c1 0.0 0.1 0.0 0.0 0.1 -0.3 0.0 0.1 ## d0 0.0 0.0 0.1 0.0 0.1 0.0 -0.3 0.1 ## d1 0.0 0.0 0.0 0.1 0.0 0.1 0.1 -0.3 print(La8) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.1 0.0 0.0 0.0 0.00 0.00 0.00 0.00 ## [2,] 0.0 -0.1 0.0 0.0 0.00 0.00 0.00 0.00 ## [3,] 0.0 0.0 -0.1 0.0 0.00 0.00 0.00 0.00 ## [4,] 0.0 0.0 0.0 -0.1 0.00 0.00 0.00 0.00 ## [5,] 0.0 0.0 0.0 0.0 -0.05 0.00 0.00 0.00 ## [6,] 0.0 0.0 0.0 0.0 0.00 -0.05 0.00 0.00 ## [7,] 0.0 0.0 0.0 0.0 0.00 0.00 -0.05 0.00 ## [8,] 0.0 0.0 0.0 0.0 0.00 0.00 0.00 -0.05 print(Q_cid8.t) ## a0 b0 c0 d0 a1 b1 c1 d1 ## a0 -0.3 0.1 0.1 0.0 0.1 0.0 0.0 0.0 ## b0 0.1 -0.3 0.0 0.1 0.0 0.1 0.0 0.0 ## c0 0.1 0.0 -0.3 0.1 0.0 0.0 0.1 0.0 ## d0 0.0 0.1 0.1 -0.3 0.0 0.0 0.0 0.1 ## a1 0.1 0.0 0.0 0.0 -0.3 0.1 0.1 0.0 ## b1 0.0 0.1 0.0 0.0 0.1 -0.3 0.0 0.1 ## c1 0.0 0.0 0.1 0.0 0.1 0.0 -0.3 0.1 ## d1 0.0 0.0 0.0 0.1 0.0 0.1 0.1 -0.3 print(La8[v,v]) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.1 0.0 0.00 0.00 0.0 0.0 0.00 0.00 ## [2,] 0.0 -0.1 0.00 0.00 0.0 0.0 0.00 0.00 ## [3,] 0.0 0.0 -0.05 0.00 0.0 0.0 0.00 0.00 ## [4,] 0.0 0.0 0.00 -0.05 0.0 0.0 0.00 0.00 ## [5,] 0.0 0.0 0.00 0.00 -0.1 0.0 0.00 0.00 ## [6,] 0.0 0.0 0.00 0.00 0.0 -0.1 0.00 0.00 ## [7,] 0.0 0.0 0.00 0.00 0.0 0.0 -0.05 0.00 ## [8,] 0.0 0.0 0.00 0.00 0.0 0.0 0.00 -0.05 4.2.3 COR8-C (correlated evolution, congruent to CID4) # like CID8 but with correlation Q_cor8_C.t &lt;- Q_cid8.t bl &lt;- matrix(c(0,.1,.1,0),2,2) Q_cor8_C.t[1:2,5:6] &lt;- bl Q_cor8_C.t[3:4,7:8] &lt;- bl Q_cor8_C.t[5:6,1:2] &lt;- bl Q_cor8_C.t[7:8,3:4] &lt;- bl v=c(1,5, 2,6, 3,7, 4,8) Q_cor8_C.r &lt;- Q_cor8_C.t[v,v] print(Q_cor8_C.r) ## a0 a1 b0 b1 c0 c1 d0 d1 ## a0 -0.3 0.0 0.1 0.1 0.1 0.0 0.0 0.0 ## a1 0.0 -0.3 0.1 0.1 0.0 0.1 0.0 0.0 ## b0 0.1 0.1 -0.3 0.0 0.0 0.0 0.1 0.0 ## b1 0.1 0.1 0.0 -0.3 0.0 0.0 0.0 0.1 ## c0 0.1 0.0 0.0 0.0 -0.3 0.0 0.1 0.1 ## c1 0.0 0.1 0.0 0.0 0.0 -0.3 0.1 0.1 ## d0 0.0 0.0 0.1 0.0 0.1 0.1 -0.3 0.0 ## d1 0.0 0.0 0.0 0.1 0.1 0.1 0.0 -0.3 #print(La8) print(Q_cor8_C.t) ## a0 b0 c0 d0 a1 b1 c1 d1 ## a0 -0.3 0.1 0.1 0.0 0.0 0.1 0.0 0.0 ## b0 0.1 -0.3 0.0 0.1 0.1 0.0 0.0 0.0 ## c0 0.1 0.0 -0.3 0.1 0.0 0.0 0.0 0.1 ## d0 0.0 0.1 0.1 -0.3 0.0 0.0 0.1 0.0 ## a1 0.0 0.1 0.0 0.0 -0.3 0.1 0.1 0.0 ## b1 0.1 0.0 0.0 0.0 0.1 -0.3 0.0 0.1 ## c1 0.0 0.0 0.0 0.1 0.1 0.0 -0.3 0.1 ## d1 0.0 0.0 0.1 0.0 0.0 0.1 0.1 -0.3 #print(La8[v,v]) 4.2.4 COR8-NC (Non-correlated evolution, congruent to CID4) # like CID8 but not congruent Q_cor8_NC.t &lt;- Q_cid8.t bl &lt;- matrix(c(0,0,.1,0),2,2) Q_cor8_NC.t[1:2,5:6] &lt;- bl Q_cor8_NC.t[3:4,7:8] &lt;- bl Q_cor8_NC.t[5:6,1:2] &lt;- bl Q_cor8_NC.t[7:8,3:4] &lt;- bl v=c(1,5, 2,6, 3,7, 4,8) Q_cor8_NC.r &lt;- Q_cor8_NC.t[v,v] print(Q_cor8_NC.r) ## a0 a1 b0 b1 c0 c1 d0 d1 ## a0 -0.3 0.0 0.1 0.1 0.1 0.0 0.0 0.0 ## a1 0.0 -0.3 0.1 0.1 0.0 0.1 0.0 0.0 ## b0 0.1 0.0 -0.3 0.0 0.0 0.0 0.1 0.0 ## b1 0.0 0.1 0.0 -0.3 0.0 0.0 0.0 0.1 ## c0 0.1 0.0 0.0 0.0 -0.3 0.0 0.1 0.1 ## c1 0.0 0.1 0.0 0.0 0.0 -0.3 0.1 0.1 ## d0 0.0 0.0 0.1 0.0 0.1 0.0 -0.3 0.0 ## d1 0.0 0.0 0.0 0.1 0.0 0.1 0.0 -0.3 #print(La8) print(Q_cor8_NC.t) ## a0 b0 c0 d0 a1 b1 c1 d1 ## a0 -0.3 0.1 0.1 0.0 0.0 0.1 0.0 0.0 ## b0 0.1 -0.3 0.0 0.1 0.0 0.0 0.0 0.0 ## c0 0.1 0.0 -0.3 0.1 0.0 0.0 0.0 0.1 ## d0 0.0 0.1 0.1 -0.3 0.0 0.0 0.0 0.0 ## a1 0.0 0.1 0.0 0.0 -0.3 0.1 0.1 0.0 ## b1 0.0 0.0 0.0 0.0 0.1 -0.3 0.0 0.1 ## c1 0.0 0.0 0.0 0.1 0.1 0.0 -0.3 0.1 ## d1 0.0 0.0 0.0 0.0 0.0 0.1 0.1 -0.3 #print(La8[v,v]) 4.3 Irreducible model 4.3.1 CID4 (4 pars) Args &lt;- list( Nstates = 4L, y = list( c(0,0,0,0, 1,0,1,0), c(0,0,0,0, 0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(4) #args$arrays #args$pars #length(args$pars) reoder_lambdas(args$arrays, c(1,3, 2,4)) ## $lam.tensor ## $lam.tensor[[1]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;lam000&quot; &quot;lam002&quot; &quot;lam001&quot; &quot;lam003&quot; ## [2,] &quot;0&quot; &quot;lam022&quot; &quot;0&quot; &quot;lam023&quot; ## [3,] &quot;0&quot; &quot;lam012&quot; &quot;lam011&quot; &quot;lam013&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam033&quot; ## ## $lam.tensor[[2]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;lam200&quot; &quot;lam202&quot; &quot;lam201&quot; &quot;lam203&quot; ## [2,] &quot;0&quot; &quot;lam222&quot; &quot;0&quot; &quot;lam223&quot; ## [3,] &quot;0&quot; &quot;lam212&quot; &quot;lam211&quot; &quot;lam213&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam233&quot; ## ## $lam.tensor[[3]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;lam100&quot; &quot;lam102&quot; &quot;lam101&quot; &quot;lam103&quot; ## [2,] &quot;0&quot; &quot;lam122&quot; &quot;0&quot; &quot;lam123&quot; ## [3,] &quot;0&quot; &quot;lam112&quot; &quot;lam111&quot; &quot;lam113&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam133&quot; ## ## $lam.tensor[[4]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;lam300&quot; &quot;lam302&quot; &quot;lam301&quot; &quot;lam303&quot; ## [2,] &quot;0&quot; &quot;lam322&quot; &quot;0&quot; &quot;lam323&quot; ## [3,] &quot;0&quot; &quot;lam312&quot; &quot;lam311&quot; &quot;lam313&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam333&quot; ## ## ## $mu ## [1] &quot;mu0&quot; &quot;mu2&quot; &quot;mu1&quot; &quot;mu3&quot; ## ## $Q ## [,1] [,2] [,3] [,4] ## [1,] &quot;0&quot; &quot;q02&quot; &quot;q01&quot; &quot;q03&quot; ## [2,] &quot;q20&quot; &quot;0&quot; &quot;q21&quot; &quot;q23&quot; ## [3,] &quot;q10&quot; &quot;q12&quot; &quot;0&quot; &quot;q13&quot; ## [4,] &quot;q30&quot; &quot;q32&quot; &quot;q31&quot; &quot;0&quot; pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam111&#39;] &lt;- 0.1 pars.hc[&#39;lam222&#39;] &lt;- 0.05 pars.hc[&#39;lam333&#39;] &lt;- 0.05 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q_cid4.r) qsl=length(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc,4) #args zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- assign_classes_pairwise(Q_cid4.r, args$arrays$Q) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0) f.lams &lt;- c(lam111 ~ lam000, lam333 ~ lam222) f.list&lt;- c(zero.constr, f.qs, f.mu, f.lams) Run inference CID4 &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/4, 1/4, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) starting.point &lt;- pars.hc[arg.const] CID4[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; Some helper functions to assess the inference parameters. get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 pars_to_arrays(CID4[[1]]$par.full, 4) %&gt;% reoder_lambdas(., c(1,3, 2,4)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] ## [1,] 0.05094386 0 0 0 ## [2,] 0.00000000 0 0 0 ## [3,] 0.00000000 0 0 0 ## [4,] 0.00000000 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] ## [1,] 0 0.00000000 0 0 ## [2,] 0 0.05091551 0 0 ## [3,] 0 0.00000000 0 0 ## [4,] 0 0.00000000 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0.00000000 0 ## [2,] 0 0 0.00000000 0 ## [3,] 0 0 0.05094386 0 ## [4,] 0 0 0.00000000 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0 0.00000000 ## [2,] 0 0 0 0.00000000 ## [3,] 0 0 0 0.00000000 ## [4,] 0 0 0 0.05091551 ## ## ## $mu ## mu0 mu2 mu1 mu3 ## 0.0003102256 0.0003102256 0.0003102256 0.0003102256 ## ## $Q ## [,1] [,2] [,3] [,4] ## [1,] -0.015124151 0.007562076 0.007562076 0.000000000 ## [2,] 0.007562076 -0.015124151 0.000000000 0.007562076 ## [3,] 0.007562076 0.000000000 -0.015124151 0.007562076 ## [4,] 0.000000000 0.007562076 0.007562076 -0.015124151 get_item(CID4[1], &#39;par&#39;) ## lam000 lam222 mu0 q01 ## 0.0509438630 0.0509155136 0.0003102256 0.0075620757 4.4 Inferences using parameters from CID4 4.4.1 CID8 (4 pars) Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) args$arrays ## $lam.tensor ## $lam.tensor[[1]] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;lam000&quot; &quot;lam001&quot; &quot;lam002&quot; &quot;lam003&quot; &quot;lam004&quot; &quot;lam005&quot; &quot;lam006&quot; &quot;lam007&quot; ## [2,] &quot;0&quot; &quot;lam011&quot; &quot;lam012&quot; &quot;lam013&quot; &quot;lam014&quot; &quot;lam015&quot; &quot;lam016&quot; &quot;lam017&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam022&quot; &quot;lam023&quot; &quot;lam024&quot; &quot;lam025&quot; &quot;lam026&quot; &quot;lam027&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam033&quot; &quot;lam034&quot; &quot;lam035&quot; &quot;lam036&quot; &quot;lam037&quot; ## [5,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam044&quot; &quot;lam045&quot; &quot;lam046&quot; &quot;lam047&quot; ## [6,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam055&quot; &quot;lam056&quot; &quot;lam057&quot; ## [7,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam066&quot; &quot;lam067&quot; ## [8,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam077&quot; ## ## $lam.tensor[[2]] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;lam100&quot; &quot;lam101&quot; &quot;lam102&quot; &quot;lam103&quot; &quot;lam104&quot; &quot;lam105&quot; &quot;lam106&quot; &quot;lam107&quot; ## [2,] &quot;0&quot; &quot;lam111&quot; &quot;lam112&quot; &quot;lam113&quot; &quot;lam114&quot; &quot;lam115&quot; &quot;lam116&quot; &quot;lam117&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam122&quot; &quot;lam123&quot; &quot;lam124&quot; &quot;lam125&quot; &quot;lam126&quot; &quot;lam127&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam133&quot; &quot;lam134&quot; &quot;lam135&quot; &quot;lam136&quot; &quot;lam137&quot; ## [5,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam144&quot; &quot;lam145&quot; &quot;lam146&quot; &quot;lam147&quot; ## [6,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam155&quot; &quot;lam156&quot; &quot;lam157&quot; ## [7,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam166&quot; &quot;lam167&quot; ## [8,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam177&quot; ## ## $lam.tensor[[3]] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;lam200&quot; &quot;lam201&quot; &quot;lam202&quot; &quot;lam203&quot; &quot;lam204&quot; &quot;lam205&quot; &quot;lam206&quot; &quot;lam207&quot; ## [2,] &quot;0&quot; &quot;lam211&quot; &quot;lam212&quot; &quot;lam213&quot; &quot;lam214&quot; &quot;lam215&quot; &quot;lam216&quot; &quot;lam217&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam222&quot; &quot;lam223&quot; &quot;lam224&quot; &quot;lam225&quot; &quot;lam226&quot; &quot;lam227&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam233&quot; &quot;lam234&quot; &quot;lam235&quot; &quot;lam236&quot; &quot;lam237&quot; ## [5,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam244&quot; &quot;lam245&quot; &quot;lam246&quot; &quot;lam247&quot; ## [6,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam255&quot; &quot;lam256&quot; &quot;lam257&quot; ## [7,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam266&quot; &quot;lam267&quot; ## [8,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam277&quot; ## ## $lam.tensor[[4]] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;lam300&quot; &quot;lam301&quot; &quot;lam302&quot; &quot;lam303&quot; &quot;lam304&quot; &quot;lam305&quot; &quot;lam306&quot; &quot;lam307&quot; ## [2,] &quot;0&quot; &quot;lam311&quot; &quot;lam312&quot; &quot;lam313&quot; &quot;lam314&quot; &quot;lam315&quot; &quot;lam316&quot; &quot;lam317&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam322&quot; &quot;lam323&quot; &quot;lam324&quot; &quot;lam325&quot; &quot;lam326&quot; &quot;lam327&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam333&quot; &quot;lam334&quot; &quot;lam335&quot; &quot;lam336&quot; &quot;lam337&quot; ## [5,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam344&quot; &quot;lam345&quot; &quot;lam346&quot; &quot;lam347&quot; ## [6,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam355&quot; &quot;lam356&quot; &quot;lam357&quot; ## [7,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam366&quot; &quot;lam367&quot; ## [8,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam377&quot; ## ## $lam.tensor[[5]] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;lam400&quot; &quot;lam401&quot; &quot;lam402&quot; &quot;lam403&quot; &quot;lam404&quot; &quot;lam405&quot; &quot;lam406&quot; &quot;lam407&quot; ## [2,] &quot;0&quot; &quot;lam411&quot; &quot;lam412&quot; &quot;lam413&quot; &quot;lam414&quot; &quot;lam415&quot; &quot;lam416&quot; &quot;lam417&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam422&quot; &quot;lam423&quot; &quot;lam424&quot; &quot;lam425&quot; &quot;lam426&quot; &quot;lam427&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam433&quot; &quot;lam434&quot; &quot;lam435&quot; &quot;lam436&quot; &quot;lam437&quot; ## [5,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam444&quot; &quot;lam445&quot; &quot;lam446&quot; &quot;lam447&quot; ## [6,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam455&quot; &quot;lam456&quot; &quot;lam457&quot; ## [7,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam466&quot; &quot;lam467&quot; ## [8,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam477&quot; ## ## $lam.tensor[[6]] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;lam500&quot; &quot;lam501&quot; &quot;lam502&quot; &quot;lam503&quot; &quot;lam504&quot; &quot;lam505&quot; &quot;lam506&quot; &quot;lam507&quot; ## [2,] &quot;0&quot; &quot;lam511&quot; &quot;lam512&quot; &quot;lam513&quot; &quot;lam514&quot; &quot;lam515&quot; &quot;lam516&quot; &quot;lam517&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam522&quot; &quot;lam523&quot; &quot;lam524&quot; &quot;lam525&quot; &quot;lam526&quot; &quot;lam527&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam533&quot; &quot;lam534&quot; &quot;lam535&quot; &quot;lam536&quot; &quot;lam537&quot; ## [5,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam544&quot; &quot;lam545&quot; &quot;lam546&quot; &quot;lam547&quot; ## [6,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam555&quot; &quot;lam556&quot; &quot;lam557&quot; ## [7,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam566&quot; &quot;lam567&quot; ## [8,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam577&quot; ## ## $lam.tensor[[7]] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;lam600&quot; &quot;lam601&quot; &quot;lam602&quot; &quot;lam603&quot; &quot;lam604&quot; &quot;lam605&quot; &quot;lam606&quot; &quot;lam607&quot; ## [2,] &quot;0&quot; &quot;lam611&quot; &quot;lam612&quot; &quot;lam613&quot; &quot;lam614&quot; &quot;lam615&quot; &quot;lam616&quot; &quot;lam617&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam622&quot; &quot;lam623&quot; &quot;lam624&quot; &quot;lam625&quot; &quot;lam626&quot; &quot;lam627&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam633&quot; &quot;lam634&quot; &quot;lam635&quot; &quot;lam636&quot; &quot;lam637&quot; ## [5,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam644&quot; &quot;lam645&quot; &quot;lam646&quot; &quot;lam647&quot; ## [6,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam655&quot; &quot;lam656&quot; &quot;lam657&quot; ## [7,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam666&quot; &quot;lam667&quot; ## [8,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam677&quot; ## ## $lam.tensor[[8]] ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;lam700&quot; &quot;lam701&quot; &quot;lam702&quot; &quot;lam703&quot; &quot;lam704&quot; &quot;lam705&quot; &quot;lam706&quot; &quot;lam707&quot; ## [2,] &quot;0&quot; &quot;lam711&quot; &quot;lam712&quot; &quot;lam713&quot; &quot;lam714&quot; &quot;lam715&quot; &quot;lam716&quot; &quot;lam717&quot; ## [3,] &quot;0&quot; &quot;0&quot; &quot;lam722&quot; &quot;lam723&quot; &quot;lam724&quot; &quot;lam725&quot; &quot;lam726&quot; &quot;lam727&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam733&quot; &quot;lam734&quot; &quot;lam735&quot; &quot;lam736&quot; &quot;lam737&quot; ## [5,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam744&quot; &quot;lam745&quot; &quot;lam746&quot; &quot;lam747&quot; ## [6,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam755&quot; &quot;lam756&quot; &quot;lam757&quot; ## [7,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam766&quot; &quot;lam767&quot; ## [8,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam777&quot; ## ## ## $mu ## [1] &quot;mu0&quot; &quot;mu1&quot; &quot;mu2&quot; &quot;mu3&quot; &quot;mu4&quot; &quot;mu5&quot; &quot;mu6&quot; &quot;mu7&quot; ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] &quot;0&quot; &quot;q01&quot; &quot;q02&quot; &quot;q03&quot; &quot;q04&quot; &quot;q05&quot; &quot;q06&quot; &quot;q07&quot; ## [2,] &quot;q10&quot; &quot;0&quot; &quot;q12&quot; &quot;q13&quot; &quot;q14&quot; &quot;q15&quot; &quot;q16&quot; &quot;q17&quot; ## [3,] &quot;q20&quot; &quot;q21&quot; &quot;0&quot; &quot;q23&quot; &quot;q24&quot; &quot;q25&quot; &quot;q26&quot; &quot;q27&quot; ## [4,] &quot;q30&quot; &quot;q31&quot; &quot;q32&quot; &quot;0&quot; &quot;q34&quot; &quot;q35&quot; &quot;q36&quot; &quot;q37&quot; ## [5,] &quot;q40&quot; &quot;q41&quot; &quot;q42&quot; &quot;q43&quot; &quot;0&quot; &quot;q45&quot; &quot;q46&quot; &quot;q47&quot; ## [6,] &quot;q50&quot; &quot;q51&quot; &quot;q52&quot; &quot;q53&quot; &quot;q54&quot; &quot;0&quot; &quot;q56&quot; &quot;q57&quot; ## [7,] &quot;q60&quot; &quot;q61&quot; &quot;q62&quot; &quot;q63&quot; &quot;q64&quot; &quot;q65&quot; &quot;0&quot; &quot;q67&quot; ## [8,] &quot;q70&quot; &quot;q71&quot; &quot;q72&quot; &quot;q73&quot; &quot;q74&quot; &quot;q75&quot; &quot;q76&quot; &quot;0&quot; #reoder_lambdas(args$arrays, c(1,3,5,7, 2,4,6,8)) Run inference CID8.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam111&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam222&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam333&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam444&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam555&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam666&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam777&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cid8.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc, 8) #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) CID8.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Compare Ln get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 CID8.pars %&gt;% unlist ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 pars_to_arrays(pars.hc, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0.05942176 0 0 0 0 0 0 0 ## [2,] 0.00000000 0 0 0 0 0 0 0 ## [3,] 0.00000000 0 0 0 0 0 0 0 ## [4,] 0.00000000 0 0 0 0 0 0 0 ## [5,] 0.00000000 0 0 0 0 0 0 0 ## [6,] 0.00000000 0 0 0 0 0 0 0 ## [7,] 0.00000000 0 0 0 0 0 0 0 ## [8,] 0.00000000 0 0 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.05942176 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0.00000000 0 0 0 0 0 ## [2,] 0 0 0.00000000 0 0 0 0 0 ## [3,] 0 0 0.08723677 0 0 0 0 0 ## [4,] 0 0 0.00000000 0 0 0 0 0 ## [5,] 0 0 0.00000000 0 0 0 0 0 ## [6,] 0 0 0.00000000 0 0 0 0 0 ## [7,] 0 0 0.00000000 0 0 0 0 0 ## [8,] 0 0 0.00000000 0 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.00000000 0 0 0 0 ## [4,] 0 0 0 0.08723677 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.05942176 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0.00000000 0 0 ## [2,] 0 0 0 0 0 0.00000000 0 0 ## [3,] 0 0 0 0 0 0.00000000 0 0 ## [4,] 0 0 0 0 0 0.00000000 0 0 ## [5,] 0 0 0 0 0 0.00000000 0 0 ## [6,] 0 0 0 0 0 0.05942176 0 0 ## [7,] 0 0 0 0 0 0.00000000 0 0 ## [8,] 0 0 0 0 0 0.00000000 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0.00000000 0 ## [2,] 0 0 0 0 0 0 0.00000000 0 ## [3,] 0 0 0 0 0 0 0.00000000 0 ## [4,] 0 0 0 0 0 0 0.00000000 0 ## [5,] 0 0 0 0 0 0 0.00000000 0 ## [6,] 0 0 0 0 0 0 0.00000000 0 ## [7,] 0 0 0 0 0 0 0.08723677 0 ## [8,] 0 0 0 0 0 0 0.00000000 0 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.00000000 ## [8,] 0 0 0 0 0 0 0 0.08723677 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.03790101 0.01263367 0.01263367 0.00000000 0.01263367 0.00000000 0.00000000 0.00000000 ## [2,] 0.01263367 -0.03790101 0.00000000 0.01263367 0.00000000 0.01263367 0.00000000 0.00000000 ## [3,] 0.01263367 0.00000000 -0.03790101 0.01263367 0.00000000 0.00000000 0.01263367 0.00000000 ## [4,] 0.00000000 0.01263367 0.01263367 -0.03790101 0.00000000 0.00000000 0.00000000 0.01263367 ## [5,] 0.01263367 0.00000000 0.00000000 0.00000000 -0.03790101 0.01263367 0.01263367 0.00000000 ## [6,] 0.00000000 0.01263367 0.00000000 0.00000000 0.01263367 -0.03790101 0.00000000 0.01263367 ## [7,] 0.00000000 0.00000000 0.01263367 0.00000000 0.01263367 0.00000000 -0.03790101 0.01263367 ## [8,] 0.00000000 0.00000000 0.00000000 0.01263367 0.00000000 0.01263367 0.01263367 -0.03790101 4.4.2 COR8-C (4 pars) Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args Run inference COR8_C.pars &lt;- list() i=2 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam111&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam222&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam333&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam444&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam555&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam666&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam777&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cor8_C.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs # pars.hc # pars_to_arrays(pars.hc, 8) #v=c(1,3,5,7, 2,4,6,8) #pars_to_arrays(pars.hc, 8)$Q[v,v] #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) COR8_C.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Compare Ln get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 COR8_C.pars %&gt;% unlist ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 pars_to_arrays(pars.hc, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0.05942176 0 0 0 0 0 0 0 ## [2,] 0.00000000 0 0 0 0 0 0 0 ## [3,] 0.00000000 0 0 0 0 0 0 0 ## [4,] 0.00000000 0 0 0 0 0 0 0 ## [5,] 0.00000000 0 0 0 0 0 0 0 ## [6,] 0.00000000 0 0 0 0 0 0 0 ## [7,] 0.00000000 0 0 0 0 0 0 0 ## [8,] 0.00000000 0 0 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.05942176 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0.00000000 0 0 0 0 0 ## [2,] 0 0 0.00000000 0 0 0 0 0 ## [3,] 0 0 0.08723677 0 0 0 0 0 ## [4,] 0 0 0.00000000 0 0 0 0 0 ## [5,] 0 0 0.00000000 0 0 0 0 0 ## [6,] 0 0 0.00000000 0 0 0 0 0 ## [7,] 0 0 0.00000000 0 0 0 0 0 ## [8,] 0 0 0.00000000 0 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.00000000 0 0 0 0 ## [4,] 0 0 0 0.08723677 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.05942176 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0.00000000 0 0 ## [2,] 0 0 0 0 0 0.00000000 0 0 ## [3,] 0 0 0 0 0 0.00000000 0 0 ## [4,] 0 0 0 0 0 0.00000000 0 0 ## [5,] 0 0 0 0 0 0.00000000 0 0 ## [6,] 0 0 0 0 0 0.05942176 0 0 ## [7,] 0 0 0 0 0 0.00000000 0 0 ## [8,] 0 0 0 0 0 0.00000000 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0.00000000 0 ## [2,] 0 0 0 0 0 0 0.00000000 0 ## [3,] 0 0 0 0 0 0 0.00000000 0 ## [4,] 0 0 0 0 0 0 0.00000000 0 ## [5,] 0 0 0 0 0 0 0.00000000 0 ## [6,] 0 0 0 0 0 0 0.00000000 0 ## [7,] 0 0 0 0 0 0 0.08723677 0 ## [8,] 0 0 0 0 0 0 0.00000000 0 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.00000000 ## [8,] 0 0 0 0 0 0 0 0.08723677 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.03790101 0.01263367 0.01263367 0.00000000 0.00000000 0.01263367 0.00000000 0.00000000 ## [2,] 0.01263367 -0.03790101 0.00000000 0.01263367 0.01263367 0.00000000 0.00000000 0.00000000 ## [3,] 0.01263367 0.00000000 -0.03790101 0.01263367 0.00000000 0.00000000 0.00000000 0.01263367 ## [4,] 0.00000000 0.01263367 0.01263367 -0.03790101 0.00000000 0.00000000 0.01263367 0.00000000 ## [5,] 0.00000000 0.01263367 0.00000000 0.00000000 -0.03790101 0.01263367 0.01263367 0.00000000 ## [6,] 0.01263367 0.00000000 0.00000000 0.00000000 0.01263367 -0.03790101 0.00000000 0.01263367 ## [7,] 0.00000000 0.00000000 0.00000000 0.01263367 0.01263367 0.00000000 -0.03790101 0.01263367 ## [8,] 0.00000000 0.00000000 0.01263367 0.00000000 0.00000000 0.01263367 0.01263367 -0.03790101 4.4.3 COR8-NC (4 pars) Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args Run inference COR8_NC.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam111&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam222&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam333&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam444&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam555&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam666&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam777&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cor8_NC.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs # pars.hc # pars_to_arrays(pars.hc, 8) # v=c(1,3,5,7, 2,4,6,8) # pars_to_arrays(pars.hc, 8)$Q[v,v] #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) COR8_NC.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Some helper function to assess the inference parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 COR8_NC.pars %&gt;% unlist ## [1] -442.1584 -432.3652 -414.2528 -425.1997 -424.8447 -420.8153 -438.9214 -432.1182 -426.2918 -399.7270 pars_to_arrays(pars.hc, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0.05942176 0 0 0 0 0 0 0 ## [2,] 0.00000000 0 0 0 0 0 0 0 ## [3,] 0.00000000 0 0 0 0 0 0 0 ## [4,] 0.00000000 0 0 0 0 0 0 0 ## [5,] 0.00000000 0 0 0 0 0 0 0 ## [6,] 0.00000000 0 0 0 0 0 0 0 ## [7,] 0.00000000 0 0 0 0 0 0 0 ## [8,] 0.00000000 0 0 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.05942176 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0.00000000 0 0 0 0 0 ## [2,] 0 0 0.00000000 0 0 0 0 0 ## [3,] 0 0 0.08723677 0 0 0 0 0 ## [4,] 0 0 0.00000000 0 0 0 0 0 ## [5,] 0 0 0.00000000 0 0 0 0 0 ## [6,] 0 0 0.00000000 0 0 0 0 0 ## [7,] 0 0 0.00000000 0 0 0 0 0 ## [8,] 0 0 0.00000000 0 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.00000000 0 0 0 0 ## [4,] 0 0 0 0.08723677 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.05942176 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0.00000000 0 0 ## [2,] 0 0 0 0 0 0.00000000 0 0 ## [3,] 0 0 0 0 0 0.00000000 0 0 ## [4,] 0 0 0 0 0 0.00000000 0 0 ## [5,] 0 0 0 0 0 0.00000000 0 0 ## [6,] 0 0 0 0 0 0.05942176 0 0 ## [7,] 0 0 0 0 0 0.00000000 0 0 ## [8,] 0 0 0 0 0 0.00000000 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0.00000000 0 ## [2,] 0 0 0 0 0 0 0.00000000 0 ## [3,] 0 0 0 0 0 0 0.00000000 0 ## [4,] 0 0 0 0 0 0 0.00000000 0 ## [5,] 0 0 0 0 0 0 0.00000000 0 ## [6,] 0 0 0 0 0 0 0.00000000 0 ## [7,] 0 0 0 0 0 0 0.08723677 0 ## [8,] 0 0 0 0 0 0 0.00000000 0 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.00000000 ## [8,] 0 0 0 0 0 0 0 0.08723677 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.03790101 0.01263367 0.01263367 0.00000000 0.00000000 0.01263367 0.00000000 0.00000000 ## [2,] 0.01263367 -0.02526734 0.00000000 0.01263367 0.00000000 0.00000000 0.00000000 0.00000000 ## [3,] 0.01263367 0.00000000 -0.03790101 0.01263367 0.00000000 0.00000000 0.00000000 0.01263367 ## [4,] 0.00000000 0.01263367 0.01263367 -0.02526734 0.00000000 0.00000000 0.00000000 0.00000000 ## [5,] 0.00000000 0.01263367 0.00000000 0.00000000 -0.03790101 0.01263367 0.01263367 0.00000000 ## [6,] 0.00000000 0.00000000 0.00000000 0.00000000 0.01263367 -0.02526734 0.00000000 0.01263367 ## [7,] 0.00000000 0.00000000 0.00000000 0.01263367 0.01263367 0.00000000 -0.03790101 0.01263367 ## [8,] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.01263367 0.01263367 -0.02526734 4.4.4 CLA8-C (4 pars) Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args$arrays # reoder_lambdas(args$arrays, c(1,3,5,7, 2,4,6,8)) Run inference CLA8_C.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars # pars.hc[&#39;lam000&#39;] &lt;- est[&#39;lam000&#39;] # pars.hc[&#39;lam111&#39;] &lt;- est[&#39;lam000&#39;] # pars.hc[&#39;lam222&#39;] &lt;- est[&#39;lam000&#39;] # pars.hc[&#39;lam333&#39;] &lt;- est[&#39;lam000&#39;] # pars.hc[&#39;lam444&#39;] &lt;- est[&#39;lam222&#39;] # pars.hc[&#39;lam555&#39;] &lt;- est[&#39;lam222&#39;] # pars.hc[&#39;lam666&#39;] &lt;- est[&#39;lam222&#39;] # pars.hc[&#39;lam777&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam022&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam133&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam202&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam311&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam466&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam577&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam646&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam757&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cor8_C.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs # pars.hc # pars_to_arrays(pars.hc, 8) # v=c(1,3,5,7, 2,4,6,8) # pars_to_arrays(pars.hc, 8)$Q[v,v] #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) CLA8_C.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Some helper function to assess the inference parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 CLA8_C.pars %&gt;% unlist ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 pars_to_arrays(pars.hc, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.05942176 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.05942176 0 0 0 0 0 0 ## [2,] 0 0.00000000 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.00000000 0 0 0 0 ## [4,] 0 0 0 0.08723677 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.08723677 0 0 0 0 ## [4,] 0 0 0 0.00000000 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0.00000000 0 0 ## [2,] 0 0 0 0 0 0.00000000 0 0 ## [3,] 0 0 0 0 0 0.00000000 0 0 ## [4,] 0 0 0 0 0 0.00000000 0 0 ## [5,] 0 0 0 0 0 0.00000000 0 0 ## [6,] 0 0 0 0 0 0.05942176 0 0 ## [7,] 0 0 0 0 0 0.00000000 0 0 ## [8,] 0 0 0 0 0 0.00000000 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.05942176 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.00000000 ## [8,] 0 0 0 0 0 0 0 0.08723677 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.08723677 ## [8,] 0 0 0 0 0 0 0 0.00000000 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.03790101 0.01263367 0.01263367 0.00000000 0.00000000 0.01263367 0.00000000 0.00000000 ## [2,] 0.01263367 -0.03790101 0.00000000 0.01263367 0.01263367 0.00000000 0.00000000 0.00000000 ## [3,] 0.01263367 0.00000000 -0.03790101 0.01263367 0.00000000 0.00000000 0.00000000 0.01263367 ## [4,] 0.00000000 0.01263367 0.01263367 -0.03790101 0.00000000 0.00000000 0.01263367 0.00000000 ## [5,] 0.00000000 0.01263367 0.00000000 0.00000000 -0.03790101 0.01263367 0.01263367 0.00000000 ## [6,] 0.01263367 0.00000000 0.00000000 0.00000000 0.01263367 -0.03790101 0.00000000 0.01263367 ## [7,] 0.00000000 0.00000000 0.00000000 0.01263367 0.01263367 0.00000000 -0.03790101 0.01263367 ## [8,] 0.00000000 0.00000000 0.01263367 0.00000000 0.00000000 0.01263367 0.01263367 -0.03790101 4.4.5 CLA8-NC (4 pars) Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args$arrays #v=c(1,3,5,7, 2,4,6,8) #reoder_lambdas(args$arrays, c(1,3,5,7, 2,4,6,8)) Run inference CLA8_NC.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars # lam004, lam116, lam422 violate lumpability pars.hc[&#39;lam004&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam116&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam202&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam311&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam422&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam577&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam646&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam757&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cor8_C.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs # pars.hc # pars_to_arrays(pars.hc, 8) # v=c(1,3,5,7, 2,4,6,8) # pars_to_arrays(pars.hc, 8)$Q[v,v] #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) CLA8_NC.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Some helper function to assess the inference parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 CLA8_NC.pars %&gt;% unlist ## [1] -432.3801 -423.9786 -407.2375 -416.6835 -427.4961 -411.1675 -428.8506 -435.2936 -416.6131 -396.3307 pars_to_arrays(pars.hc, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0.05942176 0 0 0 0 0 ## [2,] 0 0 0.00000000 0 0 0 0 0 ## [3,] 0 0 0.00000000 0 0 0 0 0 ## [4,] 0 0 0.00000000 0 0 0 0 0 ## [5,] 0 0 0.00000000 0 0 0 0 0 ## [6,] 0 0 0.00000000 0 0 0 0 0 ## [7,] 0 0 0.00000000 0 0 0 0 0 ## [8,] 0 0 0.00000000 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.05942176 0 0 0 0 0 0 ## [2,] 0 0.00000000 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.08723677 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.08723677 0 0 0 0 ## [4,] 0 0 0 0.00000000 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.00000000 0 0 0 0 ## [4,] 0 0 0 0.00000000 0 0 0 0 ## [5,] 0 0 0 0.05942176 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.05942176 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.00000000 ## [8,] 0 0 0 0 0 0 0 0.08723677 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.08723677 ## [8,] 0 0 0 0 0 0 0 0.00000000 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 0.007294742 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.03790101 0.01263367 0.01263367 0.00000000 0.00000000 0.01263367 0.00000000 0.00000000 ## [2,] 0.01263367 -0.03790101 0.00000000 0.01263367 0.01263367 0.00000000 0.00000000 0.00000000 ## [3,] 0.01263367 0.00000000 -0.03790101 0.01263367 0.00000000 0.00000000 0.00000000 0.01263367 ## [4,] 0.00000000 0.01263367 0.01263367 -0.03790101 0.00000000 0.00000000 0.01263367 0.00000000 ## [5,] 0.00000000 0.01263367 0.00000000 0.00000000 -0.03790101 0.01263367 0.01263367 0.00000000 ## [6,] 0.01263367 0.00000000 0.00000000 0.00000000 0.01263367 -0.03790101 0.00000000 0.01263367 ## [7,] 0.00000000 0.00000000 0.00000000 0.01263367 0.01263367 0.00000000 -0.03790101 0.01263367 ## [8,] 0.00000000 0.00000000 0.01263367 0.00000000 0.00000000 0.01263367 0.01263367 -0.03790101 4.5 Maximum Likelihood. All models have 4 pars. 4.5.1 CID8 Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args$arrays #args$pars #length(args$pars) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam111&#39;] &lt;- 0.1 pars.hc[&#39;lam222&#39;] &lt;- 0.1 pars.hc[&#39;lam333&#39;] &lt;- 0.1 pars.hc[&#39;lam444&#39;] &lt;- 0.05 pars.hc[&#39;lam555&#39;] &lt;- 0.05 pars.hc[&#39;lam666&#39;] &lt;- 0.05 pars.hc[&#39;lam777&#39;] &lt;- 0.05 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q_cid8.r) qsl=length(qs) #unique(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc,8) #args zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- assign_classes_pairwise(Q_cid8.r, args$arrays$Q) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0) f.lams &lt;- c(lam111 ~ lam000, lam222 ~ lam000, lam333 ~ lam000, lam555 ~ lam444, lam666 ~ lam444, lam777 ~ lam444) f.list&lt;- c(zero.constr, f.qs, f.mu, f.lams) Run inference CID8 &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) starting.point &lt;- pars.hc[arg.const] # starting.point &lt;- get_item(CID4[i], &#39;par&#39;) # names(starting.point) &lt;- c(&#39;lam444&#39;, &#39;lam000&#39;, &#39;mu0&#39;, &#39;q01&#39;, &#39;q02&#39;) # starting.point[&#39;q01&#39;] &lt;- starting.point[&#39;q02&#39;]/2 CID8[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Assessing the inferred parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 get_item(CID8, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 get_item(CID8[1], &#39;par&#39;) ## lam000 lam444 mu0 q01 ## 0.0509438630 0.0509155136 0.0003102256 0.0075620757 get_item(CID4[1], &#39;par&#39;) ## lam000 lam222 mu0 q01 ## 0.0509438630 0.0509155136 0.0003102256 0.0075620757 #pars_to_arrays(CID8[[1]]$par.full, 8) pars_to_arrays(CID8[[1]]$par.full, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0.05094386 0 0 0 0 0 0 0 ## [2,] 0.00000000 0 0 0 0 0 0 0 ## [3,] 0.00000000 0 0 0 0 0 0 0 ## [4,] 0.00000000 0 0 0 0 0 0 0 ## [5,] 0.00000000 0 0 0 0 0 0 0 ## [6,] 0.00000000 0 0 0 0 0 0 0 ## [7,] 0.00000000 0 0 0 0 0 0 0 ## [8,] 0.00000000 0 0 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.05094386 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0.00000000 0 0 0 0 0 ## [2,] 0 0 0.00000000 0 0 0 0 0 ## [3,] 0 0 0.05091551 0 0 0 0 0 ## [4,] 0 0 0.00000000 0 0 0 0 0 ## [5,] 0 0 0.00000000 0 0 0 0 0 ## [6,] 0 0 0.00000000 0 0 0 0 0 ## [7,] 0 0 0.00000000 0 0 0 0 0 ## [8,] 0 0 0.00000000 0 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.00000000 0 0 0 0 ## [4,] 0 0 0 0.05091551 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.05094386 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0.00000000 0 0 ## [2,] 0 0 0 0 0 0.00000000 0 0 ## [3,] 0 0 0 0 0 0.00000000 0 0 ## [4,] 0 0 0 0 0 0.00000000 0 0 ## [5,] 0 0 0 0 0 0.00000000 0 0 ## [6,] 0 0 0 0 0 0.05094386 0 0 ## [7,] 0 0 0 0 0 0.00000000 0 0 ## [8,] 0 0 0 0 0 0.00000000 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0.00000000 0 ## [2,] 0 0 0 0 0 0 0.00000000 0 ## [3,] 0 0 0 0 0 0 0.00000000 0 ## [4,] 0 0 0 0 0 0 0.00000000 0 ## [5,] 0 0 0 0 0 0 0.00000000 0 ## [6,] 0 0 0 0 0 0 0.00000000 0 ## [7,] 0 0 0 0 0 0 0.05091551 0 ## [8,] 0 0 0 0 0 0 0.00000000 0 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.00000000 ## [8,] 0 0 0 0 0 0 0 0.05091551 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.0003102256 0.0003102256 0.0003102256 0.0003102256 0.0003102256 0.0003102256 0.0003102256 0.0003102256 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.022686227 0.007562076 0.007562076 0.000000000 0.007562076 0.000000000 0.000000000 0.000000000 ## [2,] 0.007562076 -0.022686227 0.000000000 0.007562076 0.000000000 0.007562076 0.000000000 0.000000000 ## [3,] 0.007562076 0.000000000 -0.022686227 0.007562076 0.000000000 0.000000000 0.007562076 0.000000000 ## [4,] 0.000000000 0.007562076 0.007562076 -0.022686227 0.000000000 0.000000000 0.000000000 0.007562076 ## [5,] 0.007562076 0.000000000 0.000000000 0.000000000 -0.022686227 0.007562076 0.007562076 0.000000000 ## [6,] 0.000000000 0.007562076 0.000000000 0.000000000 0.007562076 -0.022686227 0.000000000 0.007562076 ## [7,] 0.000000000 0.000000000 0.007562076 0.000000000 0.007562076 0.000000000 -0.022686227 0.007562076 ## [8,] 0.000000000 0.000000000 0.000000000 0.007562076 0.000000000 0.007562076 0.007562076 -0.022686227 4.5.2 COR8-C Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args #args$pars #length(args$pars) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam111&#39;] &lt;- 0.1 pars.hc[&#39;lam222&#39;] &lt;- 0.1 pars.hc[&#39;lam333&#39;] &lt;- 0.1 pars.hc[&#39;lam444&#39;] &lt;- 0.05 pars.hc[&#39;lam555&#39;] &lt;- 0.05 pars.hc[&#39;lam666&#39;] &lt;- 0.05 pars.hc[&#39;lam777&#39;] &lt;- 0.05 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q_cor8_C.r) qsl=length(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc,8) #args zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- assign_classes_pairwise(Q_cor8_C.r, args$arrays$Q) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0) f.lams &lt;- c(lam111 ~ lam000, lam222 ~ lam000, lam333 ~ lam000, lam555 ~ lam444, lam666 ~ lam444, lam777 ~ lam444) f.list&lt;- c(zero.constr, f.qs, f.mu, f.lams) Run inference COR8_C &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) starting.point &lt;- pars.hc[arg.const] # starting.point &lt;- get_item(CID8[i], &#39;par&#39;) # names(starting.point) &lt;- arg.const # starting.point[&#39;q02&#39;] &lt;- get_item(CID8[i], &#39;par&#39;)[&#39;q02&#39;] # starting.point[&#39;q03&#39;] &lt;- get_item(CID8[i], &#39;par&#39;)[&#39;q01&#39;] COR8_C[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Assessing the inferred parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 get_item(CID8, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 get_item(COR8_C, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 get_item(COR8_C[1], &#39;par&#39;) ## lam000 lam444 mu0 q02 ## 0.0509438630 0.0509155136 0.0003102256 0.0075620757 pars_to_arrays(COR8_C[[1]]$par.full, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0.05094386 0 0 0 0 0 0 0 ## [2,] 0.00000000 0 0 0 0 0 0 0 ## [3,] 0.00000000 0 0 0 0 0 0 0 ## [4,] 0.00000000 0 0 0 0 0 0 0 ## [5,] 0.00000000 0 0 0 0 0 0 0 ## [6,] 0.00000000 0 0 0 0 0 0 0 ## [7,] 0.00000000 0 0 0 0 0 0 0 ## [8,] 0.00000000 0 0 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.05094386 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0.00000000 0 0 0 0 0 ## [2,] 0 0 0.00000000 0 0 0 0 0 ## [3,] 0 0 0.05091551 0 0 0 0 0 ## [4,] 0 0 0.00000000 0 0 0 0 0 ## [5,] 0 0 0.00000000 0 0 0 0 0 ## [6,] 0 0 0.00000000 0 0 0 0 0 ## [7,] 0 0 0.00000000 0 0 0 0 0 ## [8,] 0 0 0.00000000 0 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.00000000 0 0 0 0 ## [4,] 0 0 0 0.05091551 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.05094386 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0.00000000 0 0 ## [2,] 0 0 0 0 0 0.00000000 0 0 ## [3,] 0 0 0 0 0 0.00000000 0 0 ## [4,] 0 0 0 0 0 0.00000000 0 0 ## [5,] 0 0 0 0 0 0.00000000 0 0 ## [6,] 0 0 0 0 0 0.05094386 0 0 ## [7,] 0 0 0 0 0 0.00000000 0 0 ## [8,] 0 0 0 0 0 0.00000000 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0.00000000 0 ## [2,] 0 0 0 0 0 0 0.00000000 0 ## [3,] 0 0 0 0 0 0 0.00000000 0 ## [4,] 0 0 0 0 0 0 0.00000000 0 ## [5,] 0 0 0 0 0 0 0.00000000 0 ## [6,] 0 0 0 0 0 0 0.00000000 0 ## [7,] 0 0 0 0 0 0 0.05091551 0 ## [8,] 0 0 0 0 0 0 0.00000000 0 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.00000000 ## [8,] 0 0 0 0 0 0 0 0.05091551 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.0003102256 0.0003102256 0.0003102256 0.0003102256 0.0003102256 0.0003102256 0.0003102256 0.0003102256 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.022686227 0.007562076 0.007562076 0.000000000 0.000000000 0.007562076 0.000000000 0.000000000 ## [2,] 0.007562076 -0.022686227 0.000000000 0.007562076 0.007562076 0.000000000 0.000000000 0.000000000 ## [3,] 0.007562076 0.000000000 -0.022686227 0.007562076 0.000000000 0.000000000 0.000000000 0.007562076 ## [4,] 0.000000000 0.007562076 0.007562076 -0.022686227 0.000000000 0.000000000 0.007562076 0.000000000 ## [5,] 0.000000000 0.007562076 0.000000000 0.000000000 -0.022686227 0.007562076 0.007562076 0.000000000 ## [6,] 0.007562076 0.000000000 0.000000000 0.000000000 0.007562076 -0.022686227 0.000000000 0.007562076 ## [7,] 0.000000000 0.000000000 0.000000000 0.007562076 0.007562076 0.000000000 -0.022686227 0.007562076 ## [8,] 0.000000000 0.000000000 0.007562076 0.000000000 0.000000000 0.007562076 0.007562076 -0.022686227 4.5.3 COR8-NC Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args #args$pars #length(args$pars) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam111&#39;] &lt;- 0.1 pars.hc[&#39;lam222&#39;] &lt;- 0.1 pars.hc[&#39;lam333&#39;] &lt;- 0.1 pars.hc[&#39;lam444&#39;] &lt;- 0.05 pars.hc[&#39;lam555&#39;] &lt;- 0.05 pars.hc[&#39;lam666&#39;] &lt;- 0.05 pars.hc[&#39;lam777&#39;] &lt;- 0.05 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q_cor8_NC.r) qsl=length(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc,8) #args zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- assign_classes_pairwise(Q_cor8_NC.r, args$arrays$Q) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0) f.lams &lt;- c(lam111 ~ lam000, lam222 ~ lam000, lam333 ~ lam000, lam555 ~ lam444, lam666 ~ lam444, lam777 ~ lam444) f.list&lt;- c(zero.constr, f.qs, f.mu, f.lams) Run inference COR8_NC &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) # starting.point &lt;- pars.hc[arg.const] starting.point &lt;- get_item(COR8_C[i], &#39;par&#39;) COR8_NC[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Assessing the inferred parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 get_item(CID8, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 get_item(COR8_NC, &#39;lnLik&#39;) ## [1] -439.3721 -428.0217 -411.3027 -421.3187 -422.2212 -416.0885 -435.6355 -428.1737 -422.4050 -398.2370 get_item(CID8[1], &#39;par&#39;) ## lam000 lam444 mu0 q01 ## 0.0509438630 0.0509155136 0.0003102256 0.0075620757 pars_to_arrays(COR8_NC[[1]]$par.full, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0.06507655 0 0 0 0 0 0 0 ## [2,] 0.00000000 0 0 0 0 0 0 0 ## [3,] 0.00000000 0 0 0 0 0 0 0 ## [4,] 0.00000000 0 0 0 0 0 0 0 ## [5,] 0.00000000 0 0 0 0 0 0 0 ## [6,] 0.00000000 0 0 0 0 0 0 0 ## [7,] 0.00000000 0 0 0 0 0 0 0 ## [8,] 0.00000000 0 0 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.06507655 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0.000000e+00 0 0 0 0 0 ## [2,] 0 0 0.000000e+00 0 0 0 0 0 ## [3,] 0 0 1.009869e-06 0 0 0 0 0 ## [4,] 0 0 0.000000e+00 0 0 0 0 0 ## [5,] 0 0 0.000000e+00 0 0 0 0 0 ## [6,] 0 0 0.000000e+00 0 0 0 0 0 ## [7,] 0 0 0.000000e+00 0 0 0 0 0 ## [8,] 0 0 0.000000e+00 0 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.000000e+00 0 0 0 0 ## [2,] 0 0 0 0.000000e+00 0 0 0 0 ## [3,] 0 0 0 0.000000e+00 0 0 0 0 ## [4,] 0 0 0 1.009869e-06 0 0 0 0 ## [5,] 0 0 0 0.000000e+00 0 0 0 0 ## [6,] 0 0 0 0.000000e+00 0 0 0 0 ## [7,] 0 0 0 0.000000e+00 0 0 0 0 ## [8,] 0 0 0 0.000000e+00 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.06507655 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0.00000000 0 0 ## [2,] 0 0 0 0 0 0.00000000 0 0 ## [3,] 0 0 0 0 0 0.00000000 0 0 ## [4,] 0 0 0 0 0 0.00000000 0 0 ## [5,] 0 0 0 0 0 0.00000000 0 0 ## [6,] 0 0 0 0 0 0.06507655 0 0 ## [7,] 0 0 0 0 0 0.00000000 0 0 ## [8,] 0 0 0 0 0 0.00000000 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0.000000e+00 0 ## [2,] 0 0 0 0 0 0 0.000000e+00 0 ## [3,] 0 0 0 0 0 0 0.000000e+00 0 ## [4,] 0 0 0 0 0 0 0.000000e+00 0 ## [5,] 0 0 0 0 0 0 0.000000e+00 0 ## [6,] 0 0 0 0 0 0 0.000000e+00 0 ## [7,] 0 0 0 0 0 0 1.009869e-06 0 ## [8,] 0 0 0 0 0 0 0.000000e+00 0 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.000000e+00 ## [2,] 0 0 0 0 0 0 0 0.000000e+00 ## [3,] 0 0 0 0 0 0 0 0.000000e+00 ## [4,] 0 0 0 0 0 0 0 0.000000e+00 ## [5,] 0 0 0 0 0 0 0 0.000000e+00 ## [6,] 0 0 0 0 0 0 0 0.000000e+00 ## [7,] 0 0 0 0 0 0 0 0.000000e+00 ## [8,] 0 0 0 0 0 0 0 1.009869e-06 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.002305683 0.002305683 0.002305683 0.002305683 0.002305683 0.002305683 0.002305683 0.002305683 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.06100916 0.02033639 0.02033639 0.00000000 0.00000000 0.02033639 0.00000000 0.00000000 ## [2,] 0.02033639 -0.04067278 0.00000000 0.02033639 0.00000000 0.00000000 0.00000000 0.00000000 ## [3,] 0.02033639 0.00000000 -0.06100916 0.02033639 0.00000000 0.00000000 0.00000000 0.02033639 ## [4,] 0.00000000 0.02033639 0.02033639 -0.04067278 0.00000000 0.00000000 0.00000000 0.00000000 ## [5,] 0.00000000 0.02033639 0.00000000 0.00000000 -0.06100916 0.02033639 0.02033639 0.00000000 ## [6,] 0.00000000 0.00000000 0.00000000 0.00000000 0.02033639 -0.04067278 0.00000000 0.02033639 ## [7,] 0.00000000 0.00000000 0.00000000 0.02033639 0.02033639 0.00000000 -0.06100916 0.02033639 ## [8,] 0.00000000 0.00000000 0.00000000 0.00000000 0.00000000 0.02033639 0.02033639 -0.04067278 4.5.4 CLA8-C Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args #args$pars #length(args$pars) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars # pars.hc[&#39;lam000&#39;] &lt;- 0.1 # pars.hc[&#39;lam111&#39;] &lt;- 0.1 # pars.hc[&#39;lam222&#39;] &lt;- 0.1 # pars.hc[&#39;lam333&#39;] &lt;- 0.1 # pars.hc[&#39;lam444&#39;] &lt;- 0.05 # pars.hc[&#39;lam555&#39;] &lt;- 0.05 # pars.hc[&#39;lam666&#39;] &lt;- 0.05 # pars.hc[&#39;lam777&#39;] &lt;- 0.05 pars.hc[&#39;lam022&#39;] &lt;- 0.1 pars.hc[&#39;lam133&#39;] &lt;- 0.1 pars.hc[&#39;lam202&#39;] &lt;- 0.1 pars.hc[&#39;lam311&#39;] &lt;- 0.1 pars.hc[&#39;lam466&#39;] &lt;- 0.05 pars.hc[&#39;lam577&#39;] &lt;- 0.05 pars.hc[&#39;lam646&#39;] &lt;- 0.05 pars.hc[&#39;lam757&#39;] &lt;- 0.05 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q_cor8_C.r) qsl=length(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc,8) #args zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- assign_classes_pairwise(Q_cor8_C.r, args$arrays$Q) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0) f.lams &lt;- c(lam133 ~ lam022, lam202 ~ lam022, lam311 ~ lam022, lam577 ~ lam466, lam646 ~ lam466, lam757 ~ lam466) f.list&lt;- c(zero.constr, f.qs, f.mu, f.lams) Run inference CLA8_C &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) #starting.point &lt;- pars.hc[arg.const] starting.point &lt;- get_item(COR8_C[i], &#39;par&#39;) names(starting.point) &lt;- arg.const CLA8_C[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Assessing the inferred parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 get_item(CLA8_C, &#39;lnLik&#39;) ## [1] -438.9548 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7798 -429.2834 -421.0964 -397.1996 get_item(CID8[1], &#39;par&#39;) ## lam000 lam444 mu0 q01 ## 0.0509438630 0.0509155136 0.0003102256 0.0075620757 pars_to_arrays(CLA8_C[[1]]$par.full, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.05095631 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.05095631 0 0 0 0 0 0 ## [2,] 0 0.00000000 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.00000000 0 0 0 0 ## [4,] 0 0 0 0.05097545 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.05097545 0 0 0 0 ## [4,] 0 0 0 0.00000000 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0.00000000 0 0 ## [2,] 0 0 0 0 0 0.00000000 0 0 ## [3,] 0 0 0 0 0 0.00000000 0 0 ## [4,] 0 0 0 0 0 0.00000000 0 0 ## [5,] 0 0 0 0 0 0.00000000 0 0 ## [6,] 0 0 0 0 0 0.05095631 0 0 ## [7,] 0 0 0 0 0 0.00000000 0 0 ## [8,] 0 0 0 0 0 0.00000000 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.05095631 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.00000000 ## [8,] 0 0 0 0 0 0 0 0.05097545 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.05097545 ## [8,] 0 0 0 0 0 0 0 0.00000000 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.0003971397 0.0003971397 0.0003971397 0.0003971397 0.0003971397 0.0003971397 0.0003971397 0.0003971397 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.022680368 0.007560123 0.007560123 0.000000000 0.000000000 0.007560123 0.000000000 0.000000000 ## [2,] 0.007560123 -0.022680368 0.000000000 0.007560123 0.007560123 0.000000000 0.000000000 0.000000000 ## [3,] 0.007560123 0.000000000 -0.022680368 0.007560123 0.000000000 0.000000000 0.000000000 0.007560123 ## [4,] 0.000000000 0.007560123 0.007560123 -0.022680368 0.000000000 0.000000000 0.007560123 0.000000000 ## [5,] 0.000000000 0.007560123 0.000000000 0.000000000 -0.022680368 0.007560123 0.007560123 0.000000000 ## [6,] 0.007560123 0.000000000 0.000000000 0.000000000 0.007560123 -0.022680368 0.000000000 0.007560123 ## [7,] 0.000000000 0.000000000 0.000000000 0.007560123 0.007560123 0.000000000 -0.022680368 0.007560123 ## [8,] 0.000000000 0.000000000 0.007560123 0.000000000 0.000000000 0.007560123 0.007560123 -0.022680368 4.5.5 CLA8-NC Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args #args$pars #length(args$pars) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars # pars.hc[&#39;lam000&#39;] &lt;- 0.1 # pars.hc[&#39;lam111&#39;] &lt;- 0.1 # pars.hc[&#39;lam222&#39;] &lt;- 0.1 # pars.hc[&#39;lam333&#39;] &lt;- 0.1 # pars.hc[&#39;lam444&#39;] &lt;- 0.05 # pars.hc[&#39;lam555&#39;] &lt;- 0.05 # pars.hc[&#39;lam666&#39;] &lt;- 0.05 # pars.hc[&#39;lam777&#39;] &lt;- 0.05 # lam004, lam116, lam422 violate lumpability pars.hc[&#39;lam004&#39;] &lt;- 0.1 pars.hc[&#39;lam116&#39;] &lt;- 0.1 pars.hc[&#39;lam202&#39;] &lt;- 0.1 pars.hc[&#39;lam311&#39;] &lt;- 0.1 pars.hc[&#39;lam422&#39;] &lt;- 0.05 pars.hc[&#39;lam577&#39;] &lt;- 0.05 pars.hc[&#39;lam646&#39;] &lt;- 0.05 pars.hc[&#39;lam757&#39;] &lt;- 0.05 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q_cor8_C.r) qsl=length(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc,8) #args zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- assign_classes_pairwise(Q_cor8_C.r, args$arrays$Q) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0) f.lams &lt;- c(lam116 ~ lam004, lam202 ~ lam004, lam311 ~ lam004, lam577 ~ lam422, lam646 ~ lam422, lam757 ~ lam422) f.list&lt;- c(zero.constr, f.qs, f.mu, f.lams) Run inference CLA8_NC &lt;- list() i=1 # skip 4 as mle search gets stuck and R crushes seq &lt;- 1:10 seq &lt;-seq[-4] for (i in seq){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) #starting.point &lt;- pars.hc[arg.const] starting.point &lt;- get_item(CLA8_C[i], &#39;par&#39;) names(starting.point) &lt;- arg.const CLA8_NC[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; Assessing the inferred parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.9549 -427.5105 -410.6673 -420.5590 -421.6901 -414.8487 -435.7799 -429.2834 -421.0965 -397.1996 get_item(COR8_NC, &#39;lnLik&#39;) ## [1] -439.3721 -428.0217 -411.3027 -421.3187 -422.2212 -416.0885 -435.6355 -428.1737 -422.4050 -398.2370 get_item(CLA8_NC, &#39;lnLik&#39;) ## [1] -428.8063 -423.3527 -407.0617 -417.3582 -411.1370 -427.4852 -424.7370 -416.0654 -394.4739 get_item(CID8[1], &#39;par&#39;) ## lam000 lam444 mu0 q01 ## 0.0509438630 0.0509155136 0.0003102256 0.0075620757 pars_to_arrays(CLA8_C[[1]]$par.full, 8) %&gt;% reoder_lambdas(., c(1,3,5,7, 2,4,6,8)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.00000000 0 0 0 0 0 0 ## [2,] 0 0.05095631 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0.05095631 0 0 0 0 0 0 ## [2,] 0 0.00000000 0 0 0 0 0 0 ## [3,] 0 0.00000000 0 0 0 0 0 0 ## [4,] 0 0.00000000 0 0 0 0 0 0 ## [5,] 0 0.00000000 0 0 0 0 0 0 ## [6,] 0 0.00000000 0 0 0 0 0 0 ## [7,] 0 0.00000000 0 0 0 0 0 0 ## [8,] 0 0.00000000 0 0 0 0 0 0 ## ## $lam.tensor$`5` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.00000000 0 0 0 0 ## [4,] 0 0 0 0.05097545 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`7` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0.00000000 0 0 0 0 ## [2,] 0 0 0 0.00000000 0 0 0 0 ## [3,] 0 0 0 0.05097545 0 0 0 0 ## [4,] 0 0 0 0.00000000 0 0 0 0 ## [5,] 0 0 0 0.00000000 0 0 0 0 ## [6,] 0 0 0 0.00000000 0 0 0 0 ## [7,] 0 0 0 0.00000000 0 0 0 0 ## [8,] 0 0 0 0.00000000 0 0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0.00000000 0 0 ## [2,] 0 0 0 0 0 0.00000000 0 0 ## [3,] 0 0 0 0 0 0.00000000 0 0 ## [4,] 0 0 0 0 0 0.00000000 0 0 ## [5,] 0 0 0 0 0 0.00000000 0 0 ## [6,] 0 0 0 0 0 0.05095631 0 0 ## [7,] 0 0 0 0 0 0.00000000 0 0 ## [8,] 0 0 0 0 0 0.00000000 0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0.00000000 0 0 0 ## [2,] 0 0 0 0 0.00000000 0 0 0 ## [3,] 0 0 0 0 0.00000000 0 0 0 ## [4,] 0 0 0 0 0.00000000 0 0 0 ## [5,] 0 0 0 0 0.05095631 0 0 0 ## [6,] 0 0 0 0 0.00000000 0 0 0 ## [7,] 0 0 0 0 0.00000000 0 0 0 ## [8,] 0 0 0 0 0.00000000 0 0 0 ## ## $lam.tensor$`6` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.00000000 ## [8,] 0 0 0 0 0 0 0 0.05097545 ## ## $lam.tensor$`8` ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] 0 0 0 0 0 0 0 0.00000000 ## [2,] 0 0 0 0 0 0 0 0.00000000 ## [3,] 0 0 0 0 0 0 0 0.00000000 ## [4,] 0 0 0 0 0 0 0 0.00000000 ## [5,] 0 0 0 0 0 0 0 0.00000000 ## [6,] 0 0 0 0 0 0 0 0.00000000 ## [7,] 0 0 0 0 0 0 0 0.05097545 ## [8,] 0 0 0 0 0 0 0 0.00000000 ## ## ## $mu ## mu0 mu2 mu4 mu6 mu1 mu3 mu5 mu7 ## 0.0003971397 0.0003971397 0.0003971397 0.0003971397 0.0003971397 0.0003971397 0.0003971397 0.0003971397 ## ## $Q ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.022680368 0.007560123 0.007560123 0.000000000 0.000000000 0.007560123 0.000000000 0.000000000 ## [2,] 0.007560123 -0.022680368 0.000000000 0.007560123 0.007560123 0.000000000 0.000000000 0.000000000 ## [3,] 0.007560123 0.000000000 -0.022680368 0.007560123 0.000000000 0.000000000 0.000000000 0.007560123 ## [4,] 0.000000000 0.007560123 0.007560123 -0.022680368 0.000000000 0.000000000 0.007560123 0.000000000 ## [5,] 0.000000000 0.007560123 0.000000000 0.000000000 -0.022680368 0.007560123 0.007560123 0.000000000 ## [6,] 0.007560123 0.000000000 0.000000000 0.000000000 0.007560123 -0.022680368 0.000000000 0.007560123 ## [7,] 0.000000000 0.000000000 0.000000000 0.007560123 0.007560123 0.000000000 -0.022680368 0.007560123 ## [8,] 0.000000000 0.000000000 0.007560123 0.000000000 0.000000000 0.007560123 0.007560123 -0.022680368 4.6 Results 4.6.1 Inferences using parameters from CID4 4.6.1.1 Likelihood table cid4 = get_item(CID4, &#39;lnLik&#39;) cor.pars &lt;- tibble( &quot;N&quot; = c(1:NSIM), &quot;cid4&quot; = cid4, &quot;CID8.pars&quot;= CID8.pars %&gt;% unlist, &quot;COR8-C.pars&quot;= COR8_C.pars %&gt;% unlist, &quot;CLA8-C.pars&quot; = CLA8_C.pars %&gt;% unlist, &quot;COR8-NC.pars&quot; = COR8_NC.pars %&gt;% unlist, &quot;CLA8-NC.pars&quot; = CLA8_NC.pars %&gt;% unlist, ) kable(cor.pars, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;)) N cid4 CID8.pars COR8-C.pars CLA8-C.pars COR8-NC.pars CLA8-NC.pars 1 -438.9549 -438.9549 -438.9549 -438.9549 -442.1584 -432.3801 2 -427.5105 -427.5105 -427.5105 -427.5105 -432.3652 -423.9786 3 -410.6673 -410.6673 -410.6673 -410.6673 -414.2528 -407.2375 4 -420.5590 -420.5590 -420.5590 -420.5590 -425.1997 -416.6835 5 -421.6901 -421.6901 -421.6901 -421.6901 -424.8447 -427.4961 6 -414.8487 -414.8487 -414.8487 -414.8487 -420.8153 -411.1675 7 -435.7799 -435.7799 -435.7799 -435.7799 -438.9214 -428.8506 8 -429.2834 -429.2834 -429.2834 -429.2834 -432.1182 -435.2936 9 -421.0965 -421.0965 -421.0965 -421.0965 -426.2918 -416.6131 10 -397.1996 -397.1996 -397.1996 -397.1996 -399.7270 -396.3307 4.6.1.2 Mean absolute error dcor.pars &lt;- tibble( &quot;cid4&quot; = cid4, &quot;CID8.pars&quot;= CID8.pars %&gt;% unlist, &quot;COR8-C.pars&quot;= COR8_C.pars %&gt;% unlist, &quot;CLA8-C.pars&quot; = CLA8_C.pars %&gt;% unlist, &quot;COR8-NC.pars&quot; = COR8_NC.pars %&gt;% unlist, &quot;CLA8-NC.pars&quot; = CLA8_NC.pars %&gt;% unlist, ) cid4t &lt;- cid4 dcor.pars &lt;- dcor.pars %&gt;% mutate_all(~ abs(cid4t - .) ) column_means &lt;- dcor.pars %&gt;% summarise_all(~ mean(.)) # Data delta_values &lt;- tibble( Delta = names(column_means), Value = column_means %&gt;% slice(1) %&gt;% unlist() ) kable(column_means, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;)) cid4 CID8.pars COR8-C.pars CLA8-C.pars COR8-NC.pars CLA8-NC.pars 0 0 0 0 3.910447 4.519079 # Create the plot ggplot(delta_values, aes(x = Delta, y = Value, label = sprintf(&quot;%.2e&quot;, Value))) + geom_col(fill = c(&quot;blue&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;)) + geom_text(vjust = -0.5, angle = 45) + labs(title = &quot;Comparison of Ln Differences&quot;, x = &quot;Deltas&quot;, y = &quot;Magnitude&quot;) + theme_minimal() 4.6.2 Maximum Likelihood estimates 4.6.2.1 Likelihood table cor.pars &lt;- tibble( &quot;N&quot; = c(1:NSIM), &quot;cid4&quot; = cid4, &quot;CID8&quot;= get_item(CID8, &#39;lnLik&#39;), &quot;COR8-C&quot;= get_item(COR8_C, &#39;lnLik&#39;), &quot;CLA8-C&quot; = get_item(CLA8_C, &#39;lnLik&#39;), &quot;COR8-NC&quot; = get_item(COR8_NC, &#39;lnLik&#39;), &quot;CLA8-NC&quot; = append(get_item(CLA8_NC, &#39;lnLik&#39;), NA, after=3), ) kable(cor.pars, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;)) N cid4 CID8 COR8-C CLA8-C COR8-NC CLA8-NC 1 -438.9549 -438.9549 -438.9549 -438.9548 -439.3721 -428.8063 2 -427.5105 -427.5105 -427.5105 -427.5105 -428.0217 -423.3527 3 -410.6673 -410.6673 -410.6673 -410.6673 -411.3027 -407.0617 4 -420.5590 -420.5590 -420.5590 -420.5590 -421.3187 NA 5 -421.6901 -421.6901 -421.6901 -421.6901 -422.2212 -417.3582 6 -414.8487 -414.8487 -414.8487 -414.8487 -416.0885 -411.1370 7 -435.7799 -435.7799 -435.7799 -435.7798 -435.6355 -427.4852 8 -429.2834 -429.2834 -429.2834 -429.2834 -428.1737 -424.7370 9 -421.0965 -421.0965 -421.0965 -421.0964 -422.4050 -416.0654 10 -397.1996 -397.1996 -397.1996 -397.1996 -398.2370 -394.4739 4.6.2.2 Mean absolute error dcor.pars &lt;- tibble( &quot;cid4&quot; = cid4, &quot;CID8&quot;= get_item(CID8, &#39;lnLik&#39;), &quot;COR8-C&quot;= get_item(COR8_C, &#39;lnLik&#39;), &quot;CLA8-C&quot; = get_item(CLA8_C, &#39;lnLik&#39;), &quot;COR8-NC&quot; = get_item(COR8_NC, &#39;lnLik&#39;), &quot;CLA8-NC&quot; = append(get_item(CLA8_NC, &#39;lnLik&#39;), NA, after=3), ) # dcor.pars &lt;- tibble( # &quot;cid4&quot; = cid4, # &quot;CID8.pars&quot;= CID8.pars %&gt;% unlist, # &quot;COR8-C.pars&quot;= COR8_C.pars %&gt;% unlist, # &quot;CLA8-C.pars&quot; = CLA8_C.pars %&gt;% unlist, # &quot;COR8-NC.pars&quot; = COR8_NC.pars %&gt;% unlist, # &quot;CLA8-NC.pars&quot; = CLA8_NC.pars %&gt;% unlist, # ) cid4t &lt;- cid4 dcor.pars &lt;- dcor.pars %&gt;% mutate_all(~ abs(cid4t - .) ) column_means &lt;- dcor.pars %&gt;% summarise_all(~ mean(., na.rm = TRUE)) # Data delta_values &lt;- tibble( Delta = names(column_means), Value = column_means %&gt;% slice(1) %&gt;% unlist() ) kable(column_means, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;)) cid4 CID8 COR8-C CLA8-C COR8-NC CLA8-NC 0 0 0 2.19e-05 0.7694592 5.172621 # Create the plot ggplot(delta_values, aes(x = Delta, y = Value, label = sprintf(&quot;%.2e&quot;, Value))) + geom_col(fill = c(&quot;blue&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;)) + geom_text(vjust = -0.5, angle = 45) + labs(title = &quot;Comparison of Ln Differences&quot;, x = &quot;Deltas&quot;, y = &quot;Magnitude&quot;) + theme_minimal() "],["equal-rate-hidden-expansion-ehe.html", "5 Equal Rate Hidden Expansion (EHE) 5.1 Read in data 5.2 Setting-up Q matrices for inference 5.3 Inferences using parameters from CID4 5.4 Compare Ln estimates", " 5 Equal Rate Hidden Expansion (EHE) HE can be extended to a point when all permissible rates are equal, except extinctions. We refer to this transformation as Equal Rate Hidden Expansion (EHE). The EHE model can be created for any SSE, if we know parameter values of that SSE. In this example, we calculate likelihood for CID4 with known parameters and construct congruent EHE8-C model. We show that the likelihoods are identical up to numerical integration error. ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~ installations and dependencies ---- ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ source(&#39;R/utils/dependencies.R&#39;) source(&#39;R/hiclasse/HiClaSSE-R.R&#39;) # pure R implementation of HiCLaSSE ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 source(&#39;R/hiclasse/HiClaSSE_cpp.R&#39;) # fast implementation ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE 5.1 Read in data NSIM = 10 phy &lt;- readRDS(file=&#39;R/data/phy_CID4.RDS&#39;) 5.2 Setting-up Q matrices for inference 5.2.1 CID4 # trait Q_t &lt;- initQ(c(0,1), c(2, 2)) # diversification regime Q_r2 &lt;- initQ(c(&#39;A&#39;,&#39;B&#39;), c(2,2)) # speciation rates for tracking the order La4 &lt;- diag(c(-3,-1),2) La4 = La4 %x% diag(1,2) # order according to regimes Q_cid4.r &lt;- amaSMM(Q_r2, Q_t) # order according to trait v=c(1,3, 2,4) Q_cid4.t &lt;- Q_cid4.r[v,v] print(Q_cid4.r) ## A0 A1 B0 B1 ## A0 -4 2 2 0 ## A1 2 -4 0 2 ## B0 2 0 -4 2 ## B1 0 2 2 -4 print(La4) ## [,1] [,2] [,3] [,4] ## [1,] -3 0 0 0 ## [2,] 0 -3 0 0 ## [3,] 0 0 -1 0 ## [4,] 0 0 0 -1 print(Q_cid4.t) ## A0 B0 A1 B1 ## A0 -4 2 2 0 ## B0 2 -4 0 2 ## A1 2 0 -4 2 ## B1 0 2 2 -4 print(La4[v,v]) ## [,1] [,2] [,3] [,4] ## [1,] -3 0 0 0 ## [2,] 0 -1 0 0 ## [3,] 0 0 -3 0 ## [4,] 0 0 0 -1 5.2.2 CID8 (congruent to CID4) # diversification regime # Q_r4 &lt;- initQ(c(&#39;a&#39;,&#39;b&#39;, &#39;c&#39;, &#39;d&#39;), c(2,2)) Q_r4 &lt;- amaSMM(Q_r2, Q_r2) colnames(Q_r4) &lt;- rownames(Q_r4) &lt;- c(&#39;a&#39;,&#39;b&#39;, &#39;c&#39;, &#39;d&#39;) # speciation rates for tracking the order La8 &lt;- diag(c(-3,-1),2) La8 = La8 %x% diag(1,4) # order according to regimes Q_cid8.r &lt;- amaSMM(Q_r4, Q_t) # order according to trait v=c(1,3,5,7, 2,4,6,8) Q_cid8.t &lt;- Q_cid8.r[v,v] print(Q_cid8.r) ## a0 a1 b0 b1 c0 c1 d0 d1 ## a0 -6 2 2 0 2 0 0 0 ## a1 2 -6 0 2 0 2 0 0 ## b0 2 0 -6 2 0 0 2 0 ## b1 0 2 2 -6 0 0 0 2 ## c0 2 0 0 0 -6 2 2 0 ## c1 0 2 0 0 2 -6 0 2 ## d0 0 0 2 0 2 0 -6 2 ## d1 0 0 0 2 0 2 2 -6 print(La8) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -3 0 0 0 0 0 0 0 ## [2,] 0 -3 0 0 0 0 0 0 ## [3,] 0 0 -3 0 0 0 0 0 ## [4,] 0 0 0 -3 0 0 0 0 ## [5,] 0 0 0 0 -1 0 0 0 ## [6,] 0 0 0 0 0 -1 0 0 ## [7,] 0 0 0 0 0 0 -1 0 ## [8,] 0 0 0 0 0 0 0 -1 print(Q_cid8.t) ## a0 b0 c0 d0 a1 b1 c1 d1 ## a0 -6 2 2 0 2 0 0 0 ## b0 2 -6 0 2 0 2 0 0 ## c0 2 0 -6 2 0 0 2 0 ## d0 0 2 2 -6 0 0 0 2 ## a1 2 0 0 0 -6 2 2 0 ## b1 0 2 0 0 2 -6 0 2 ## c1 0 0 2 0 2 0 -6 2 ## d1 0 0 0 2 0 2 2 -6 print(La8[v,v]) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -3 0 0 0 0 0 0 0 ## [2,] 0 -3 0 0 0 0 0 0 ## [3,] 0 0 -1 0 0 0 0 0 ## [4,] 0 0 0 -1 0 0 0 0 ## [5,] 0 0 0 0 -3 0 0 0 ## [6,] 0 0 0 0 0 -3 0 0 ## [7,] 0 0 0 0 0 0 -1 0 ## [8,] 0 0 0 0 0 0 0 -1 5.2.3 EHE8-C (correlated evolution, congruent to CID4) # Create the matrix as a data frame Q_ehe8_C.t &lt;- data.frame( a0 = c(-4, 0, 1, 1, 1, 1, 0, 0), b0 = c(0, -4, 1, 1, 1, 1, 0, 0), c0 = c(1, 1, -4, 0, 0, 0, 1, 1), d0 = c(1, 1, 0, -4, 0, 0, 1, 1), a1 = c(1, 1, 0, 0, -4, 0, 1, 1), b1 = c(1, 1, 0, 0, 0, -4, 1, 1), c1 = c(0, 0, 1, 1, 1, 1, -4, 0), d1 = c(0, 0, 1, 1, 1, 1, 0, -4) ) # Set row names and column names rownames(Q_ehe8_C.t) &lt;- colnames(Q_ehe8_C.t) Q_ehe8_C.t &lt;-as.matrix(Q_ehe8_C.t) v=c(1,5, 2,6, 3,7, 4,8) Q_ehe8_C.r &lt;- Q_ehe8_C.t[v,v] print(Q_ehe8_C.r) ## a0 a1 b0 b1 c0 c1 d0 d1 ## a0 -4 1 0 1 1 0 1 0 ## a1 1 -4 1 0 0 1 0 1 ## b0 0 1 -4 1 1 0 1 0 ## b1 1 0 1 -4 0 1 0 1 ## c0 1 0 1 0 -4 1 0 1 ## c1 0 1 0 1 1 -4 1 0 ## d0 1 0 1 0 0 1 -4 1 ## d1 0 1 0 1 1 0 1 -4 #print(La8) print(Q_ehe8_C.t) ## a0 b0 c0 d0 a1 b1 c1 d1 ## a0 -4 0 1 1 1 1 0 0 ## b0 0 -4 1 1 1 1 0 0 ## c0 1 1 -4 0 0 0 1 1 ## d0 1 1 0 -4 0 0 1 1 ## a1 1 1 0 0 -4 0 1 1 ## b1 1 1 0 0 0 -4 1 1 ## c1 0 0 1 1 1 1 -4 0 ## d1 0 0 1 1 1 1 0 -4 print(La8[v,v]) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -3 0 0 0 0 0 0 0 ## [2,] 0 -1 0 0 0 0 0 0 ## [3,] 0 0 -3 0 0 0 0 0 ## [4,] 0 0 0 -1 0 0 0 0 ## [5,] 0 0 0 0 -3 0 0 0 ## [6,] 0 0 0 0 0 -1 0 0 ## [7,] 0 0 0 0 0 0 -3 0 ## [8,] 0 0 0 0 0 0 0 -1 5.3 Inferences using parameters from CID4 5.3.1 CID4 (4 pars) We assume that we know the parameter estimated for CID4 lam1=0.3 lam2=0.1 q=0.2 mu=0.01 Calculating likelihood Args &lt;- list( Nstates = 4L, y = list( c(0,0,0,0, 1,0,1,0), c(0,0,0,0, 0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(4) CID4.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- lam1 pars.hc[&#39;lam111&#39;] &lt;- lam1 pars.hc[&#39;lam222&#39;] &lt;- lam2 pars.hc[&#39;lam333&#39;] &lt;- lam2 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- mu qs &lt;- extract_off_diagonal(Q_cid4.r/10) qsl=length(qs) #qs[qs==1] &lt;- est[&#39;q01&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc, 4) #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/4, 4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) CID4.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 00001010&quot; ## [1] &quot;Recoding: 0001 -&gt; 00000101&quot; This is CID4 model. pars_to_arrays(pars.hc, 4) %&gt;% reoder_lambdas(., c(1,3, 2,4)) ## $lam.tensor ## $lam.tensor$`1` ## [,1] [,2] [,3] [,4] ## [1,] 0.3 0 0 0 ## [2,] 0.0 0 0 0 ## [3,] 0.0 0 0 0 ## [4,] 0.0 0 0 0 ## ## $lam.tensor$`3` ## [,1] [,2] [,3] [,4] ## [1,] 0 0.0 0 0 ## [2,] 0 0.1 0 0 ## [3,] 0 0.0 0 0 ## [4,] 0 0.0 0 0 ## ## $lam.tensor$`2` ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0.0 0 ## [2,] 0 0 0.0 0 ## [3,] 0 0 0.3 0 ## [4,] 0 0 0.0 0 ## ## $lam.tensor$`4` ## [,1] [,2] [,3] [,4] ## [1,] 0 0 0 0.0 ## [2,] 0 0 0 0.0 ## [3,] 0 0 0 0.0 ## [4,] 0 0 0 0.1 ## ## ## $mu ## mu0 mu2 mu1 mu3 ## 0.01 0.01 0.01 0.01 ## ## $Q ## [,1] [,2] [,3] [,4] ## [1,] -0.4 0.2 0.2 0.0 ## [2,] 0.2 -0.4 0.0 0.2 ## [3,] 0.2 0.0 -0.4 0.2 ## [4,] 0.0 0.2 0.2 -0.4 5.3.2 EHE8-C (2 pars) Now we create EHE8-C by decomposing our known parameter estimates into just two parameters: (1.) speciation and transitions rates equal to 0.1; and extinction equal to 0.01. Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args$arrays #reoder_lambdas(args$arrays, c(1,3,5,7, 2,4,6,8)) Calculating Ln lam1=0.3 lam2=0.1 q=0.2 mu=0.01 EHE8_C.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars # pars.hc[&#39;lam000&#39;] &lt;- lam1 # pars.hc[&#39;lam111&#39;] &lt;- lam1 # pars.hc[&#39;lam222&#39;] &lt;- lam1 # pars.hc[&#39;lam333&#39;] &lt;- lam1 pars.hc[&#39;lam000&#39;] &lt;- pars.hc[&#39;lam002&#39;] &lt;- pars.hc[&#39;lam022&#39;] &lt;- lam1/3 pars.hc[&#39;lam200&#39;] &lt;- pars.hc[&#39;lam202&#39;] &lt;- pars.hc[&#39;lam222&#39;] &lt;- lam1/3 pars.hc[&#39;lam111&#39;] &lt;- pars.hc[&#39;lam113&#39;] &lt;- pars.hc[&#39;lam133&#39;] &lt;- lam1/3 pars.hc[&#39;lam311&#39;] &lt;- pars.hc[&#39;lam313&#39;] &lt;- pars.hc[&#39;lam333&#39;] &lt;- lam1/3 pars.hc[&#39;lam444&#39;] &lt;- lam2 pars.hc[&#39;lam555&#39;] &lt;- lam2 pars.hc[&#39;lam666&#39;] &lt;- lam2 pars.hc[&#39;lam777&#39;] &lt;- lam2 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- mu qs &lt;- extract_off_diagonal(Q_ehe8_C.r/10) qsl=length(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc pars_to_arrays(pars.hc, 8) reoder_lambdas(pars_to_arrays(pars.hc, 8), c(1,3,5,7, 2,4,6,8)) #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) EHE8_C.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0000000010101010&quot; ## [1] &quot;Recoding: 0001 -&gt; 0000000001010101&quot; 5.4 Compare Ln estimates The likelihoods are the same, the errors are due to numerical integration. cid4 &lt;- CID4.pars %&gt;% unlist print(cid4) ## [1] -584.5449 -519.5364 -490.6876 -505.0053 -562.0536 -481.1865 -539.0145 -546.3710 -508.4142 -477.1595 ehe8 &lt;- EHE8_C.pars %&gt;% unlist print(ehe8) ## [1] -584.5449 -519.5364 -490.6876 -505.0053 -562.0536 -481.1865 -539.0145 -546.3711 -508.4142 -477.1595 print(cid4-ehe8) ## [1] 2.922985e-06 2.760492e-06 3.440786e-06 3.040528e-06 2.149453e-06 3.493703e-06 2.752414e-06 2.570285e-06 2.996501e-06 3.601493e-06 "],["semi-congruent-behavior.html", "6 Semi-congruent Behavior 6.1 Setting-up Q matrices for inference 6.2 Read in data 6.3 Maximum Likelihood 6.4 Results", " 6 Semi-congruent Behavior In this example, we simulated data using the CID4 model for three different scenarios: 100, 500, and 1000 tips. Subsequently, we conduct ML inference using two models: the original CID4 and the semi-congruent EHE8-C model. The CID4 model has four parameters, while the EHE8-C model has only two. We observe that the likelihood of the CID4 model is always better than that of the EHE8-C model across all scenarios. However, due to fewer parameters, the AIC of the EHE8-C tends to be better in most trials. It’s worth noting that lumping the semi-congruent EHE8-C model produces the CID4 model. In other words, if we create an irreducible model from the EHE8-C model, we obtain the original CID4 model with its four parameters. ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~ installations and dependencies ---- ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ source(&#39;R/utils/dependencies.R&#39;) source(&#39;R/hiclasse/HiClaSSE-R.R&#39;) # pure R implementation of HiCLaSSE ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 source(&#39;R/hiclasse/HiClaSSE_cpp.R&#39;) # fast implementation ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE 6.1 Setting-up Q matrices for inference 6.1.1 CID4 # trait Q_t &lt;- initQ(c(0,1), c(2, 2)) # diversification regime Q_r2 &lt;- initQ(c(&#39;A&#39;,&#39;B&#39;), c(2,2)) # speciation rates for tracking the order La4 &lt;- diag(c(-3,-1),2) La4 = La4 %x% diag(1,2) # order according to regimes Q_cid4.r &lt;- amaSMM(Q_r2, Q_t) # order according to trait v=c(1,3, 2,4) Q_cid4.t &lt;- Q_cid4.r[v,v] print(Q_cid4.r) ## A0 A1 B0 B1 ## A0 -4 2 2 0 ## A1 2 -4 0 2 ## B0 2 0 -4 2 ## B1 0 2 2 -4 print(La4) ## [,1] [,2] [,3] [,4] ## [1,] -3 0 0 0 ## [2,] 0 -3 0 0 ## [3,] 0 0 -1 0 ## [4,] 0 0 0 -1 print(Q_cid4.t) ## A0 B0 A1 B1 ## A0 -4 2 2 0 ## B0 2 -4 0 2 ## A1 2 0 -4 2 ## B1 0 2 2 -4 print(La4[v,v]) ## [,1] [,2] [,3] [,4] ## [1,] -3 0 0 0 ## [2,] 0 -1 0 0 ## [3,] 0 0 -3 0 ## [4,] 0 0 0 -1 6.1.2 EHE8-C (correlated evolution, congruent to CID4) # Create the matrix as a data frame Q_ehe8_C.t &lt;- data.frame( a0 = c(-4, 0, 1, 1, 1, 1, 0, 0), b0 = c(0, -4, 1, 1, 1, 1, 0, 0), c0 = c(1, 1, -4, 0, 0, 0, 1, 1), d0 = c(1, 1, 0, -4, 0, 0, 1, 1), a1 = c(1, 1, 0, 0, -4, 0, 1, 1), b1 = c(1, 1, 0, 0, 0, -4, 1, 1), c1 = c(0, 0, 1, 1, 1, 1, -4, 0), d1 = c(0, 0, 1, 1, 1, 1, 0, -4) ) # Set row names and column names rownames(Q_ehe8_C.t) &lt;- colnames(Q_ehe8_C.t) Q_ehe8_C.t &lt;-as.matrix(Q_ehe8_C.t) v=c(1,5, 2,6, 3,7, 4,8) Q_ehe8_C.r &lt;- Q_ehe8_C.t[v,v] print(Q_ehe8_C.r) ## a0 a1 b0 b1 c0 c1 d0 d1 ## a0 -4 1 0 1 1 0 1 0 ## a1 1 -4 1 0 0 1 0 1 ## b0 0 1 -4 1 1 0 1 0 ## b1 1 0 1 -4 0 1 0 1 ## c0 1 0 1 0 -4 1 0 1 ## c1 0 1 0 1 1 -4 1 0 ## d0 1 0 1 0 0 1 -4 1 ## d1 0 1 0 1 1 0 1 -4 #print(La8) print(Q_ehe8_C.t) ## a0 b0 c0 d0 a1 b1 c1 d1 ## a0 -4 0 1 1 1 1 0 0 ## b0 0 -4 1 1 1 1 0 0 ## c0 1 1 -4 0 0 0 1 1 ## d0 1 1 0 -4 0 0 1 1 ## a1 1 1 0 0 -4 0 1 1 ## b1 1 1 0 0 0 -4 1 1 ## c1 0 0 1 1 1 1 -4 0 ## d1 0 0 1 1 1 1 0 -4 #print(La8[v,v]) 6.2 Read in data NSIM=100 files_base &lt;- c(&#39;phy_CID4-100tips-100tr&#39;, &#39;phy_CID4-500tips-100tr&#39;, &#39;phy_CID4-1000tips-100tr&#39;) 6.3 Maximum Likelihood 6.3.1 CID4 (4 pars) Args &lt;- list( Nstates = 4L, y = list( c(0,0,0,0, 1,0,1,0), c(0,0,0,0, 0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(4) #args$arrays #args$pars #length(args$pars) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam111&#39;] &lt;- 0.1 pars.hc[&#39;lam222&#39;] &lt;- 0.05 pars.hc[&#39;lam333&#39;] &lt;- 0.05 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q_cid4.r) qsl=length(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc,4) #args zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- assign_classes_pairwise(Q_cid4.r, args$arrays$Q) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0) f.lams &lt;- c(lam111 ~ lam000, lam333 ~ lam222) f.list&lt;- c(zero.constr, f.qs, f.mu, f.lams) Run inference #base=&quot;phy_CID4-100tips-100tr&quot; for (base in files_base[1:3]){ file=file.path(&quot;R/data&quot;, paste0(base, &#39;.RDS&#39;)) print(paste0(&#39;Reading file: &#39;,file)) phy &lt;- readRDS(file=file) CID4 &lt;- list() #i=1 #which(is.na(phy)) for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/4, 1/4, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) starting.point &lt;- pars.hc[arg.const] CID4[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) #CID4[[1]]$lnLik } file_out=paste0(&#39;R/data/lik-CID4-&#39;, base, &#39;.RDS&#39;) saveRDS(CID4, file= file_out) } 6.3.2 EHE8-C lam1=0.3 lam2=0.1 q=0.2 mu=0.01 Args &lt;- list( Nstates = 8L, y = list( c(0,0,0,0,0,0,0,0, 1,0,1,0,1,0,1,0), c(0,0,0,0,0,0,0,0, 0,1,0,1,0,1,0,1) )) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args$arrays #args$pars #length(args$pars) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- pars.hc[&#39;lam002&#39;] &lt;- pars.hc[&#39;lam022&#39;] &lt;- lam1/3 pars.hc[&#39;lam200&#39;] &lt;- pars.hc[&#39;lam202&#39;] &lt;- pars.hc[&#39;lam222&#39;] &lt;- lam1/3 pars.hc[&#39;lam111&#39;] &lt;- pars.hc[&#39;lam113&#39;] &lt;- pars.hc[&#39;lam133&#39;] &lt;- lam1/3 pars.hc[&#39;lam311&#39;] &lt;- pars.hc[&#39;lam313&#39;] &lt;- pars.hc[&#39;lam333&#39;] &lt;- lam1/3 pars.hc[&#39;lam444&#39;] &lt;- lam2 pars.hc[&#39;lam555&#39;] &lt;- lam2 pars.hc[&#39;lam666&#39;] &lt;- lam2 pars.hc[&#39;lam777&#39;] &lt;- lam2 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;-mu qs &lt;- extract_off_diagonal(Q_ehe8_C.r/10) qsl=length(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc,8) #args zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- assign_classes_pairwise(Q_ehe8_C.r/10, args$arrays$Q) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0, mu4 ~ mu0, mu5 ~ mu0, mu6 ~ mu0, mu7 ~ mu0) f.lams &lt;- c(lam002 ~ q01, lam022 ~ q01, lam200 ~ q01, lam202 ~ q01, lam222 ~ q01, lam111 ~ q01, lam113 ~ q01, lam133 ~ q01, lam311 ~ q01, lam313 ~ q01, lam333 ~ q01, lam444 ~ q01, lam555 ~ q01, lam666 ~ q01, lam777 ~ q01, lam000 ~ q01 ) f.list&lt;- c(zero.constr, f.qs, f.mu, f.lams) Run inference for (base in files_base){ file=file.path(&quot;R/data&quot;, paste0(base, &#39;.RDS&#39;)) print(paste0(&#39;Reading file: &#39;,file)) phy &lt;- readRDS(file=file) EHE8_C &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) starting.point &lt;- pars.hc[arg.const] EHE8_C[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) #EHE8_C[[1]]$lnLik } file_out=paste0(&#39;R/data/lik-EHE8_C-&#39;, base, &#39;.RDS&#39;) saveRDS(EHE8_C, file= file_out) } 6.4 Results cid &lt;- tibble( t100=get_item(readRDS(file=&#39;R/data/lik-CID4-phy_CID4-100tips-100tr.RDS&#39;), &#39;lnLik&#39;) %&gt;% get_aic(., 4), t500=get_item(readRDS(file=&#39;R/data/lik-CID4-phy_CID4-500tips-100tr.RDS&#39;), &#39;lnLik&#39;) %&gt;% get_aic(., 4), t1000=get_item(readRDS(file=&#39;R/data/lik-CID4-phy_CID4-1000tips-100tr.RDS&#39;), &#39;lnLik&#39;) %&gt;% get_aic(., 4) ) ehe &lt;- tibble( t100=get_item(readRDS(file=&#39;R/data/lik-EHE8_C-phy_CID4-100tips-100tr.RDS&#39;), &#39;lnLik&#39;) %&gt;% get_aic(., 2), t500=get_item(readRDS(file=&#39;R/data/lik-EHE8_C-phy_CID4-500tips-100tr.RDS&#39;), &#39;lnLik&#39;) %&gt;% get_aic(., 2), t1000=get_item(readRDS(file=&#39;R/data/lik-EHE8_C-phy_CID4-1000tips-100tr.RDS&#39;), &#39;lnLik&#39;) %&gt;% get_aic(., 2) ) cid.lik &lt;- tibble( t100=get_item(readRDS(file=&#39;R/data/lik-CID4-phy_CID4-100tips-100tr.RDS&#39;), &#39;lnLik&#39;), t500=get_item(readRDS(file=&#39;R/data/lik-CID4-phy_CID4-500tips-100tr.RDS&#39;), &#39;lnLik&#39;) , t1000=get_item(readRDS(file=&#39;R/data/lik-CID4-phy_CID4-1000tips-100tr.RDS&#39;), &#39;lnLik&#39;) ) ehe.lik &lt;- tibble( t100=get_item(readRDS(file=&#39;R/data/lik-EHE8_C-phy_CID4-100tips-100tr.RDS&#39;), &#39;lnLik&#39;), t500=get_item(readRDS(file=&#39;R/data/lik-EHE8_C-phy_CID4-500tips-100tr.RDS&#39;), &#39;lnLik&#39;), t1000=get_item(readRDS(file=&#39;R/data/lik-EHE8_C-phy_CID4-1000tips-100tr.RDS&#39;), &#39;lnLik&#39;) ) MLE of CID is constantly better than MLE of the semi-congruent EHE8-C. del.lik &lt;- cid.lik-ehe.lik # The positive values indicate that CID&#39;s MLE is better # There are only positive values apply(del.lik, 2, min) ## t100 t500 t1000 ## 0.004118721 0.013512631 0.003768857 However, in most trials EHE8-C has better AIC. library(ggplot2) library(dplyr) library(tidyr) # Load tidyr package del &lt;- cid-ehe # Calculate ECDF for each column ecdf_del &lt;- del %&gt;% summarise( t100_ecdf = ecdf(t100), t500_ecdf = ecdf(t500), t1000_ecdf = ecdf(t1000) ) # Create a data frame for plotting ecdf_data &lt;- data.frame( Value = c(del$t100, del$t500, del$t1000), Group = rep(c(&quot;100 tips&quot;, &quot;500 tips&quot;, &quot;1000 tips&quot;), each = nrow(del)) ) Proportion of trials with dAIC&gt;2. 1-ecdf_del$t100_ecdf(2) ## [1] 0.56 1-ecdf_del$t500_ecdf(2) ## [1] 0.64 1-ecdf_del$t1000_ecdf(2) ## [1] 0.55 #hist(ecdf_data$Value) Plot # Plot the ECDFs for each group cdf_plot &lt;-ggplot(ecdf_data, aes(x = Value, color = Group)) + stat_ecdf(geom = &quot;step&quot;) + labs(x = expression(Delta~AIC), y = &quot;CDF&quot;) + theme_minimal() + scale_x_continuous( limits = c(-5, 4), breaks = seq(-5, 4, by = 1) ) + theme( panel.grid.minor.x = element_blank(), # Remove minor grid lines on the x-axis panel.grid.minor.y = element_blank() ) + guides(color = guide_legend(title = NULL)) + geom_vline(xintercept=2, linetype=&quot;dashed&quot;, color = &quot;black&quot;, size=.5) + theme( #plot.background = element_rect(fill = &quot;white&quot;), #panel.background = element_rect(fill = &quot;white&quot;), legend.box.background = element_rect(fill = &quot;white&quot;), legend.text = element_text(size = 8), legend.position = c(0.25, 0.60) ) cdf_plot ## Warning: Removed 2 rows containing non-finite values (`stat_ecdf()`). # Save the plot with a specific width in centimeters #ggsave(&quot;Figs/cdf.eps&quot;, plot = cdf_plot , width = 8.7, height = 5, units = &quot;cm&quot;) #ggsave(&quot;Figs/cdf.png&quot;, plot = cdf_plot , width = 8.7, height = 5, units = &quot;cm&quot;) "],["congruence-under-varying-sampling-fraction.html", "7 Congruence under varying Sampling Fraction 7.1 Read in data 7.2 Setup Sampling Fraction 7.3 Setting-up Q matrices for inference 7.4 Irreducible model 7.5 Inferences using parameters from CID4 7.6 Results", " 7 Congruence under varying Sampling Fraction Hrein, we show that congruence holds under varying sampling fraction using the previous. This simulation is very close to the CID example from the section “Congruence between independent and dependent SSEs”, except that we use different sampling fraction. Model np pars Cong. with CID4 Trait &amp; Div. Speciation Rates CID4 4 2d 1q 1mu – independent decoupled (d) CID8 4 2d 1q 1mu yes independent decoupled (d) COR8-C 4 2d 1q 1mu yes correlated decoupled (d) CLA8-C 4 2c 1q 1mu yes correlated coupled (c) COR8-NC 4 2d 1q 1mu no correlated* decoupled (d) CLA8-NC 4 2c 1q 1mu no correlated coupled* (c) *indicates non-lumpable transition or speciation rates. See also, Fig. referenced and Table S1. ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ## ~ installations and dependencies ---- ##~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ source(&#39;R/utils/dependencies.R&#39;) source(&#39;R/hiclasse/HiClaSSE-R.R&#39;) # pure R implementation of HiCLaSSE ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 source(&#39;R/hiclasse/HiClaSSE_cpp.R&#39;) # fast implementation ## [1] &quot;Original matrix:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 7 ## [2,] 2 5 8 ## [3,] 3 6 9 ## [1] &quot;Matrix with right diagonal set to zero:&quot; ## [,1] [,2] [,3] ## [1,] 1 4 0 ## [2,] 2 0 8 ## [3,] 0 6 9 ## [1] TRUE ## [1] TRUE ## [1] TRUE ## [1] TRUE 7.1 Read in data NSIM = 10 phy &lt;- readRDS(file=&#39;R/data/phy_CID4.RDS&#39;) 7.2 Setup Sampling Fraction s1 &lt;- 0.6 s2 &lt;- 0.3 sam.fr4 = list( c(1-s1, 1-s2, 1-s1, 1-s2, s1, 0, s1, 0), c(1-s1, 1-s2, 1-s1, 1-s2, 0, s2, 0, s2) ) sam.fr8 = list( c(1-s1, 1-s2, 1-s1, 1-s2, 1-s1, 1-s2, 1-s1, 1-s2, s1,0,s1,0,s1,0,s1,0), c(1-s1, 1-s2, 1-s1, 1-s2, 1-s1, 1-s2, 1-s1, 1-s2, 0,s2,0,s2,0,s2,0,s2) ) 7.3 Setting-up Q matrices for inference 7.3.1 CID4 # trait Q_t &lt;- initQ(c(0,1), c(.1, .1)) # diversification regime Q_r2 &lt;- initQ(c(&#39;A&#39;,&#39;B&#39;), c(.1,.1)) # speciation rates for tracking the order La4 &lt;- diag(c(-0.1,-0.05),2) La4 = La4 %x% diag(1,2) # order according to regimes Q_cid4.r &lt;- amaSMM(Q_r2, Q_t) # order according to trait v=c(1,3, 2,4) Q_cid4.t &lt;- Q_cid4.r[v,v] print(Q_cid4.r) ## A0 A1 B0 B1 ## A0 -0.2 0.1 0.1 0.0 ## A1 0.1 -0.2 0.0 0.1 ## B0 0.1 0.0 -0.2 0.1 ## B1 0.0 0.1 0.1 -0.2 print(La4) ## [,1] [,2] [,3] [,4] ## [1,] -0.1 0.0 0.00 0.00 ## [2,] 0.0 -0.1 0.00 0.00 ## [3,] 0.0 0.0 -0.05 0.00 ## [4,] 0.0 0.0 0.00 -0.05 print(Q_cid4.t) ## A0 B0 A1 B1 ## A0 -0.2 0.1 0.1 0.0 ## B0 0.1 -0.2 0.0 0.1 ## A1 0.1 0.0 -0.2 0.1 ## B1 0.0 0.1 0.1 -0.2 print(La4[v,v]) ## [,1] [,2] [,3] [,4] ## [1,] -0.1 0.00 0.0 0.00 ## [2,] 0.0 -0.05 0.0 0.00 ## [3,] 0.0 0.00 -0.1 0.00 ## [4,] 0.0 0.00 0.0 -0.05 7.3.2 CID8 (congruent to CID4) # diversification regime #Q_r4 &lt;- initQ(c(&#39;a&#39;,&#39;b&#39;, &#39;c&#39;, &#39;d&#39;), c(.01,.01)) Q_r4 &lt;-amaSMM(Q_t, Q_t) colnames(Q_r4) &lt;- rownames(Q_r4) &lt;- c(&#39;a&#39;,&#39;b&#39;, &#39;c&#39;, &#39;d&#39;) # speciation rates for tracking the order La8 &lt;- diag(c(-0.1,-0.05),2) La8 = La8 %x% diag(1,4) # order according to regimes Q_cid8.r &lt;- amaSMM(Q_r4, Q_t) # order according to trait v=c(1,3,5,7, 2,4,6,8) Q_cid8.t &lt;- Q_cid8.r[v,v] print(Q_cid8.r) ## a0 a1 b0 b1 c0 c1 d0 d1 ## a0 -0.3 0.1 0.1 0.0 0.1 0.0 0.0 0.0 ## a1 0.1 -0.3 0.0 0.1 0.0 0.1 0.0 0.0 ## b0 0.1 0.0 -0.3 0.1 0.0 0.0 0.1 0.0 ## b1 0.0 0.1 0.1 -0.3 0.0 0.0 0.0 0.1 ## c0 0.1 0.0 0.0 0.0 -0.3 0.1 0.1 0.0 ## c1 0.0 0.1 0.0 0.0 0.1 -0.3 0.0 0.1 ## d0 0.0 0.0 0.1 0.0 0.1 0.0 -0.3 0.1 ## d1 0.0 0.0 0.0 0.1 0.0 0.1 0.1 -0.3 print(La8) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.1 0.0 0.0 0.0 0.00 0.00 0.00 0.00 ## [2,] 0.0 -0.1 0.0 0.0 0.00 0.00 0.00 0.00 ## [3,] 0.0 0.0 -0.1 0.0 0.00 0.00 0.00 0.00 ## [4,] 0.0 0.0 0.0 -0.1 0.00 0.00 0.00 0.00 ## [5,] 0.0 0.0 0.0 0.0 -0.05 0.00 0.00 0.00 ## [6,] 0.0 0.0 0.0 0.0 0.00 -0.05 0.00 0.00 ## [7,] 0.0 0.0 0.0 0.0 0.00 0.00 -0.05 0.00 ## [8,] 0.0 0.0 0.0 0.0 0.00 0.00 0.00 -0.05 print(Q_cid8.t) ## a0 b0 c0 d0 a1 b1 c1 d1 ## a0 -0.3 0.1 0.1 0.0 0.1 0.0 0.0 0.0 ## b0 0.1 -0.3 0.0 0.1 0.0 0.1 0.0 0.0 ## c0 0.1 0.0 -0.3 0.1 0.0 0.0 0.1 0.0 ## d0 0.0 0.1 0.1 -0.3 0.0 0.0 0.0 0.1 ## a1 0.1 0.0 0.0 0.0 -0.3 0.1 0.1 0.0 ## b1 0.0 0.1 0.0 0.0 0.1 -0.3 0.0 0.1 ## c1 0.0 0.0 0.1 0.0 0.1 0.0 -0.3 0.1 ## d1 0.0 0.0 0.0 0.1 0.0 0.1 0.1 -0.3 print(La8[v,v]) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] ## [1,] -0.1 0.0 0.00 0.00 0.0 0.0 0.00 0.00 ## [2,] 0.0 -0.1 0.00 0.00 0.0 0.0 0.00 0.00 ## [3,] 0.0 0.0 -0.05 0.00 0.0 0.0 0.00 0.00 ## [4,] 0.0 0.0 0.00 -0.05 0.0 0.0 0.00 0.00 ## [5,] 0.0 0.0 0.00 0.00 -0.1 0.0 0.00 0.00 ## [6,] 0.0 0.0 0.00 0.00 0.0 -0.1 0.00 0.00 ## [7,] 0.0 0.0 0.00 0.00 0.0 0.0 -0.05 0.00 ## [8,] 0.0 0.0 0.00 0.00 0.0 0.0 0.00 -0.05 7.3.3 COR8-C (correlated evolution, congruent to CID4) # like CID8 but with correlation Q_cor8_C.t &lt;- Q_cid8.t bl &lt;- matrix(c(0,.1,.1,0),2,2) Q_cor8_C.t[1:2,5:6] &lt;- bl Q_cor8_C.t[3:4,7:8] &lt;- bl Q_cor8_C.t[5:6,1:2] &lt;- bl Q_cor8_C.t[7:8,3:4] &lt;- bl v=c(1,5, 2,6, 3,7, 4,8) Q_cor8_C.r &lt;- Q_cor8_C.t[v,v] print(Q_cor8_C.r) ## a0 a1 b0 b1 c0 c1 d0 d1 ## a0 -0.3 0.0 0.1 0.1 0.1 0.0 0.0 0.0 ## a1 0.0 -0.3 0.1 0.1 0.0 0.1 0.0 0.0 ## b0 0.1 0.1 -0.3 0.0 0.0 0.0 0.1 0.0 ## b1 0.1 0.1 0.0 -0.3 0.0 0.0 0.0 0.1 ## c0 0.1 0.0 0.0 0.0 -0.3 0.0 0.1 0.1 ## c1 0.0 0.1 0.0 0.0 0.0 -0.3 0.1 0.1 ## d0 0.0 0.0 0.1 0.0 0.1 0.1 -0.3 0.0 ## d1 0.0 0.0 0.0 0.1 0.1 0.1 0.0 -0.3 #print(La8) print(Q_cor8_C.t) ## a0 b0 c0 d0 a1 b1 c1 d1 ## a0 -0.3 0.1 0.1 0.0 0.0 0.1 0.0 0.0 ## b0 0.1 -0.3 0.0 0.1 0.1 0.0 0.0 0.0 ## c0 0.1 0.0 -0.3 0.1 0.0 0.0 0.0 0.1 ## d0 0.0 0.1 0.1 -0.3 0.0 0.0 0.1 0.0 ## a1 0.0 0.1 0.0 0.0 -0.3 0.1 0.1 0.0 ## b1 0.1 0.0 0.0 0.0 0.1 -0.3 0.0 0.1 ## c1 0.0 0.0 0.0 0.1 0.1 0.0 -0.3 0.1 ## d1 0.0 0.0 0.1 0.0 0.0 0.1 0.1 -0.3 #print(La8[v,v]) 7.3.4 COR8-NC (Non-correlated evolution, congruent to CID4) # like CID8 but not congruent Q_cor8_NC.t &lt;- Q_cid8.t bl &lt;- matrix(c(0,0,.1,0),2,2) Q_cor8_NC.t[1:2,5:6] &lt;- bl Q_cor8_NC.t[3:4,7:8] &lt;- bl Q_cor8_NC.t[5:6,1:2] &lt;- bl Q_cor8_NC.t[7:8,3:4] &lt;- bl v=c(1,5, 2,6, 3,7, 4,8) Q_cor8_NC.r &lt;- Q_cor8_NC.t[v,v] print(Q_cor8_NC.r) ## a0 a1 b0 b1 c0 c1 d0 d1 ## a0 -0.3 0.0 0.1 0.1 0.1 0.0 0.0 0.0 ## a1 0.0 -0.3 0.1 0.1 0.0 0.1 0.0 0.0 ## b0 0.1 0.0 -0.3 0.0 0.0 0.0 0.1 0.0 ## b1 0.0 0.1 0.0 -0.3 0.0 0.0 0.0 0.1 ## c0 0.1 0.0 0.0 0.0 -0.3 0.0 0.1 0.1 ## c1 0.0 0.1 0.0 0.0 0.0 -0.3 0.1 0.1 ## d0 0.0 0.0 0.1 0.0 0.1 0.0 -0.3 0.0 ## d1 0.0 0.0 0.0 0.1 0.0 0.1 0.0 -0.3 #print(La8) print(Q_cor8_NC.t) ## a0 b0 c0 d0 a1 b1 c1 d1 ## a0 -0.3 0.1 0.1 0.0 0.0 0.1 0.0 0.0 ## b0 0.1 -0.3 0.0 0.1 0.0 0.0 0.0 0.0 ## c0 0.1 0.0 -0.3 0.1 0.0 0.0 0.0 0.1 ## d0 0.0 0.1 0.1 -0.3 0.0 0.0 0.0 0.0 ## a1 0.0 0.1 0.0 0.0 -0.3 0.1 0.1 0.0 ## b1 0.0 0.0 0.0 0.0 0.1 -0.3 0.0 0.1 ## c1 0.0 0.0 0.0 0.1 0.1 0.0 -0.3 0.1 ## d1 0.0 0.0 0.0 0.0 0.0 0.1 0.1 -0.3 #print(La8[v,v]) 7.4 Irreducible model 7.4.1 CID4 (4 pars) Args &lt;- list( Nstates = 4L, y = sam.fr4) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(4) #args$arrays #args$pars #length(args$pars) reoder_lambdas(args$arrays, c(1,3, 2,4)) ## $lam.tensor ## $lam.tensor[[1]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;lam000&quot; &quot;lam002&quot; &quot;lam001&quot; &quot;lam003&quot; ## [2,] &quot;0&quot; &quot;lam022&quot; &quot;0&quot; &quot;lam023&quot; ## [3,] &quot;0&quot; &quot;lam012&quot; &quot;lam011&quot; &quot;lam013&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam033&quot; ## ## $lam.tensor[[2]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;lam200&quot; &quot;lam202&quot; &quot;lam201&quot; &quot;lam203&quot; ## [2,] &quot;0&quot; &quot;lam222&quot; &quot;0&quot; &quot;lam223&quot; ## [3,] &quot;0&quot; &quot;lam212&quot; &quot;lam211&quot; &quot;lam213&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam233&quot; ## ## $lam.tensor[[3]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;lam100&quot; &quot;lam102&quot; &quot;lam101&quot; &quot;lam103&quot; ## [2,] &quot;0&quot; &quot;lam122&quot; &quot;0&quot; &quot;lam123&quot; ## [3,] &quot;0&quot; &quot;lam112&quot; &quot;lam111&quot; &quot;lam113&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam133&quot; ## ## $lam.tensor[[4]] ## [,1] [,2] [,3] [,4] ## [1,] &quot;lam300&quot; &quot;lam302&quot; &quot;lam301&quot; &quot;lam303&quot; ## [2,] &quot;0&quot; &quot;lam322&quot; &quot;0&quot; &quot;lam323&quot; ## [3,] &quot;0&quot; &quot;lam312&quot; &quot;lam311&quot; &quot;lam313&quot; ## [4,] &quot;0&quot; &quot;0&quot; &quot;0&quot; &quot;lam333&quot; ## ## ## $mu ## [1] &quot;mu0&quot; &quot;mu2&quot; &quot;mu1&quot; &quot;mu3&quot; ## ## $Q ## [,1] [,2] [,3] [,4] ## [1,] &quot;0&quot; &quot;q02&quot; &quot;q01&quot; &quot;q03&quot; ## [2,] &quot;q20&quot; &quot;0&quot; &quot;q21&quot; &quot;q23&quot; ## [3,] &quot;q10&quot; &quot;q12&quot; &quot;0&quot; &quot;q13&quot; ## [4,] &quot;q30&quot; &quot;q32&quot; &quot;q31&quot; &quot;0&quot; pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- 0.1 pars.hc[&#39;lam111&#39;] &lt;- 0.1 pars.hc[&#39;lam222&#39;] &lt;- 0.05 pars.hc[&#39;lam333&#39;] &lt;- 0.05 pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;-0.1 qs &lt;- extract_off_diagonal(Q_cid4.r) qsl=length(qs) pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs zero.constr &lt;- formulas_zero_pars(pars.hc) f.qs &lt;- assign_classes_pairwise(Q_cid4.r, args$arrays$Q) f.mu &lt;- c(mu1 ~ mu0, mu2 ~ mu0, mu3 ~ mu0) f.lams &lt;- c(lam111 ~ lam000, lam333 ~ lam222) f.list&lt;- c(zero.constr, f.qs, f.mu, f.lams) Run inference CID4 &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- c(1/4, 1/4, 1/4, 1/4) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) lik.const &lt;- constrain(lik.c, formulae = f.list) arg.const &lt;- argnames(lik.const) starting.point &lt;- pars.hc[arg.const] CID4[[i]] &lt;- find.mle(lik.const, starting.point, method=&quot;subplex&quot;, keep.func=F, root=ROOT.GIVEN, root.p=root, condition.surv=TRUE) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.700.300.3&quot; Some helper functions to assess the inference parameters. get_item(CID4, &#39;lnLik&#39;) ## [1] -438.1492 -423.6706 -406.3133 -415.9856 -423.3954 -411.9496 -428.5559 -423.9597 -417.3035 -396.6808 7.5 Inferences using parameters from CID4 7.5.1 CID8 (4 pars) Args &lt;- list( Nstates = 8L, y = sam.fr8) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args$arrays #reoder_lambdas(args$arrays, c(1,3,5,7, 2,4,6,8)) Run inference CID8.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam111&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam222&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam333&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam444&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam555&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam666&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam777&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cid8.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs #pars.hc #pars_to_arrays(pars.hc, 8) #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) CID8.pars[[i]] &lt;- lik.c(pars.hc, intermediates=T, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; Compare Ln get_item(CID4, &#39;lnLik&#39;) ## [1] -438.1492 -423.6706 -406.3133 -415.9856 -423.3954 -411.9496 -428.5559 -423.9597 -417.3035 -396.6808 CID8.pars %&gt;% unlist ## [1] -438.1492 -423.6706 -406.3133 -415.9856 -423.3954 -411.9496 -428.5559 -423.9597 -417.3035 -396.6808 7.5.2 COR8-C (4 pars) Args &lt;- list( Nstates = 8L, y = sam.fr8) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args Run inference COR8_C.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam111&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam222&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam333&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam444&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam555&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam666&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam777&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cor8_C.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs # pars.hc # pars_to_arrays(pars.hc, 8) #v=c(1,3,5,7, 2,4,6,8) #pars_to_arrays(pars.hc, 8)$Q[v,v] #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) COR8_C.pars[[i]] &lt;- lik.c(pars.hc, root=ROOT.GIVEN, root.p=root, condition.surv=T, intermediates=F) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; Compare Ln get_item(CID4, &#39;lnLik&#39;) ## [1] -438.1492 -423.6706 -406.3133 -415.9856 -423.3954 -411.9496 -428.5559 -423.9597 -417.3035 -396.6808 COR8_C.pars %&gt;% unlist ## [1] -438.1492 -423.6706 -406.3133 -415.9856 -423.3954 -411.9496 -428.5559 -423.9597 -417.3035 -396.6808 7.5.3 COR8-NC (4 pars) Args &lt;- list( Nstates = 8L, y = sam.fr8) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args Run inference COR8_NC.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars pars.hc[&#39;lam000&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam111&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam222&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam333&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam444&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam555&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam666&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam777&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cor8_NC.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs # pars.hc # pars_to_arrays(pars.hc, 8) # v=c(1,3,5,7, 2,4,6,8) # pars_to_arrays(pars.hc, 8)$Q[v,v] #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) COR8_NC.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; Some helper function to assess the inference parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.1492 -423.6706 -406.3133 -415.9856 -423.3954 -411.9496 -428.5559 -423.9597 -417.3035 -396.6808 COR8_NC.pars %&gt;% unlist ## [1] -442.7588 -424.9431 -409.1647 -418.0908 -426.8760 -415.5245 -429.7205 -423.6662 -418.6281 -400.0462 7.5.4 CLA8-C (4 pars) Args &lt;- list( Nstates = 8L, y = sam.fr8) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args$arrays # reoder_lambdas(args$arrays, c(1,3,5,7, 2,4,6,8)) Run inference CLA8_C.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars # pars.hc[&#39;lam000&#39;] &lt;- est[&#39;lam000&#39;] # pars.hc[&#39;lam111&#39;] &lt;- est[&#39;lam000&#39;] # pars.hc[&#39;lam222&#39;] &lt;- est[&#39;lam000&#39;] # pars.hc[&#39;lam333&#39;] &lt;- est[&#39;lam000&#39;] # pars.hc[&#39;lam444&#39;] &lt;- est[&#39;lam222&#39;] # pars.hc[&#39;lam555&#39;] &lt;- est[&#39;lam222&#39;] # pars.hc[&#39;lam666&#39;] &lt;- est[&#39;lam222&#39;] # pars.hc[&#39;lam777&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam022&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam133&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam202&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam311&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam466&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam577&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam646&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam757&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cor8_C.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs # pars.hc # pars_to_arrays(pars.hc, 8) # v=c(1,3,5,7, 2,4,6,8) # pars_to_arrays(pars.hc, 8)$Q[v,v] #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) CLA8_C.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; Some helper function to assess the inference parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.1492 -423.6706 -406.3133 -415.9856 -423.3954 -411.9496 -428.5559 -423.9597 -417.3035 -396.6808 CLA8_C.pars %&gt;% unlist ## [1] -438.1492 -423.6706 -406.3133 -415.9856 -423.3954 -411.9496 -428.5559 -423.9597 -417.3035 -396.6808 7.5.5 CLA8-NC (4 pars) Args &lt;- list( Nstates = 8L, y = sam.fr8) newArgs &lt;- makeArgs(Args) #printArgsGlobal() args &lt;- argnames_HiClaSSE(8) #args$arrays #v=c(1,3,5,7, 2,4,6,8) #reoder_lambdas(args$arrays, c(1,3,5,7, 2,4,6,8)) Run inference CLA8_NC.pars &lt;- list() i=1 for (i in 1:NSIM){ print(paste0(&#39;Working on: &#39;, i)) #----------- est &lt;- get_item(CID4[i], &#39;par&#39;) pars.hc &lt;- rep(0, length(args$pars)) names(pars.hc) &lt;- args$pars # lam004, lam116, lam422 violate lumpability pars.hc[&#39;lam004&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam116&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam202&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam311&#39;] &lt;- est[&#39;lam000&#39;] pars.hc[&#39;lam422&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam577&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam646&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;lam757&#39;] &lt;- est[&#39;lam222&#39;] pars.hc[&#39;mu0&#39;] &lt;-pars.hc[&#39;mu1&#39;] &lt;- pars.hc[&#39;mu2&#39;] &lt;- pars.hc[&#39;mu3&#39;] &lt;- pars.hc[&#39;mu4&#39;]&lt;- pars.hc[&#39;mu5&#39;]&lt;- pars.hc[&#39;mu6&#39;]&lt;- pars.hc[&#39;mu7&#39;] &lt;- est[&#39;mu0&#39;] qs &lt;- extract_off_diagonal(Q_cor8_C.r) qsl=length(qs) qs[qs==0.1] &lt;- est[&#39;q01&#39;] qs[qs==0.01] &lt;- est[&#39;q02&#39;]/2 pars.hc[c(length(pars.hc)-qsl+1):length(pars.hc)] &lt;- qs # pars.hc # pars_to_arrays(pars.hc, 8) # v=c(1,3,5,7, 2,4,6,8) # pars_to_arrays(pars.hc, 8)$Q[v,v] #------ tree &lt;- phy[[i]] states&lt;- tree$tip.state states&lt;- mapvalues(states, from = c(&quot;0&quot;, &quot;1&quot;, &quot;2&quot;, &quot;3&quot;), to=c(0, 1, 0, 1) ) root &lt;- rep(1/8, 8) lik.c &lt;- make.HiClasse_cpp(tree, states, sampling.f=NULL, strict=TRUE, control=list(backend = &quot;gslode&quot;), newArgs) CLA8_NC.pars[[i]] &lt;- lik.c(pars.hc, intermediates=F, root=ROOT.GIVEN, root.p=root, condition.surv=T) } ## [1] &quot;Working on: 1&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 2&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 3&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 4&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 5&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 6&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 7&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 8&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 9&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; ## [1] &quot;Working on: 10&quot; ## [1] &quot;Recoding: 0010 -&gt; 0.40.70.40.70.40.70.40.70.600.600.600.60&quot; ## [1] &quot;Recoding: 0001 -&gt; 0.40.70.40.70.40.70.40.700.300.300.300.3&quot; Some helper function to assess the inference parameters get_item(CID4, &#39;lnLik&#39;) ## [1] -438.1492 -423.6706 -406.3133 -415.9856 -423.3954 -411.9496 -428.5559 -423.9597 -417.3035 -396.6808 CLA8_NC.pars %&gt;% unlist ## [1] -455.2435 -423.1396 -404.8852 -416.3316 -421.3739 -411.4208 -429.5248 -433.8740 -416.1229 -395.2733 7.6 Results 7.6.1 Inferences using parameters from CID4 7.6.1.1 Likelihood table cid4 = get_item(CID4, &#39;lnLik&#39;) cor.pars &lt;- tibble( &quot;N&quot; = c(1:NSIM), &quot;cid4&quot; = cid4, &quot;CID8.pars&quot;= CID8.pars %&gt;% unlist, &quot;COR8-C.pars&quot;= COR8_C.pars %&gt;% unlist, &quot;CLA8-C.pars&quot; = CLA8_C.pars %&gt;% unlist, &quot;COR8-NC.pars&quot; = COR8_NC.pars %&gt;% unlist, &quot;CLA8-NC.pars&quot; = CLA8_NC.pars %&gt;% unlist, ) kable(cor.pars, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;)) N cid4 CID8.pars COR8-C.pars CLA8-C.pars COR8-NC.pars CLA8-NC.pars 1 -438.1492 -438.1492 -438.1492 -438.1492 -442.7588 -455.2435 2 -423.6706 -423.6706 -423.6706 -423.6706 -424.9431 -423.1396 3 -406.3133 -406.3133 -406.3133 -406.3133 -409.1647 -404.8852 4 -415.9856 -415.9856 -415.9856 -415.9856 -418.0908 -416.3316 5 -423.3954 -423.3954 -423.3954 -423.3954 -426.8760 -421.3739 6 -411.9496 -411.9496 -411.9496 -411.9496 -415.5245 -411.4208 7 -428.5559 -428.5559 -428.5559 -428.5559 -429.7205 -429.5248 8 -423.9597 -423.9597 -423.9597 -423.9597 -423.6662 -433.8740 9 -417.3035 -417.3035 -417.3035 -417.3035 -418.6281 -416.1229 10 -396.6808 -396.6808 -396.6808 -396.6808 -400.0462 -395.2733 7.6.1.2 Mean absolute error dcor.pars &lt;- tibble( &quot;cid4&quot; = cid4, &quot;CID8.pars&quot;= CID8.pars %&gt;% unlist, &quot;COR8-C.pars&quot;= COR8_C.pars %&gt;% unlist, &quot;CLA8-C.pars&quot; = CLA8_C.pars %&gt;% unlist, &quot;COR8-NC.pars&quot; = COR8_NC.pars %&gt;% unlist, &quot;CLA8-NC.pars&quot; = CLA8_NC.pars %&gt;% unlist, ) cid4t &lt;- cid4 dcor.pars &lt;- dcor.pars %&gt;% mutate_all(~ abs(cid4t - .) ) column_means &lt;- dcor.pars %&gt;% summarise_all(~ mean(.)) # Data delta_values &lt;- tibble( Delta = names(column_means), Value = column_means %&gt;% slice(1) %&gt;% unlist() ) kable(column_means, &quot;html&quot;) %&gt;% kable_styling(bootstrap_options = c(&quot;striped&quot;, &quot;hover&quot;)) cid4 CID8.pars COR8-C.pars CLA8-C.pars COR8-NC.pars CLA8-NC.pars 0 1e-07 1e-07 1e-07 2.404245 3.542092 # Create the plot ggplot(delta_values, aes(x = Delta, y = Value, label = sprintf(&quot;%.2e&quot;, Value))) + geom_col(fill = c(&quot;blue&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;blue&quot;, &quot;red&quot;, &quot;red&quot;)) + geom_text(vjust = -0.5, angle = 45) + labs(title = &quot;Comparison of Ln Differences&quot;, x = &quot;Deltas&quot;, y = &quot;Magnitude&quot;) + theme_minimal() "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
